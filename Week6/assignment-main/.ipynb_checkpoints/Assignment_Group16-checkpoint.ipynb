{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4305TU: Week 6 - Artificial Neural Network - Assignment\n",
    "## Investigating neighbourhood choice behaviour using ANNs\n",
    "**7 & 11 October 2021**\n",
    "\n",
    "- Sander van Cranenburgh\n",
    "- Francisco Garrido-Valenzuela "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information\n",
    "\n",
    "* For this assignment we will use *Stated Choice data* on residential location choice, collected in:\n",
    "    - Mainz, Germany\n",
    "    - Hanover, Germany\n",
    "    - Bern, Switzerland\n",
    "    - Zurich, Switzerland \n",
    "\n",
    "- For more details on the data, see the description provided on [Brightspace](https://brightspace.tudelft.nl/d2l/le/content/399675/viewContent/2506146/View). \n",
    "\n",
    "- In total you can earn **6.0** points in this assignment. \n",
    "\n",
    "- Add **Code cells** to complement your analyses. You can draw a lot form the snippets of codes we used for the in-class exercises.\n",
    "\n",
    "### Submission instructions\n",
    "\n",
    "- Answer the questions (code and/or text) in this notebook\n",
    "- Rename this file by adding your group nomber (e.g. Assignment_groupXX.ipynb)\n",
    "- Submit your answers both in ipynb and html format\n",
    "\n",
    "**Provide your answers in the allocated markdown boxes** (with the red font color)\n",
    "\n",
    "\n",
    "### Set up your environment\n",
    "\n",
    "You need to set up your environment based on which platform you would like to use. In this case we offer two options:\n",
    "\n",
    "- Google Colaboratory (Colab)\n",
    "- Jupyter Lab or Notebooks (Local)\n",
    "\n",
    "#### Using Colab\n",
    "\n",
    "Students using **Colab**, just need to install **Biogeme**. Biogeme is a Python package designed for the maximum likelihood estimation of parametric models in general, with a special emphasis on discrete choice models. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using Google Colab (keep the exclamation mark)\n",
    "#!pip install biogeme\n",
    "#!git clone https://github.com/cs4305tu/assignment\n",
    "#root = 'assignment/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using local environment\n",
    "\n",
    "Students using their *local environments*, need to install all the dependencies used in this *Week 6*, to ensure compatibility, they also need to check the versions of each dependency. All dependencies are contained in the text file: **requirements.txt**. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using your local environment (keep the exclamation mark)\n",
    "# !pip3 install -r requirements.txt\n",
    "# root = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Python packages\n",
    "\n",
    "In the following cell add all the packages you need to finish this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow  2.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from heatmap import corrplot\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.database as db\n",
    "import biogeme.optimization as opt\n",
    "import biogeme.messaging as msg\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Using tensorflow \",tf.__version__)\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import ML packaged and modules\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID2</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>SSTADT</th>\n",
       "      <th>RESPCITY</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ENVCONC</th>\n",
       "      <th>COMPLETE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  ID2  STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  \\\n",
       "0   2    5       10           5      1       2       2       0.4       15   \n",
       "1   2    6       15           5      4       4       1       0.1        2   \n",
       "2   2    7       10          15      1       3       1       0.4       15   \n",
       "3   2    8       15          15      5       4       4       0.4        2   \n",
       "4   3    9       15           5      5       1       3       0.4        2   \n",
       "\n",
       "   TRANSPORT2  ...  NOISE3  GREEN3  FOREIGN3  CHOICE  SSTADT  RESPCITY  WOMAN  \\\n",
       "0          10  ...       4       4       0.2       1       3         3      0   \n",
       "1          10  ...       2       3       0.3       2       3         3      0   \n",
       "2           2  ...       1       3       0.2       3       3         3      0   \n",
       "3           2  ...       2       2       0.2       2       3         3      0   \n",
       "4          10  ...       3       1       0.2       2       2         2      1   \n",
       "\n",
       "   AGE  ENVCONC  COMPLETE  \n",
       "0   42      3.0         1  \n",
       "1   42      3.0         1  \n",
       "2   42      3.0         1  \n",
       "3   42      3.0         1  \n",
       "4   41      4.5         1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a dataframe\n",
    "root = ''\n",
    "df = pd.read_csv(f'{root}datasets/neighbourhood_choice2018.dat', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Do a proper descriptive analysis of the data set (1.0 pt)\n",
    "\n",
    "It is good practice to do a descriptive analysis of the data you want to model, prior to the real modelling. So inspect e.g. what levels the attributes (features) take, correlations, class (im)balances, redudant variables, missing values, etc. to attain a good feeling for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice features are: ['STORES', 'TRANSPORT', 'CITY', 'NOISE', 'GREEN', 'FOREIGN']\n",
      "Other available features are: ['WOMAN', 'AGE', 'SSTADT', 'RESPCITY', 'ENVCONC']\n",
      "The evaluation metric is ['CHOICE']\n",
      "\n",
      "Total number of Nan values: 0\n",
      "Total number of empty (None) values: 0\n",
      "Total number of incomplete responses: 0\n",
      "\n",
      "Check the levels that each feature can take:\n",
      "Choice features:\n",
      "\tSTORES can take: [ 2  5 10 15]\n",
      "\tTRANSPORT can take: [ 2  5 10 15]\n",
      "\tCITY can take: [1 2 4 5]\n",
      "\tNOISE can take: [1 2 3 4]\n",
      "\tGREEN can take: [1 2 3 4]\n",
      "\tFOREIGN can take: [0.1 0.2 0.3 0.4]\n",
      "Other features\n",
      "\tWOMAN can take: [    0     1 99999]\n",
      "\tAGE can take: [   18    19    20    21    22    23    24    25    26    27    28    29\n",
      "    30    31    32    33    34    35    36    37    38    39    40    41\n",
      "    42    43    44    45    46    47    48    49    50    51    52    53\n",
      "    54    55    56    57    58    59    60    61    62    63    64    65\n",
      "    66    67    68    69    70 99999]\n",
      "\tSSTADT can take: [1 2 3 4]\n",
      "\tRESPCITY can take: [1 2 3 4]\n",
      "\tENVCONC can take: [1.00000000e+00 1.16666663e+00 1.33333337e+00 1.50000000e+00\n",
      " 1.66666663e+00 1.83333337e+00 2.00000000e+00 2.16666675e+00\n",
      " 2.33333325e+00 2.50000000e+00 2.66666675e+00 2.83333325e+00\n",
      " 3.00000000e+00 3.16666675e+00 3.33333325e+00 3.50000000e+00\n",
      " 3.66666675e+00 3.75000000e+00 3.83333325e+00 4.00000000e+00\n",
      " 4.16666651e+00 4.33333349e+00 4.50000000e+00 4.66666651e+00\n",
      " 4.75000000e+00 4.83333349e+00 5.00000000e+00 9.99990000e+04]\n",
      "\n",
      "Total number of 99999 values in AGE: 64\n",
      "nTotal number of 99999 values in WOMAN: 20\n",
      "nTotal number of 9.99990000e+04 values in ENVCONC: 188\n"
     ]
    }
   ],
   "source": [
    "# All features in dataset, devided into the choice feature, and additional feaures.\n",
    "features_choices = ['STORES', 'TRANSPORT', 'CITY', 'NOISE', 'GREEN', 'FOREIGN']\n",
    "features_other = ['WOMAN', 'AGE', 'SSTADT', 'RESPCITY', 'ENVCONC']\n",
    "print(f'The choice features are: {features_choices}')\n",
    "print(f'Other available features are: {features_other}')\n",
    "print(f\"The evaluation metric is ['CHOICE']\")\n",
    "\n",
    "\n",
    "# Check for Nan values in dataset\n",
    "print(f'\\nTotal number of Nan values: {df.isna().sum().sum()}')\n",
    "# Check for empty (None) values in dataset\n",
    "print(f'Total number of empty (None) values: {int(df[df==None].sum().sum())}')\n",
    "# Check for complete responses\n",
    "print(f'Total number of incomplete responses: {df.COMPLETE[df.COMPLETE==0].sum()}')\n",
    "\n",
    "# Check the various levels that each feature can take\n",
    "print('\\nCheck the levels that each feature can take:')\n",
    "print('Choice features:')\n",
    "for feature in features_choices:\n",
    "    feature_choice = [feature+str(choice) for choice in range(1, 4)]\n",
    "    levels = np.unique(df[feature_choice].to_numpy().flatten())\n",
    "    print(f\"\\t{feature} can take: {levels}\")\n",
    "print('Other features')\n",
    "for feature in features_other:\n",
    "    levels = np.unique(df[feature].to_numpy().flatten())\n",
    "    print(f\"\\t{feature} can take: {levels}\")\n",
    "\n",
    "# Check for faulty values\n",
    "print(f'\\nTotal number of 99999 values in AGE: {df.AGE[df.AGE==99999].size}')\n",
    "print(f'nTotal number of 99999 values in WOMAN: {df.WOMAN[df.WOMAN==99999].size}')\n",
    "print(f'nTotal number of 9.99990000e+04 values in ENVCONC: {df.ENVCONC[df.ENVCONC==9.99990000e+04].size}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of choices: 9720\n",
      "--------------------------------\n",
      "\t Number of choices equal to 1: 3440 --> 35.39% of total\n",
      "\t Number of choices equal to 2: 3266 --> 33.6% of total\n",
      "\t Number of choices equal to 3: 3014 --> 31.01% of total\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show how often each alternative is chosen\n",
    "print(f\"Total number of choices: {len(df.CHOICE)}\")\n",
    "print('--------------------------------')\n",
    "for choice in range(1, 4):\n",
    "    print(f\"\\t Number of choices equal to {choice}: {len(df.CHOICE[df.CHOICE == choice])} --> {round(len(df.CHOICE[df.CHOICE == choice])/len(df.CHOICE)*100, 2)}% of total\")\n",
    "\n",
    "fig=plt.figure(figsize=(6,4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.hist(df.CHOICE, bins = [0.75, 1.25, 1.75, 2.25, 2.75, 3.25])\n",
    "plt.xticks((1, 2, 3))\n",
    "plt.title('Number of choices per alternative')\n",
    "plt.xlabel('Choice')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of each feature to CHOICE, sorted by absolute value:\n",
      "CHOICE        1.000000\n",
      "GREEN1        0.269186\n",
      "NOISE1        0.236012\n",
      "GREEN3        0.221183\n",
      "NOISE3        0.217670\n",
      "TRANSPORT1    0.197005\n",
      "TRANSPORT3    0.187422\n",
      "NOISE2        0.168685\n",
      "CITY3         0.165109\n",
      "CITY1         0.153796\n",
      "FOREIGN1      0.095885\n",
      "TRANSPORT2    0.095360\n",
      "STORES3       0.079537\n",
      "CITY2         0.067889\n",
      "FOREIGN3      0.064269\n",
      "STORES1       0.060248\n",
      "FOREIGN2      0.048984\n",
      "GREEN2        0.025195\n",
      "SSTADT        0.009905\n",
      "RESPCITY      0.009905\n",
      "AGE           0.007536\n",
      "ENVCONC       0.006206\n",
      "WOMAN         0.002445\n",
      "STORES2       0.000457\n",
      "Name: CHOICE, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_features = [features_choices[i]+str(j) for j in range(1, 4) for i in range(len(features_choices))]\n",
    "\n",
    "corr = df[['CHOICE'] + all_features + features_other].corr()\n",
    "\n",
    "corr_choice = corr['CHOICE']\n",
    "abs_corr_sorted = corr_choice.abs().sort_values(ascending=False)     # sorted by largest correlation to income\n",
    "\n",
    "print('Correlation of each feature to CHOICE, sorted by absolute value:')\n",
    "print(abs_corr_sorted)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "corrplot(corr, size_scale=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>GREEN2</th>\n",
       "      <th>FOREIGN2</th>\n",
       "      <th>STORES3</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  TRANSPORT2  CITY2  \\\n",
       "0       10           5      1       2       2       0.4          10      2   \n",
       "1       15           5      4       4       1       0.1          10      5   \n",
       "2       10          15      1       3       1       0.4           2      2   \n",
       "3       15          15      5       4       4       0.4           2      1   \n",
       "4       15           5      5       1       3       0.4          10      1   \n",
       "\n",
       "   NOISE2  GREEN2  FOREIGN2  STORES3  TRANSPORT3  CITY3  NOISE3  GREEN3  \\\n",
       "0       3       3       0.1        2          15      4       4       4   \n",
       "1       1       2       0.2        5          15      1       2       3   \n",
       "2       4       2       0.1        2           5      4       1       3   \n",
       "3       1       1       0.1        5           5      2       2       2   \n",
       "4       2       4       0.1        5          15      2       3       1   \n",
       "\n",
       "   FOREIGN3  CHOICE  \n",
       "0       0.2       1  \n",
       "1       0.3       2  \n",
       "2       0.2       3  \n",
       "3       0.2       2  \n",
       "4       0.2       2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop features that are leased relatted to choice\n",
    "df_reduced = df.drop(['STORES2'] + features_other + ['COMPLETE', 'ID', 'ID2'], axis=1)\n",
    "# df_reduced = df.drop(['STORES2', 'GREEN2', 'FOREIGN2'] + features_other + ['COMPLETE', 'ID', 'ID2'], axis=1)\n",
    "# df_reduced = df.drop(['STORES2', 'GREEN2', 'FOREIGN2', 'STORES1', 'FOREIGN3', 'CITY2'] + features_other + ['COMPLETE', 'ID', 'ID2'], axis=1)\n",
    "\n",
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q1** <br>\n",
    "The dataset is seen to consist out of two main set of features. The first set is the various 'choice features' available for each of the three choices; and the second set consist of 'other features', which contain information regarding the applicant, e.g.: age, woman (yes or no), place of citizenship.\n",
    "\n",
    "Considering all the available data, the dataset is checked for Nan and empty values. It is found that none of these input types are present. It is also checked whether all choices are complete, which is done by evaluation the COMPLETE feature. This is also found to true for all choices.\n",
    "\n",
    "Then, the type of levels each feature can take-on are obtained. For the choice features, no irrelevant/faulty levels are seen to exist in the dataset. For the 'other features', it can be seen that the WOMAN, AGE, and ENVCONC, contain irrelevant/faulty levels, equal to 99999. The number of occurances of these irrelevant levels are obtained for the three features. As later-on it will be found that these 'other features' do not relate to the CHOICE output, they will be discarded. Therefore, there is no need to correct for these faulty levels.\n",
    "\n",
    "Furthermore, the data is seen to be nicely balanced, with a distribution of 35.4%, 33.6%, and 31%, for the three choices, respectively.\n",
    "\n",
    "Finally, the correlations for all features to the CHOICE are constructed. These correlations are plotted, from which it can be seen that the 'other features' are not related to the CHOICE, and can therefore be discarded in the model. It is also found that ['STORES2', 'GREEN2', 'FOREIGN2', 'STORES1', 'FOREIGN3', 'CITY2'] do also have a small correlation to CHOICE. By removing some or all of these features, and evaluating the model performance, it is decided to remove the following features from the model: ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Estimate a RUM-MNL discrete choice model (1.0 pt)\n",
    "\n",
    "Assume utility is linear additive-utility: \n",
    "\n",
    "$ V_{in} = \\sum_{m}\\beta_m x_{imn}$\n",
    "\n",
    "And estimate marginal utilities (i.e. betas) for: \n",
    "\n",
    "1. Distance to Transport [min] (**Note** that distances are given in minutes)\n",
    "2. Distance to City [km]\n",
    "3. Distance to Stores [min] (**Note** that distances are given in minutes)\n",
    "4. Traffic Noise\n",
    "5. Green area\n",
    "6. Share of foreigners [%]\n",
    "\n",
    "**Note:** Do not add any other variables (features) to the model.\n",
    "\n",
    "**To get the scores, address the following:**\n",
    "\n",
    "- (A) Report the parameter estimates, and interpret them. i.e. do they have the expected sign? (0.5 pts)\n",
    "- (B) Compute and report the cross-entropy (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with pandas and database variable for Biogeme estimation\n",
    "database = db.Database('residential_choicedata2021', df)\n",
    "\n",
    "# The following statement allows you to use the names of the variable stored in Biogeme as Python variables.\n",
    "globals().update(database.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_stores = Beta('B_stores', 0, None, None, 0)\n",
    "B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "B_city = Beta('B_city', 0, None, None, 0)\n",
    "B_noise = Beta('B_noise', 0, None, None, 0)\n",
    "B_green = Beta('B_green', 0, None, None, 0)\n",
    "B_foreign = Beta('B_foreign', 0, None, None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate utility functions with the numbering of alternatives in df.CHOICE\n",
    "V = {1: V1, 2: V2, 3: V3}\n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "av = {1:1, 2:1, 3:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters\n",
      "----------\n",
      "                Value   Std err     t-test  p-value\n",
      "B_city      -0.167377  0.007949 -21.055742      0.0\n",
      "B_foreign   -1.196023  0.109408 -10.931775      0.0\n",
      "B_green      0.415894  0.011616  35.802485      0.0\n",
      "B_noise     -0.437468  0.011335 -38.594267      0.0\n",
      "B_stores    -0.034433  0.002577 -13.363956      0.0\n",
      "B_transport -0.073962  0.002548 -29.026039      0.0\n"
     ]
    }
   ],
   "source": [
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "prob = models.loglogit(V, av, CHOICE)\n",
    "\n",
    "# Create the Biogeme object\n",
    "biogeme = bio.BIOGEME(database, prob)\n",
    "biogeme.modelName = 'My first discrete choice model'\n",
    "biogeme.generatePickle = False\n",
    "biogeme.generateHtml = False\n",
    "\n",
    "# Calculate the null log likelihood for reporting.\n",
    "biogeme.calculateNullLoglikelihood(av)\n",
    "\n",
    "# Estimate the parameters\n",
    "results = biogeme.estimate()\n",
    "\n",
    "# Report the results in a pandas table\n",
    "print('Estimated parameters')\n",
    "print('----------')\n",
    "pandasResults = results.getEstimatedParameters()\n",
    "print(pandasResults[['Value','Std err','t-test','p-value']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-entropy of the DCM is         0.889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Get the estimated betas from the discrete choice model\n",
    "betas = results.getBetaValues()\n",
    "\n",
    "# Define compute objects\n",
    "prob_1 = models.logit(V, av, 1)\n",
    "prob_2 = models.logit(V, av, 2)\n",
    "prob_3 = models.logit(V, av, 3)\n",
    "\n",
    "# Define dictionary\n",
    "simulate_dict = {\n",
    "    'Prob_1': prob_1,\n",
    "    'Prob_2': prob_2,\n",
    "    'Prob_3': prob_3}\n",
    "\n",
    "# Create Biogeme object\n",
    "simulator = bio.BIOGEME(database, simulate_dict)\n",
    "\n",
    "# Compute probabilities using the estimated choice model\n",
    "probs_DCM = simulator.simulate(betas)\n",
    "\n",
    "# Compute the cross-entropy for the DCM\n",
    "cross_entropy_DCM = log_loss(df.CHOICE,probs_DCM)\n",
    "\n",
    "print('The cross-entropy of the DCM is        ',\"{:.3f}\".format(cross_entropy_DCM))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q2** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Based on your results, compute the WtP of the average decision maker to reduce the share of foreigners in a neighbourhood by 1 percentage point in terms of the distance to the grocery stores (0.5 pts)\n",
    "\n",
    "Thus, the answer must be of the following form: .... [minutes/percentage point].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q3** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Train a hybrid RUM-MNL-ANN model (1.5 pts)\n",
    "\n",
    "Since we are interested in the WtP of Q3, make sure when building the hybrid model to place the features of the share of foreigners and of the distance to the grocery stores in the *MNL part of the model*. For the *ANN part of the model* use 2 hidden layers, with 5 nodes each. \n",
    "\n",
    "\n",
    "**To get the scores, address the following:**\n",
    "\n",
    "\n",
    "- (A) Build the model, plot the loss as a function of the epochs & report the cross entropy of your final model based on the test data. (1.0 pt)\n",
    "- (B) Compare the model performance to that of the discrete choice model. Interpret the result. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NALT = 3           # Number of alterantives in the data set.\n",
    "no_X_MNL = 2       # Number of attributes with behavioural interest (-->MNL model part).  In this example we are particularly interested in the WtP for extra storage space --> Cost & Storage\n",
    "no_X_ANN = 17       # Number of features without behavioural interest (-->ANN model part). In this example we are not behaviourall interested in Camera, Size, and the socio demographic variables\n",
    "num_nodes = 5      # Number of nodes in hidden layer(s). Again we use 2 hidden layers with *num_nodes* nodes each\n",
    "nEpoch = 500       # Number epochs for training (max). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FOR MNL PART\n",
    "X_MNL = Input((no_X_MNL, NALT,1), name = 'Features2MNL')\n",
    "\n",
    "# COMPUTE UTILITY FOR MNL\n",
    "V_MNL = Conv2D(filters = 1, kernel_size = [no_X_MNL,1], strides = (1,1), padding = 'valid', name = 'MNL_layer', use_bias = False, trainable = True)(X_MNL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FOR ANN PART\n",
    "X_ANN = Input((no_X_ANN), name ='Features2ANN')\n",
    "\n",
    "# CREATE HIDDEN LAYER(S) OF ANN\n",
    "layer1_ANN = Dense(units = num_nodes, name = \"ANN_layer1\", use_bias = True)(X_ANN) \n",
    "layer2_ANN = Dense(units = num_nodes, name = \"ANN_layer2\", use_bias = True)(layer1_ANN)\n",
    "\n",
    "# COMPUTE UTILITY FOR ANN \n",
    "V_ANN = Dense(units = NALT, name = \"V_ANN\")(layer2_ANN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1', 'FOREIGN1',\n",
       "       'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2', 'FOREIGN2', 'STORES3',\n",
       "       'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3', 'FOREIGN3', 'CHOICE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE TENSORS TO [1 X NALT]\n",
    "V_MNL = Reshape([NALT], name = 'Flatten_Dim_MNL')(V_MNL)\n",
    "V_ANN = Reshape([NALT], name = 'Flatten_Dim_ANN')(V_ANN) \n",
    "\n",
    "# SUM THE UTILITIES OF BOTH MODEL PARTS\n",
    "V_MNL_ANN = Add(name = \"Combining_Vs\")([V_MNL,V_ANN])\n",
    "\n",
    "# CREATE LOGIT (AKA SOFTMAX ) OUTPUT LAYER\n",
    "logits = Activation('softmax', name = 'Probability')(V_MNL_ANN)\n",
    "\n",
    "# BUILD THE MODEL\n",
    "model = Model(inputs = [X_MNL, X_ANN], outputs = logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>GREEN2</th>\n",
       "      <th>FOREIGN2</th>\n",
       "      <th>STORES3</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9720 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  TRANSPORT2  CITY2  \\\n",
       "0          10           5      1       2       2       0.4          10      2   \n",
       "1          15           5      4       4       1       0.1          10      5   \n",
       "2          10          15      1       3       1       0.4           2      2   \n",
       "3          15          15      5       4       4       0.4           2      1   \n",
       "4          15           5      5       1       3       0.4          10      1   \n",
       "...       ...         ...    ...     ...     ...       ...         ...    ...   \n",
       "9715        5           5      2       4       1       0.3          10      4   \n",
       "9716       15          10      1       3       3       0.3          15      2   \n",
       "9717       10           5      2       3       4       0.1          10      4   \n",
       "9718        5           2      5       2       4       0.1           5      1   \n",
       "9719        5           5      2       4       1       0.3          10      4   \n",
       "\n",
       "      NOISE2  GREEN2  FOREIGN2  STORES3  TRANSPORT3  CITY3  NOISE3  GREEN3  \\\n",
       "0          3       3       0.1        2          15      4       4       4   \n",
       "1          1       2       0.2        5          15      1       2       3   \n",
       "2          4       2       0.1        2           5      4       1       3   \n",
       "3          1       1       0.1        5           5      2       2       2   \n",
       "4          2       4       0.1        5          15      2       3       1   \n",
       "...      ...     ...       ...      ...         ...    ...     ...     ...   \n",
       "9715       1       2       0.4       15          15      5       2       3   \n",
       "9716       4       4       0.4        5           2      4       1       1   \n",
       "9717       4       1       0.2        2          15      5       1       2   \n",
       "9718       3       1       0.2       15          10      2       4       2   \n",
       "9719       1       2       0.4       15          15      5       2       3   \n",
       "\n",
       "      FOREIGN3  CHOICE  \n",
       "0          0.2       1  \n",
       "1          0.3       2  \n",
       "2          0.2       3  \n",
       "3          0.2       2  \n",
       "4          0.2       2  \n",
       "...        ...     ...  \n",
       "9715       0.1       2  \n",
       "9716       0.1       3  \n",
       "9717       0.3       1  \n",
       "9718       0.3       1  \n",
       "9719       0.1       2  \n",
       "\n",
       "[9720 rows x 18 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and the output class\n",
    "X = df[['STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1',\n",
    "       'FOREIGN1', 'STORES2', 'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2',\n",
    "       'FOREIGN2', 'STORES3', 'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3',\n",
    "       'FOREIGN3', 'SSTADT', 'RESPCITY', 'WOMAN', 'AGE', 'ENVCONC']]\n",
    "\n",
    "# Define the output target\n",
    "Y = df['CHOICE']\n",
    "Y_cat = to_categorical(Y-1, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl (9720, 2, 3, 1)\n",
      "Shape of x_ann (9720, 17)\n"
     ]
    }
   ],
   "source": [
    "# Create x input for MNL layer, and rescale\n",
    "scale = 100 # We cannot just use the sklearn scaler here, as it is import for the interpretation later how the input data are scaled. \n",
    "\n",
    "x_mnl = np.array([[np.divide(X['STORES1'], scale), np.divide(X['FOREIGN1'], scale)],\n",
    "                  [np.divide(X['STORES2'], scale), np.divide(X['FOREIGN2'], scale)],\n",
    "                  [np.divide(X['STORES3'], scale), np.divide(X['FOREIGN3'], scale)]])\n",
    "x_mnl = np.swapaxes(x_mnl, 0, 2)\n",
    "x_mnl = np.expand_dims(x_mnl, 3)\n",
    "print('Shape of x_mnl', x_mnl.shape)\n",
    "\n",
    "# Create x input for ANN layer\n",
    "x_ann = np.array([[X['TRANSPORT1'], X['CITY1'], X['NOISE1'], X['GREEN1'], X['TRANSPORT2'], X['CITY2'], X['NOISE2'], X['GREEN2'], X['TRANSPORT3'], X['CITY3'], X['NOISE3'], X['GREEN3'], X['SSTADT'], X['RESPCITY'], X['WOMAN'], X['AGE'], X['ENVCONC']]])\n",
    "x_ann = np.squeeze(np.swapaxes(x_ann, 0, 2))\n",
    "\n",
    "# Rescale input for the ANN part\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(x_ann)  \n",
    "x_ann = scaler.transform(x_ann)  \n",
    "print('Shape of x_ann',x_ann.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of obervations in the data set =  9720\n",
      "Number of obervations in the training set   =  6318\n",
      "Number of obervations in the test set       =  3402\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training and test part\n",
    "X_mnl_train, X_mnl_test, Y_train, Y_test = train_test_split(x_mnl, Y_cat, random_state = 1, test_size = 0.35)\n",
    "X_ann_train, X_ann_test, Y_train, Y_test = train_test_split(x_ann, Y_cat, random_state = 1, test_size = 0.35)\n",
    "print('Total number of obervations in the data set = ', len(x_mnl))\n",
    "print('Number of obervations in the training set   = ', len(X_mnl_train))\n",
    "print('Number of obervations in the test set       = ', len(X_mnl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            90          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 140\n",
      "Trainable params: 140\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-2), metrics = [\"accuracy\"], loss = 'categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4287 - accuracy: 0.3121 - val_loss: 1.3609 - val_accuracy: 0.3101\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.3487 - accuracy: 0.3175 - val_loss: 1.2941 - val_accuracy: 0.3348\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2815 - accuracy: 0.3422 - val_loss: 1.2389 - val_accuracy: 0.3583\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2260 - accuracy: 0.3734 - val_loss: 1.1935 - val_accuracy: 0.3589\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.1804 - accuracy: 0.3758 - val_loss: 1.1562 - val_accuracy: 0.3574\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.1433 - accuracy: 0.3772 - val_loss: 1.1253 - val_accuracy: 0.3633\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1130 - accuracy: 0.3811 - val_loss: 1.0994 - val_accuracy: 0.3951\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.0878 - accuracy: 0.4123 - val_loss: 1.0775 - val_accuracy: 0.4265\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0667 - accuracy: 0.4387 - val_loss: 1.0587 - val_accuracy: 0.4518\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0488 - accuracy: 0.4647 - val_loss: 1.0427 - val_accuracy: 0.4738\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0336 - accuracy: 0.4873 - val_loss: 1.0289 - val_accuracy: 0.4835\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0206 - accuracy: 0.4973 - val_loss: 1.0172 - val_accuracy: 0.4974\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0096 - accuracy: 0.5109 - val_loss: 1.0073 - val_accuracy: 0.5115\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0002 - accuracy: 0.5250 - val_loss: 0.9988 - val_accuracy: 0.5259\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9921 - accuracy: 0.5412 - val_loss: 0.9916 - val_accuracy: 0.5335\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9851 - accuracy: 0.5486 - val_loss: 0.9852 - val_accuracy: 0.5341\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9788 - accuracy: 0.5491 - val_loss: 0.9795 - val_accuracy: 0.5312\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9731 - accuracy: 0.5461 - val_loss: 0.9742 - val_accuracy: 0.5356\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9677 - accuracy: 0.5481 - val_loss: 0.9691 - val_accuracy: 0.5364\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9625 - accuracy: 0.5518 - val_loss: 0.9641 - val_accuracy: 0.5403\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9575 - accuracy: 0.5519 - val_loss: 0.9591 - val_accuracy: 0.5461\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9525 - accuracy: 0.5582 - val_loss: 0.9543 - val_accuracy: 0.5520\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9476 - accuracy: 0.5641 - val_loss: 0.9494 - val_accuracy: 0.5511\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9428 - accuracy: 0.5663 - val_loss: 0.9447 - val_accuracy: 0.5517\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9381 - accuracy: 0.56 - 0s 49ms/step - loss: 0.9381 - accuracy: 0.5682 - val_loss: 0.9399 - val_accuracy: 0.5523\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9335 - accuracy: 0.5689 - val_loss: 0.9352 - val_accuracy: 0.5597\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9290 - accuracy: 0.5741 - val_loss: 0.9305 - val_accuracy: 0.5611\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9246 - accuracy: 0.5742 - val_loss: 0.9258 - val_accuracy: 0.5600\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9203 - accuracy: 0.5720 - val_loss: 0.9211 - val_accuracy: 0.5594\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9160 - accuracy: 0.5692 - val_loss: 0.9165 - val_accuracy: 0.5594\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9118 - accuracy: 0.5693 - val_loss: 0.9120 - val_accuracy: 0.5594\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9078 - accuracy: 0.5689 - val_loss: 0.9076 - val_accuracy: 0.5617\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9039 - accuracy: 0.5714 - val_loss: 0.9033 - val_accuracy: 0.5691\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9002 - accuracy: 0.5690 - val_loss: 0.8993 - val_accuracy: 0.5679\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8967 - accuracy: 0.5703 - val_loss: 0.8954 - val_accuracy: 0.5682\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8934 - accuracy: 0.5708 - val_loss: 0.8918 - val_accuracy: 0.5744\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8904 - accuracy: 0.5768 - val_loss: 0.8884 - val_accuracy: 0.5747\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8876 - accuracy: 0.5766 - val_loss: 0.8853 - val_accuracy: 0.5794\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8850 - accuracy: 0.5812 - val_loss: 0.8825 - val_accuracy: 0.5817\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8826 - accuracy: 0.5828 - val_loss: 0.8800 - val_accuracy: 0.5961\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8805 - accuracy: 0.5929 - val_loss: 0.8777 - val_accuracy: 0.6032\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8785 - accuracy: 0.5978 - val_loss: 0.8757 - val_accuracy: 0.6008\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8767 - accuracy: 0.5975 - val_loss: 0.8739 - val_accuracy: 0.6002\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8750 - accuracy: 0.5983 - val_loss: 0.8724 - val_accuracy: 0.6005\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8734 - accuracy: 0.5973 - val_loss: 0.8710 - val_accuracy: 0.6005\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8720 - accuracy: 0.5977 - val_loss: 0.8698 - val_accuracy: 0.5979\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8707 - accuracy: 0.5951 - val_loss: 0.8687 - val_accuracy: 0.5944\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8696 - accuracy: 0.5905 - val_loss: 0.8678 - val_accuracy: 0.5947\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8685 - accuracy: 0.5907 - val_loss: 0.8668 - val_accuracy: 0.5949\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8675 - accuracy: 0.5918 - val_loss: 0.8660 - val_accuracy: 0.5955\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8666 - accuracy: 0.5920 - val_loss: 0.8651 - val_accuracy: 0.5958\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8658 - accuracy: 0.5918 - val_loss: 0.8643 - val_accuracy: 0.5985\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8650 - accuracy: 0.5899 - val_loss: 0.8636 - val_accuracy: 0.5988\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8643 - accuracy: 0.5893 - val_loss: 0.8628 - val_accuracy: 0.5991\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8636 - accuracy: 0.5893 - val_loss: 0.8621 - val_accuracy: 0.5988\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8630 - accuracy: 0.5891 - val_loss: 0.8615 - val_accuracy: 0.5988\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8624 - accuracy: 0.5891 - val_loss: 0.8609 - val_accuracy: 0.5970\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8619 - accuracy: 0.5878 - val_loss: 0.8604 - val_accuracy: 0.5970\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8614 - accuracy: 0.5880 - val_loss: 0.8599 - val_accuracy: 0.5970\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8609 - accuracy: 0.5882 - val_loss: 0.8595 - val_accuracy: 0.5958\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8605 - accuracy: 0.5882 - val_loss: 0.8591 - val_accuracy: 0.5967\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8601 - accuracy: 0.5912 - val_loss: 0.8587 - val_accuracy: 0.5964\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8597 - accuracy: 0.5913 - val_loss: 0.8584 - val_accuracy: 0.5958\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8594 - accuracy: 0.5913 - val_loss: 0.8581 - val_accuracy: 0.5955\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8590 - accuracy: 0.5909 - val_loss: 0.8579 - val_accuracy: 0.5976\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8587 - accuracy: 0.5909 - val_loss: 0.8577 - val_accuracy: 0.6014\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8584 - accuracy: 0.5934 - val_loss: 0.8575 - val_accuracy: 0.6011\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8581 - accuracy: 0.5932 - val_loss: 0.8573 - val_accuracy: 0.6011\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8578 - accuracy: 0.5932 - val_loss: 0.8570 - val_accuracy: 0.6011\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8575 - accuracy: 0.5932 - val_loss: 0.8568 - val_accuracy: 0.6011\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8572 - accuracy: 0.5932 - val_loss: 0.8566 - val_accuracy: 0.6011\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8569 - accuracy: 0.5932 - val_loss: 0.8563 - val_accuracy: 0.6011\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8566 - accuracy: 0.5932 - val_loss: 0.8561 - val_accuracy: 0.6011\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8563 - accuracy: 0.5932 - val_loss: 0.8558 - val_accuracy: 0.6014\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8560 - accuracy: 0.5932 - val_loss: 0.8556 - val_accuracy: 0.6014\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8557 - accuracy: 0.5935 - val_loss: 0.8554 - val_accuracy: 0.6008\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8555 - accuracy: 0.5935 - val_loss: 0.8552 - val_accuracy: 0.6008\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8552 - accuracy: 0.5934 - val_loss: 0.8550 - val_accuracy: 0.6008\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8550 - accuracy: 0.5934 - val_loss: 0.8548 - val_accuracy: 0.6008\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8547 - accuracy: 0.5934 - val_loss: 0.8547 - val_accuracy: 0.6008\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8545 - accuracy: 0.5934 - val_loss: 0.8545 - val_accuracy: 0.6011\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8543 - accuracy: 0.5939 - val_loss: 0.8544 - val_accuracy: 0.6011\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8541 - accuracy: 0.5939 - val_loss: 0.8543 - val_accuracy: 0.6011\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8539 - accuracy: 0.5939 - val_loss: 0.8542 - val_accuracy: 0.6032\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8537 - accuracy: 0.5935 - val_loss: 0.8541 - val_accuracy: 0.6032\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8535 - accuracy: 0.5935 - val_loss: 0.8540 - val_accuracy: 0.6032\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8533 - accuracy: 0.5937 - val_loss: 0.8540 - val_accuracy: 0.6032\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8532 - accuracy: 0.5940 - val_loss: 0.8539 - val_accuracy: 0.6029\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8530 - accuracy: 0.5939 - val_loss: 0.8538 - val_accuracy: 0.6029\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8528 - accuracy: 0.5939 - val_loss: 0.8537 - val_accuracy: 0.6029\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8527 - accuracy: 0.5939 - val_loss: 0.8537 - val_accuracy: 0.6029\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8525 - accuracy: 0.5939 - val_loss: 0.8536 - val_accuracy: 0.6032\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8524 - accuracy: 0.5940 - val_loss: 0.8535 - val_accuracy: 0.6032\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8523 - accuracy: 0.5940 - val_loss: 0.8534 - val_accuracy: 0.6032\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8521 - accuracy: 0.5940 - val_loss: 0.8533 - val_accuracy: 0.6032\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8520 - accuracy: 0.5940 - val_loss: 0.8533 - val_accuracy: 0.6032\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8519 - accuracy: 0.5940 - val_loss: 0.8532 - val_accuracy: 0.6032\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8517 - accuracy: 0.5940 - val_loss: 0.8531 - val_accuracy: 0.6032\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8516 - accuracy: 0.5940 - val_loss: 0.8530 - val_accuracy: 0.6032\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8515 - accuracy: 0.5940 - val_loss: 0.8529 - val_accuracy: 0.6029\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8514 - accuracy: 0.5942 - val_loss: 0.8528 - val_accuracy: 0.6029\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8513 - accuracy: 0.5942 - val_loss: 0.8528 - val_accuracy: 0.6029\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8511 - accuracy: 0.5942 - val_loss: 0.8527 - val_accuracy: 0.6029\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8510 - accuracy: 0.5942 - val_loss: 0.8526 - val_accuracy: 0.6029\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8509 - accuracy: 0.5942 - val_loss: 0.8525 - val_accuracy: 0.6029\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8508 - accuracy: 0.5940 - val_loss: 0.8525 - val_accuracy: 0.6029\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8507 - accuracy: 0.5940 - val_loss: 0.8524 - val_accuracy: 0.6020\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8506 - accuracy: 0.5939 - val_loss: 0.8524 - val_accuracy: 0.6020\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8506 - accuracy: 0.5939 - val_loss: 0.8523 - val_accuracy: 0.6020\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8505 - accuracy: 0.5939 - val_loss: 0.8523 - val_accuracy: 0.6020\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8504 - accuracy: 0.5939 - val_loss: 0.8522 - val_accuracy: 0.6020\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8503 - accuracy: 0.5939 - val_loss: 0.8522 - val_accuracy: 0.6020\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8502 - accuracy: 0.5939 - val_loss: 0.8521 - val_accuracy: 0.6020\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8501 - accuracy: 0.5939 - val_loss: 0.8521 - val_accuracy: 0.6017\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8501 - accuracy: 0.5934 - val_loss: 0.8520 - val_accuracy: 0.6017\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8500 - accuracy: 0.5934 - val_loss: 0.8520 - val_accuracy: 0.6017\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8499 - accuracy: 0.5934 - val_loss: 0.8519 - val_accuracy: 0.6017\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8498 - accuracy: 0.5934 - val_loss: 0.8519 - val_accuracy: 0.6017\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8498 - accuracy: 0.5934 - val_loss: 0.8519 - val_accuracy: 0.6017\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8497 - accuracy: 0.5934 - val_loss: 0.8518 - val_accuracy: 0.6017\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8496 - accuracy: 0.5934 - val_loss: 0.8518 - val_accuracy: 0.6017\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8496 - accuracy: 0.5934 - val_loss: 0.8517 - val_accuracy: 0.6017\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8495 - accuracy: 0.5934 - val_loss: 0.8517 - val_accuracy: 0.6020\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8494 - accuracy: 0.5934 - val_loss: 0.8517 - val_accuracy: 0.6020\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8494 - accuracy: 0.5934 - val_loss: 0.8516 - val_accuracy: 0.6020\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8493 - accuracy: 0.5934 - val_loss: 0.8516 - val_accuracy: 0.6011\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8493 - accuracy: 0.5912 - val_loss: 0.8515 - val_accuracy: 0.6014\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8492 - accuracy: 0.5912 - val_loss: 0.8515 - val_accuracy: 0.6014\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8492 - accuracy: 0.5913 - val_loss: 0.8515 - val_accuracy: 0.6014\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8491 - accuracy: 0.5913 - val_loss: 0.8514 - val_accuracy: 0.6014\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8490 - accuracy: 0.5913 - val_loss: 0.8514 - val_accuracy: 0.6014\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8490 - accuracy: 0.5913 - val_loss: 0.8513 - val_accuracy: 0.6014\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8489 - accuracy: 0.5913 - val_loss: 0.8513 - val_accuracy: 0.6014\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8489 - accuracy: 0.5913 - val_loss: 0.8512 - val_accuracy: 0.6014\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8488 - accuracy: 0.5913 - val_loss: 0.8512 - val_accuracy: 0.6014\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8488 - accuracy: 0.5913 - val_loss: 0.8511 - val_accuracy: 0.6014\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8488 - accuracy: 0.5913 - val_loss: 0.8511 - val_accuracy: 0.6014\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8487 - accuracy: 0.5913 - val_loss: 0.8510 - val_accuracy: 0.6014\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8487 - accuracy: 0.5913 - val_loss: 0.8510 - val_accuracy: 0.6014\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8486 - accuracy: 0.5913 - val_loss: 0.8510 - val_accuracy: 0.6014\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8486 - accuracy: 0.5913 - val_loss: 0.8509 - val_accuracy: 0.6014\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8485 - accuracy: 0.5913 - val_loss: 0.8509 - val_accuracy: 0.6014\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8485 - accuracy: 0.5913 - val_loss: 0.8508 - val_accuracy: 0.6014\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8484 - accuracy: 0.5913 - val_loss: 0.8508 - val_accuracy: 0.6014\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8484 - accuracy: 0.5913 - val_loss: 0.8508 - val_accuracy: 0.6014\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8484 - accuracy: 0.5913 - val_loss: 0.8507 - val_accuracy: 0.6014\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8483 - accuracy: 0.5913 - val_loss: 0.8507 - val_accuracy: 0.6014\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8483 - accuracy: 0.5913 - val_loss: 0.8506 - val_accuracy: 0.6014\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8482 - accuracy: 0.5913 - val_loss: 0.8506 - val_accuracy: 0.6014\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8482 - accuracy: 0.5913 - val_loss: 0.8506 - val_accuracy: 0.5982\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8482 - accuracy: 0.5893 - val_loss: 0.8505 - val_accuracy: 0.5982\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8481 - accuracy: 0.5893 - val_loss: 0.8505 - val_accuracy: 0.5982\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8481 - accuracy: 0.5893 - val_loss: 0.8505 - val_accuracy: 0.5982\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8481 - accuracy: 0.5893 - val_loss: 0.8504 - val_accuracy: 0.5982\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8480 - accuracy: 0.5893 - val_loss: 0.8504 - val_accuracy: 0.5982\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8480 - accuracy: 0.5893 - val_loss: 0.8503 - val_accuracy: 0.5982\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8479 - accuracy: 0.5893 - val_loss: 0.8503 - val_accuracy: 0.5982\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8479 - accuracy: 0.5893 - val_loss: 0.8503 - val_accuracy: 0.5973\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8479 - accuracy: 0.5928 - val_loss: 0.8502 - val_accuracy: 0.5973\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8478 - accuracy: 0.5928 - val_loss: 0.8502 - val_accuracy: 0.5973\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8478 - accuracy: 0.5928 - val_loss: 0.8502 - val_accuracy: 0.5973\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8478 - accuracy: 0.5928 - val_loss: 0.8501 - val_accuracy: 0.5973\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8477 - accuracy: 0.5928 - val_loss: 0.8501 - val_accuracy: 0.5973\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8477 - accuracy: 0.5928 - val_loss: 0.8501 - val_accuracy: 0.5973\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8477 - accuracy: 0.5928 - val_loss: 0.8500 - val_accuracy: 0.5973\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8476 - accuracy: 0.5928 - val_loss: 0.8500 - val_accuracy: 0.5973\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8476 - accuracy: 0.5928 - val_loss: 0.8499 - val_accuracy: 0.5973\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8476 - accuracy: 0.5928 - val_loss: 0.8499 - val_accuracy: 0.5973\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8475 - accuracy: 0.5928 - val_loss: 0.8499 - val_accuracy: 0.5973\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8475 - accuracy: 0.5928 - val_loss: 0.8498 - val_accuracy: 0.5973\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8475 - accuracy: 0.5928 - val_loss: 0.8498 - val_accuracy: 0.5973\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8475 - accuracy: 0.5928 - val_loss: 0.8498 - val_accuracy: 0.5973\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8474 - accuracy: 0.5928 - val_loss: 0.8497 - val_accuracy: 0.5973\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8474 - accuracy: 0.5928 - val_loss: 0.8497 - val_accuracy: 0.5973\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8474 - accuracy: 0.5928 - val_loss: 0.8497 - val_accuracy: 0.5973\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8473 - accuracy: 0.5928 - val_loss: 0.8496 - val_accuracy: 0.5973\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8473 - accuracy: 0.5928 - val_loss: 0.8496 - val_accuracy: 0.5973\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8473 - accuracy: 0.5928 - val_loss: 0.8496 - val_accuracy: 0.5973\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8472 - accuracy: 0.5928 - val_loss: 0.8495 - val_accuracy: 0.5973\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8472 - accuracy: 0.5928 - val_loss: 0.8495 - val_accuracy: 0.5973\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8472 - accuracy: 0.5928 - val_loss: 0.8495 - val_accuracy: 0.5973\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8472 - accuracy: 0.5928 - val_loss: 0.8494 - val_accuracy: 0.5973\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8471 - accuracy: 0.5928 - val_loss: 0.8494 - val_accuracy: 0.5973\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8471 - accuracy: 0.5928 - val_loss: 0.8494 - val_accuracy: 0.5973\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8471 - accuracy: 0.5928 - val_loss: 0.8493 - val_accuracy: 0.6017\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8470 - accuracy: 0.5959 - val_loss: 0.8493 - val_accuracy: 0.6017\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8470 - accuracy: 0.5959 - val_loss: 0.8493 - val_accuracy: 0.6017\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8470 - accuracy: 0.5959 - val_loss: 0.8492 - val_accuracy: 0.6017\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8470 - accuracy: 0.5959 - val_loss: 0.8492 - val_accuracy: 0.6017\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8469 - accuracy: 0.5959 - val_loss: 0.8492 - val_accuracy: 0.6017\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8469 - accuracy: 0.5959 - val_loss: 0.8491 - val_accuracy: 0.6017\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8469 - accuracy: 0.5959 - val_loss: 0.8491 - val_accuracy: 0.6017\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8469 - accuracy: 0.5959 - val_loss: 0.8491 - val_accuracy: 0.6017\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8468 - accuracy: 0.5959 - val_loss: 0.8491 - val_accuracy: 0.6017\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8468 - accuracy: 0.5959 - val_loss: 0.8490 - val_accuracy: 0.6017\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8468 - accuracy: 0.5959 - val_loss: 0.8490 - val_accuracy: 0.6017\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8467 - accuracy: 0.5959 - val_loss: 0.8490 - val_accuracy: 0.6017\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8467 - accuracy: 0.5959 - val_loss: 0.8489 - val_accuracy: 0.6017\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8467 - accuracy: 0.5959 - val_loss: 0.8489 - val_accuracy: 0.6017\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8467 - accuracy: 0.5959 - val_loss: 0.8489 - val_accuracy: 0.6017\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8466 - accuracy: 0.5959 - val_loss: 0.8489 - val_accuracy: 0.6017\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8466 - accuracy: 0.5959 - val_loss: 0.8488 - val_accuracy: 0.6017\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8466 - accuracy: 0.5959 - val_loss: 0.8488 - val_accuracy: 0.6017\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8466 - accuracy: 0.5959 - val_loss: 0.8488 - val_accuracy: 0.6017\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8465 - accuracy: 0.5959 - val_loss: 0.8487 - val_accuracy: 0.6017\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8465 - accuracy: 0.5959 - val_loss: 0.8487 - val_accuracy: 0.6017\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8465 - accuracy: 0.5959 - val_loss: 0.8487 - val_accuracy: 0.6017\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8465 - accuracy: 0.5959 - val_loss: 0.8487 - val_accuracy: 0.5982\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8464 - accuracy: 0.5943 - val_loss: 0.8486 - val_accuracy: 0.5982\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8464 - accuracy: 0.5943 - val_loss: 0.8486 - val_accuracy: 0.5982\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8464 - accuracy: 0.5943 - val_loss: 0.8486 - val_accuracy: 0.5982\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8464 - accuracy: 0.5943 - val_loss: 0.8486 - val_accuracy: 0.5982\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8463 - accuracy: 0.5945 - val_loss: 0.8485 - val_accuracy: 0.5958\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8463 - accuracy: 0.5962 - val_loss: 0.8485 - val_accuracy: 0.5958\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8463 - accuracy: 0.5962 - val_loss: 0.8485 - val_accuracy: 0.5958\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8463 - accuracy: 0.59 - 0s 54ms/step - loss: 0.8463 - accuracy: 0.5962 - val_loss: 0.8485 - val_accuracy: 0.5958\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8462 - accuracy: 0.5962 - val_loss: 0.8484 - val_accuracy: 0.5958\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8462 - accuracy: 0.5962 - val_loss: 0.8484 - val_accuracy: 0.5958\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8462 - accuracy: 0.5962 - val_loss: 0.8484 - val_accuracy: 0.5958\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8462 - accuracy: 0.5962 - val_loss: 0.8484 - val_accuracy: 0.5958\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8462 - accuracy: 0.5962 - val_loss: 0.8483 - val_accuracy: 0.5958\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8461 - accuracy: 0.5962 - val_loss: 0.8483 - val_accuracy: 0.5958\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8461 - accuracy: 0.5962 - val_loss: 0.8483 - val_accuracy: 0.5958\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8461 - accuracy: 0.5962 - val_loss: 0.8483 - val_accuracy: 0.5958\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8461 - accuracy: 0.5962 - val_loss: 0.8483 - val_accuracy: 0.5958\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8482 - val_accuracy: 0.5958\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8482 - val_accuracy: 0.5958\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8482 - val_accuracy: 0.5958\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8482 - val_accuracy: 0.5958\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8481 - val_accuracy: 0.5958\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8459 - accuracy: 0.5962 - val_loss: 0.8481 - val_accuracy: 0.5958\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8459 - accuracy: 0.5962 - val_loss: 0.8481 - val_accuracy: 0.5958\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8459 - accuracy: 0.5962 - val_loss: 0.8481 - val_accuracy: 0.5958\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8459 - accuracy: 0.5962 - val_loss: 0.8481 - val_accuracy: 0.5958\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8458 - accuracy: 0.5962 - val_loss: 0.8480 - val_accuracy: 0.5958\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8458 - accuracy: 0.5962 - val_loss: 0.8480 - val_accuracy: 0.5964\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.59 - 0s 53ms/step - loss: 0.8458 - accuracy: 0.5964 - val_loss: 0.8480 - val_accuracy: 0.5964\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8458 - accuracy: 0.5972 - val_loss: 0.8480 - val_accuracy: 0.5964\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8458 - accuracy: 0.5972 - val_loss: 0.8480 - val_accuracy: 0.5964\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8457 - accuracy: 0.5972 - val_loss: 0.8479 - val_accuracy: 0.5964\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8457 - accuracy: 0.5972 - val_loss: 0.8479 - val_accuracy: 0.5964\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8457 - accuracy: 0.5972 - val_loss: 0.8479 - val_accuracy: 0.5964\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8457 - accuracy: 0.5972 - val_loss: 0.8479 - val_accuracy: 0.5964\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8457 - accuracy: 0.5972 - val_loss: 0.8479 - val_accuracy: 0.5958\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8456 - accuracy: 0.5970 - val_loss: 0.8478 - val_accuracy: 0.5958\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8456 - accuracy: 0.5970 - val_loss: 0.8478 - val_accuracy: 0.5958\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8456 - accuracy: 0.5970 - val_loss: 0.8478 - val_accuracy: 0.5958\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8456 - accuracy: 0.5970 - val_loss: 0.8478 - val_accuracy: 0.5958\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8455 - accuracy: 0.5970 - val_loss: 0.8478 - val_accuracy: 0.5958\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8455 - accuracy: 0.5970 - val_loss: 0.8477 - val_accuracy: 0.5958\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8455 - accuracy: 0.5970 - val_loss: 0.8477 - val_accuracy: 0.5958\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8455 - accuracy: 0.5970 - val_loss: 0.8477 - val_accuracy: 0.5885\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8455 - accuracy: 0.5994 - val_loss: 0.8477 - val_accuracy: 0.5885\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8477 - val_accuracy: 0.5885\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8474 - val_accuracy: 0.5885\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8474 - val_accuracy: 0.5885\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8474 - val_accuracy: 0.5885\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8474 - val_accuracy: 0.5885\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8451 - accuracy: 0.5994 - val_loss: 0.8474 - val_accuracy: 0.5885\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8451 - accuracy: 0.5994 - val_loss: 0.8474 - val_accuracy: 0.5885\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8451 - accuracy: 0.5994 - val_loss: 0.8473 - val_accuracy: 0.5885\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8451 - accuracy: 0.5994 - val_loss: 0.8473 - val_accuracy: 0.5885\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8451 - accuracy: 0.5994 - val_loss: 0.8473 - val_accuracy: 0.5885\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8451 - accuracy: 0.5994 - val_loss: 0.8473 - val_accuracy: 0.5885\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8450 - accuracy: 0.5994 - val_loss: 0.8473 - val_accuracy: 0.5917\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8450 - accuracy: 0.6040 - val_loss: 0.8473 - val_accuracy: 0.5917\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8450 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5917\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8450 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5917\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8450 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5917\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5917\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5917\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5920\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5920\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8469 - val_accuracy: 0.5920\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8469 - val_accuracy: 0.5920\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8446 - accuracy: 0.6040 - val_loss: 0.8469 - val_accuracy: 0.5920\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8446 - accuracy: 0.6040 - val_loss: 0.8469 - val_accuracy: 0.5920\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8446 - accuracy: 0.6040 - val_loss: 0.8469 - val_accuracy: 0.5920\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8446 - accuracy: 0.6040 - val_loss: 0.8469 - val_accuracy: 0.5920\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8446 - accuracy: 0.6040 - val_loss: 0.8469 - val_accuracy: 0.5920\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8446 - accuracy: 0.6040 - val_loss: 0.8468 - val_accuracy: 0.5920\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8445 - accuracy: 0.6040 - val_loss: 0.8468 - val_accuracy: 0.5920\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8445 - accuracy: 0.6040 - val_loss: 0.8468 - val_accuracy: 0.5920\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8445 - accuracy: 0.6040 - val_loss: 0.8468 - val_accuracy: 0.5941\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8445 - accuracy: 0.6067 - val_loss: 0.8468 - val_accuracy: 0.5944\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5949\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5949\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5949\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5949\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5949\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5949\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5949\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5949\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5949\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5949\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8442 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8442 - accuracy: 0.6064 - val_loss: 0.8465 - val_accuracy: 0.5947\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8442 - accuracy: 0.6064 - val_loss: 0.8465 - val_accuracy: 0.5947\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8442 - accuracy: 0.6064 - val_loss: 0.8465 - val_accuracy: 0.5947\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8442 - accuracy: 0.6064 - val_loss: 0.8465 - val_accuracy: 0.5947\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8442 - accuracy: 0.6064 - val_loss: 0.8465 - val_accuracy: 0.5947\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8442 - accuracy: 0.6064 - val_loss: 0.8465 - val_accuracy: 0.5947\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8441 - accuracy: 0.6064 - val_loss: 0.8465 - val_accuracy: 0.5947\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8441 - accuracy: 0.6064 - val_loss: 0.8465 - val_accuracy: 0.5947\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8441 - accuracy: 0.6064 - val_loss: 0.8465 - val_accuracy: 0.5947\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8441 - accuracy: 0.6064 - val_loss: 0.8464 - val_accuracy: 0.5947\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8441 - accuracy: 0.6064 - val_loss: 0.8464 - val_accuracy: 0.5952\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8441 - accuracy: 0.6067 - val_loss: 0.8464 - val_accuracy: 0.5938\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8441 - accuracy: 0.6081 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8441 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8437 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8437 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8437 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8437 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8437 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8437 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8437 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8437 - accuracy: 0.6091 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8437 - accuracy: 0.6091 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8436 - accuracy: 0.6091 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8436 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8436 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8436 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8436 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8436 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8436 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8436 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8436 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8436 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8435 - accuracy: 0.6089 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8435 - accuracy: 0.6098 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8434 - accuracy: 0.6098 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8434 - accuracy: 0.6098 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8434 - accuracy: 0.6098 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8434 - accuracy: 0.6098 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8434 - accuracy: 0.6098 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8434 - accuracy: 0.6098 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8434 - accuracy: 0.6098 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8434 - accuracy: 0.6098 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5935\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5935\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8433 - accuracy: 0.61 - 0s 55ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5935\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5935\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5935\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5935\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5935\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8456 - val_accuracy: 0.5938\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8431 - accuracy: 0.6100 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8430 - accuracy: 0.6100 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8430 - accuracy: 0.6100 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8430 - accuracy: 0.6100 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8430 - accuracy: 0.6100 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8430 - accuracy: 0.6100 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8430 - accuracy: 0.6100 - val_loss: 0.8455 - val_accuracy: 0.5935\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8430 - accuracy: 0.6098 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8430 - accuracy: 0.6098 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8430 - accuracy: 0.6098 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8430 - accuracy: 0.6098 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8430 - accuracy: 0.6098 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8430 - accuracy: 0.6098 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8430 - accuracy: 0.6097 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8430 - accuracy: 0.6097 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8430 - accuracy: 0.6097 - val_loss: 0.8455 - val_accuracy: 0.5938\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8429 - accuracy: 0.6097 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8429 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8428 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8427 - accuracy: 0.6089 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8427 - accuracy: 0.6091 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.843\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(patience = 4, monitor = 'val_loss')\n",
    "history = model.fit([X_mnl_train, X_ann_train],Y_train, batch_size=len(X_mnl_train), epochs = nEpoch, verbose = 1, validation_data = ([X_mnl_test, X_ann_test], Y_test), callbacks = [early_stopping])\n",
    "\n",
    "betas_layer = model.get_layer(name = 'MNL_layer')\n",
    "betas = betas_layer.get_weights()\n",
    "print('The cross-entropy on the test data of the tensor flow ANN is',\"{:.3f}\".format(history.history['loss'][-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss as a function of epochs\n",
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.ylim(0.8,1)\n",
    "\n",
    "# plot accuracy\n",
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label = 'test')\n",
    "plt.ylim(0, 0.8)\n",
    "plt.legend()\n",
    "\n",
    "# Tweak spacing between subplots to prevent labels from overlapping\n",
    "plt.subplots_adjust(hspace = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q4** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Compute the WtP of the average decision maker to reduce the share of foreigners in a neighbourhood by 1 percentage point using the results from the hybrid model. Compare the outcome with the results of your discrete choice model (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q5** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Explore whether, or not, the preferences of the inhabitants of the four cities regarding the trade-off between share of foreigners and distance to grocery stores are equal across the four cities. (1.5 pts)\n",
    "\n",
    "Perform a series of (clever) analyses, and interpret the findings. In other words, can we conclude that the inhabintants of all cities are equally xenophobic? For these analysis, use hybrid models, and/or DCMs.\n",
    "\n",
    "**Hint:** create new features capturing for the share of foreigners *per city*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q6** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cab132ea358786bca809bd44131ddd0564f8abae658fe95d8fa3ee53812826fd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
