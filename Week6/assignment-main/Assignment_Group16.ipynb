{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4305TU: Week 6 - Artificial Neural Network - Assignment\n",
    "## Investigating neighbourhood choice behaviour using ANNs\n",
    "**7 & 11 October 2021**\n",
    "\n",
    "- Sander van Cranenburgh\n",
    "- Francisco Garrido-Valenzuela "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information\n",
    "\n",
    "* For this assignment we will use *Stated Choice data* on residential location choice, collected in:\n",
    "    - Mainz, Germany\n",
    "    - Hanover, Germany\n",
    "    - Bern, Switzerland\n",
    "    - Zurich, Switzerland \n",
    "\n",
    "- For more details on the data, see the description provided on [Brightspace](https://brightspace.tudelft.nl/d2l/le/content/399675/viewContent/2506146/View). \n",
    "\n",
    "- In total you can earn **6.0** points in this assignment. \n",
    "\n",
    "- Add **Code cells** to complement your analyses. You can draw a lot form the snippets of codes we used for the in-class exercises.\n",
    "\n",
    "### Submission instructions\n",
    "\n",
    "- Answer the questions (code and/or text) in this notebook\n",
    "- Rename this file by adding your group nomber (e.g. Assignment_groupXX.ipynb)\n",
    "- Submit your answers both in ipynb and html format\n",
    "\n",
    "**Provide your answers in the allocated markdown boxes** (with the red font color)\n",
    "\n",
    "\n",
    "### Set up your environment\n",
    "\n",
    "You need to set up your environment based on which platform you would like to use. In this case we offer two options:\n",
    "\n",
    "- Google Colaboratory (Colab)\n",
    "- Jupyter Lab or Notebooks (Local)\n",
    "\n",
    "#### Using Colab\n",
    "\n",
    "Students using **Colab**, just need to install **Biogeme**. Biogeme is a Python package designed for the maximum likelihood estimation of parametric models in general, with a special emphasis on discrete choice models. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using Google Colab (keep the exclamation mark)\n",
    "#!pip install biogeme\n",
    "#!git clone https://github.com/cs4305tu/assignment\n",
    "#root = 'assignment/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using local environment\n",
    "\n",
    "Students using their *local environments*, need to install all the dependencies used in this *Week 6*, to ensure compatibility, they also need to check the versions of each dependency. All dependencies are contained in the text file: **requirements.txt**. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using your local environment (keep the exclamation mark)\n",
    "# !pip3 install -r requirements.txt\n",
    "# root = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Python packages\n",
    "\n",
    "In the following cell add all the packages you need to finish this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow  2.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from heatmap import corrplot\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.database as db\n",
    "import biogeme.optimization as opt\n",
    "import biogeme.messaging as msg\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Using tensorflow \",tf.__version__)\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import ML packaged and modules\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID2</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>SSTADT</th>\n",
       "      <th>RESPCITY</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ENVCONC</th>\n",
       "      <th>COMPLETE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  ID2  STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  \\\n",
       "0   2    5       10           5      1       2       2       0.4       15   \n",
       "1   2    6       15           5      4       4       1       0.1        2   \n",
       "2   2    7       10          15      1       3       1       0.4       15   \n",
       "3   2    8       15          15      5       4       4       0.4        2   \n",
       "4   3    9       15           5      5       1       3       0.4        2   \n",
       "\n",
       "   TRANSPORT2  ...  NOISE3  GREEN3  FOREIGN3  CHOICE  SSTADT  RESPCITY  WOMAN  \\\n",
       "0          10  ...       4       4       0.2       1       3         3      0   \n",
       "1          10  ...       2       3       0.3       2       3         3      0   \n",
       "2           2  ...       1       3       0.2       3       3         3      0   \n",
       "3           2  ...       2       2       0.2       2       3         3      0   \n",
       "4          10  ...       3       1       0.2       2       2         2      1   \n",
       "\n",
       "   AGE  ENVCONC  COMPLETE  \n",
       "0   42      3.0         1  \n",
       "1   42      3.0         1  \n",
       "2   42      3.0         1  \n",
       "3   42      3.0         1  \n",
       "4   41      4.5         1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a dataframe\n",
    "root = ''\n",
    "df_raw = pd.read_csv(f'{root}datasets/neighbourhood_choice2018.dat', sep='\\t')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Do a proper descriptive analysis of the data set (1.0 pt)\n",
    "\n",
    "It is good practice to do a descriptive analysis of the data you want to model, prior to the real modelling. So inspect e.g. what levels the attributes (features) take, correlations, class (im)balances, redudant variables, missing values, etc. to attain a good feeling for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice features are: ['STORES', 'TRANSPORT', 'CITY', 'NOISE', 'GREEN', 'FOREIGN']\n",
      "Other available features are: ['WOMAN', 'AGE', 'SSTADT', 'RESPCITY', 'ENVCONC']\n",
      "The evaluation metric is ['CHOICE']\n",
      "\n",
      "Total number of Nan values: 0\n",
      "Total number of empty (None) values: 0\n",
      "Total number of incomplete responses: 0\n",
      "\n",
      "Check the levels that each feature can take:\n",
      "Choice features:\n",
      "\tSTORES can take: [ 2  5 10 15]\n",
      "\tTRANSPORT can take: [ 2  5 10 15]\n",
      "\tCITY can take: [1 2 4 5]\n",
      "\tNOISE can take: [1 2 3 4]\n",
      "\tGREEN can take: [1 2 3 4]\n",
      "\tFOREIGN can take: [0.1 0.2 0.3 0.4]\n",
      "Other features\n",
      "\tWOMAN can take: [    0     1 99999]\n",
      "\tAGE can take: [   18    19    20    21    22    23    24    25    26    27    28    29\n",
      "    30    31    32    33    34    35    36    37    38    39    40    41\n",
      "    42    43    44    45    46    47    48    49    50    51    52    53\n",
      "    54    55    56    57    58    59    60    61    62    63    64    65\n",
      "    66    67    68    69    70 99999]\n",
      "\tSSTADT can take: [1 2 3 4]\n",
      "\tRESPCITY can take: [1 2 3 4]\n",
      "\tENVCONC can take: [1.00000000e+00 1.16666663e+00 1.33333337e+00 1.50000000e+00\n",
      " 1.66666663e+00 1.83333337e+00 2.00000000e+00 2.16666675e+00\n",
      " 2.33333325e+00 2.50000000e+00 2.66666675e+00 2.83333325e+00\n",
      " 3.00000000e+00 3.16666675e+00 3.33333325e+00 3.50000000e+00\n",
      " 3.66666675e+00 3.75000000e+00 3.83333325e+00 4.00000000e+00\n",
      " 4.16666651e+00 4.33333349e+00 4.50000000e+00 4.66666651e+00\n",
      " 4.75000000e+00 4.83333349e+00 5.00000000e+00 9.99990000e+04]\n",
      "\n",
      "Total number of 99999 values in AGE: 64\n",
      "Total number of 99999 values in WOMAN: 20\n",
      "Total number of 9.99990000e+04 values in ENVCONC: 188\n",
      "\n",
      "Rows containing faulty values are removed in \"df\"\n"
     ]
    }
   ],
   "source": [
    "# All features in dataset, devided into the choice feature, and additional feaures.\n",
    "features_choices = ['STORES', 'TRANSPORT', 'CITY', 'NOISE', 'GREEN', 'FOREIGN']\n",
    "features_other = ['WOMAN', 'AGE', 'SSTADT', 'RESPCITY', 'ENVCONC']\n",
    "print(f'The choice features are: {features_choices}')\n",
    "print(f'Other available features are: {features_other}')\n",
    "print(f\"The evaluation metric is ['CHOICE']\")\n",
    "\n",
    "# Check for Nan values in dataset\n",
    "print(f'\\nTotal number of Nan values: {df_raw.isna().sum().sum()}')\n",
    "# Check for empty (None) values in dataset\n",
    "print(f'Total number of empty (None) values: {int(df_raw[df_raw==None].sum().sum())}')\n",
    "# Check for complete responses\n",
    "print(f'Total number of incomplete responses: {df_raw.COMPLETE[df_raw.COMPLETE==0].sum()}')\n",
    "\n",
    "# Check the various levels that each feature can take\n",
    "print('\\nCheck the levels that each feature can take:')\n",
    "print('Choice features:')\n",
    "for feature in features_choices:\n",
    "    feature_choice = [feature+str(choice) for choice in range(1, 4)]\n",
    "    levels = np.unique(df_raw[feature_choice].to_numpy().flatten())\n",
    "    print(f\"\\t{feature} can take: {levels}\")\n",
    "print('Other features')\n",
    "for feature in features_other:\n",
    "    levels = np.unique(df_raw[feature].to_numpy().flatten())\n",
    "    print(f\"\\t{feature} can take: {levels}\")\n",
    "\n",
    "# Check for faulty values\n",
    "print(f'\\nTotal number of 99999 values in AGE: {df_raw.AGE[df_raw.AGE==99999].size}')\n",
    "print(f'Total number of 99999 values in WOMAN: {df_raw.WOMAN[df_raw.WOMAN==99999].size}')\n",
    "print(f'Total number of 9.99990000e+04 values in ENVCONC: {df_raw.ENVCONC[df_raw.ENVCONC==9.99990000e+04].size}')\n",
    "# Remove faulty values\n",
    "df = df_raw[(df_raw.WOMAN != 99999) & (df_raw.AGE != 99999) & (df_raw.ENVCONC != 99990000e+04)]\n",
    "print(f'\\nRows containing faulty values are removed in \"df\"')\n",
    "\n",
    "# Remove irrelevant features\n",
    "df = df.drop(['ID', 'ID2', 'COMPLETE'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of choices: 9656\n",
      "--------------------------------\n",
      "\t Number of choices equal to 1: 3419 --> 35.41% of total\n",
      "\t Number of choices equal to 2: 3246 --> 33.62% of total\n",
      "\t Number of choices equal to 3: 2991 --> 30.98% of total\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show how often each alternative is chosen\n",
    "print(f\"Total number of choices: {len(df.CHOICE)}\")\n",
    "print('--------------------------------')\n",
    "for choice in range(1, 4):\n",
    "    print(f\"\\t Number of choices equal to {choice}: {len(df.CHOICE[df.CHOICE == choice])} --> {round(len(df.CHOICE[df.CHOICE == choice])/len(df.CHOICE)*100, 2)}% of total\")\n",
    "\n",
    "fig=plt.figure(figsize=(6,4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.hist(df.CHOICE, bins = [0.75, 1.25, 1.75, 2.25, 2.75, 3.25])\n",
    "plt.xticks((1, 2, 3))\n",
    "plt.title('Number of choices per alternative')\n",
    "plt.xlabel('Choice')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of each feature to CHOICE, sorted by absolute value:\n",
      "CHOICE        1.000000\n",
      "GREEN1        0.269395\n",
      "NOISE1        0.235075\n",
      "GREEN3        0.222014\n",
      "NOISE3        0.217443\n",
      "TRANSPORT1    0.196445\n",
      "TRANSPORT3    0.187104\n",
      "NOISE2        0.168003\n",
      "CITY3         0.165390\n",
      "CITY1         0.154733\n",
      "TRANSPORT2    0.094403\n",
      "FOREIGN1      0.094172\n",
      "STORES3       0.079956\n",
      "CITY2         0.068386\n",
      "FOREIGN3      0.062488\n",
      "STORES1       0.059513\n",
      "FOREIGN2      0.049579\n",
      "GREEN2        0.025982\n",
      "AGE           0.014812\n",
      "WOMAN         0.011703\n",
      "SSTADT        0.010152\n",
      "RESPCITY      0.010152\n",
      "ENVCONC       0.004726\n",
      "STORES2       0.000912\n",
      "Name: CHOICE, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain correlations\n",
    "all_features = list(df.columns[df.columns!='CHOICE'])\n",
    "\n",
    "# get choice as first input\n",
    "corr = df[['CHOICE'] + all_features].corr()\n",
    "corr_choice = corr['CHOICE']\n",
    "abs_corr_sorted = corr_choice.abs().sort_values(ascending=False)     # sorted by largest correlation to income\n",
    "\n",
    "print('Correlation of each feature to CHOICE, sorted by absolute value:')\n",
    "print(abs_corr_sorted)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "corrplot(corr, size_scale=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reduced dataframe \"df_reduced\" of shape (9656, 19):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>GREEN2</th>\n",
       "      <th>FOREIGN2</th>\n",
       "      <th>STORES3</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  TRANSPORT2  \\\n",
       "0       10           5      1       2       2       0.4       15          10   \n",
       "1       15           5      4       4       1       0.1        2          10   \n",
       "2       10          15      1       3       1       0.4       15           2   \n",
       "3       15          15      5       4       4       0.4        2           2   \n",
       "4       15           5      5       1       3       0.4        2          10   \n",
       "\n",
       "   CITY2  NOISE2  GREEN2  FOREIGN2  STORES3  TRANSPORT3  CITY3  NOISE3  \\\n",
       "0      2       3       3       0.1        2          15      4       4   \n",
       "1      5       1       2       0.2        5          15      1       2   \n",
       "2      2       4       2       0.1        2           5      4       1   \n",
       "3      1       1       1       0.1        5           5      2       2   \n",
       "4      1       2       4       0.1        5          15      2       3   \n",
       "\n",
       "   GREEN3  FOREIGN3  CHOICE  \n",
       "0       4       0.2       1  \n",
       "1       3       0.3       2  \n",
       "2       3       0.2       3  \n",
       "3       2       0.2       2  \n",
       "4       1       0.2       2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final complete dataframe \"df\" of shape (9656, 23):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>...</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>SSTADT</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ENVCONC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  TRANSPORT2  \\\n",
       "0       10           5      1       2       2       0.4       15          10   \n",
       "1       15           5      4       4       1       0.1        2          10   \n",
       "2       10          15      1       3       1       0.4       15           2   \n",
       "3       15          15      5       4       4       0.4        2           2   \n",
       "4       15           5      5       1       3       0.4        2          10   \n",
       "\n",
       "   CITY2  NOISE2  ...  TRANSPORT3  CITY3  NOISE3  GREEN3  FOREIGN3  CHOICE  \\\n",
       "0      2       3  ...          15      4       4       4       0.2       1   \n",
       "1      5       1  ...          15      1       2       3       0.3       2   \n",
       "2      2       4  ...           5      4       1       3       0.2       3   \n",
       "3      1       1  ...           5      2       2       2       0.2       2   \n",
       "4      1       2  ...          15      2       3       1       0.2       2   \n",
       "\n",
       "   SSTADT  WOMAN  AGE  ENVCONC  \n",
       "0       3      0   42      3.0  \n",
       "1       3      0   42      3.0  \n",
       "2       3      0   42      3.0  \n",
       "3       3      0   42      3.0  \n",
       "4       2      1   41      4.5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove additional attributes\n",
    "df_reduced = df.drop(features_other, axis=1)\n",
    "print(f'Final reduced dataframe \"df_reduced\" of shape {df_reduced.shape}:')\n",
    "display(df_reduced.head())\n",
    "\n",
    "# Remove irrelevant labels\n",
    "df = df.drop(['RESPCITY'], axis=1)\n",
    "print(f'Final complete dataframe \"df\" of shape {df.shape}:')\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q1** <br>\n",
    "The dataset is seen to consist out of two main set of features. The first set is the various 'choice features' available for each of the three choices; and the second set consist of 'other features', which contain information regarding the applicant, e.g.: age, woman (yes or no), place of citizenship.\n",
    "\n",
    "Considering all the available data, the dataset is checked for Nan and empty values. It is found that none of these input types are present. It is also checked whether all choices are complete, which is done by evaluation the COMPLETE feature. This is also found to be true for all choices. Furthermore, the features ID, ID2, and COMPLETE are removed as they are not used any further in this assignment.\n",
    "\n",
    "Then, the type of levels each feature can take-on are obtained. For the choice features, no irrelevant/faulty levels are seen to exist in the dataset. For the 'other features', it can be seen that WOMAN, AGE, and ENVCONC, contain irrelevant/faulty levels, equal to 99999. The number of occurances of these irrelevant levels are obtained for the three features. As this turns out to be a relatively low number, the rows containing faulty values are removed.\n",
    "\n",
    "Furthermore, the data is seen to be nicely balanced, with a distribution of 35.41%, 33.62%, and 30.98%, for the three choices, respectively.\n",
    "\n",
    "Finally, the correlations for all features to the CHOICE are constructed. These correlations are plotted, from which it can be seen that the 'other features' (AGE, WOMAN, SSTADT, RESPCITY, ENVCONC) and STORES2 have a low correlation to the CHOICE. Since the DCM does not use the 'other features', no features have to be removed. The ANN does use all features, including the low-correlated features. As the ANN is able to capture more complex relations it is still found useful to use all features.\n",
    "\n",
    "Furthermore, the correlation plot shows that SSTADT and RESPCITY are the same feature, correlated with 1. RESPCITY can therefore be removed from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Estimate a RUM-MNL discrete choice model (1.0 pt)\n",
    "\n",
    "Assume utility is linear additive-utility: \n",
    "\n",
    "$ V_{in} = \\sum_{m}\\beta_m x_{imn}$\n",
    "\n",
    "And estimate marginal utilities (i.e. betas) for: \n",
    "\n",
    "1. Distance to Transport [min] (**Note** that distances are given in minutes)\n",
    "2. Distance to City [km]\n",
    "3. Distance to Stores [min] (**Note** that distances are given in minutes)\n",
    "4. Traffic Noise\n",
    "5. Green area\n",
    "6. Share of foreigners [%]\n",
    "\n",
    "**Note:** Do not add any other variables (features) to the model.\n",
    "\n",
    "**To get the scores, address the following:**\n",
    "\n",
    "- (A) Report the parameter estimates, and interpret them. i.e. do they have the expected sign? (0.5 pts)\n",
    "- (B) Compute and report the cross-entropy (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with pandas and database variable for Biogeme estimation\n",
    "database = db.Database('residential_choicedata2021', df_reduced)\n",
    "\n",
    "# The following statement allows you to use the names of the variable stored in Biogeme as Python variables.\n",
    "globals().update(database.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_stores = Beta('B_stores', 0, None, None, 0)\n",
    "B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "B_city = Beta('B_city', 0, None, None, 0)\n",
    "B_noise = Beta('B_noise', 0, None, None, 0)\n",
    "B_green = Beta('B_green', 0, None, None, 0)\n",
    "B_foreign = Beta('B_foreign', 0, None, None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate utility functions with the numbering of alternatives in df.CHOICE\n",
    "V = {1: V1, 2: V2, 3: V3}\n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "av = {1:1, 2:1, 3:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters\n",
      "----------\n",
      "                Value   Std err     t-test  p-value\n",
      "B_city      -0.168094  0.007977 -21.072663      0.0\n",
      "B_foreign   -1.173841  0.109769 -10.693729      0.0\n",
      "B_green      0.416031  0.011653  35.701378      0.0\n",
      "B_noise     -0.438004  0.011379 -38.490741      0.0\n",
      "B_stores    -0.034612  0.002586 -13.386340      0.0\n",
      "B_transport -0.073980  0.002556 -28.944421      0.0\n"
     ]
    }
   ],
   "source": [
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "prob = models.loglogit(V, av, CHOICE)\n",
    "\n",
    "# Create the Biogeme object\n",
    "biogeme = bio.BIOGEME(database, prob)\n",
    "biogeme.modelName = 'My first discrete choice model'\n",
    "biogeme.generatePickle = False\n",
    "biogeme.generateHtml = False\n",
    "\n",
    "# Calculate the null log likelihood for reporting.\n",
    "biogeme.calculateNullLoglikelihood(av)\n",
    "\n",
    "# Estimate the parameters\n",
    "results1 = biogeme.estimate()\n",
    "\n",
    "# Report the results in a pandas table\n",
    "print('Estimated parameters')\n",
    "print('----------')\n",
    "pandasResults = results1.getEstimatedParameters()\n",
    "print(pandasResults[['Value','Std err','t-test','p-value']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-entropy of the DCM is         0.889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Get the estimated betas from the discrete choice model\n",
    "betas1 = results1.getBetaValues()\n",
    "\n",
    "# Define compute objects\n",
    "prob_1 = models.logit(V, av, 1)\n",
    "prob_2 = models.logit(V, av, 2)\n",
    "prob_3 = models.logit(V, av, 3)\n",
    "\n",
    "# Define dictionary\n",
    "simulate_dict = {\n",
    "    'Prob_1': prob_1,\n",
    "    'Prob_2': prob_2,\n",
    "    'Prob_3': prob_3}\n",
    "\n",
    "# Create Biogeme object\n",
    "simulator = bio.BIOGEME(database, simulate_dict)\n",
    "\n",
    "# Compute probabilities using the estimated choice model\n",
    "probs_DCM = simulator.simulate(betas1)\n",
    "\n",
    "# Compute the cross-entropy for the DCM\n",
    "cross_entropy_DCM = log_loss(df_reduced.CHOICE, probs_DCM)\n",
    "\n",
    "print('The cross-entropy of the DCM is        ',\"{:.3f}\".format(cross_entropy_DCM))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q2** <br>\n",
    "The signs make sense as people in general want to be close to things as the city, stores and transport. Also they want less foreigners in their neighbourhood and less noise from traffic. They do want more green in their neighboorhood. \n",
    "We can see that people attach most value to not having a lot of foreigners close to their home and less to the other properties. After that green and noise are most important. \n",
    "    \n",
    "<br> The cross-entropy measures the performance of a classification model. The cross-entropy increases as the predicted probability diverges from the actual label. A perfect model would have a cross-entropy of 0, so minimization of the cross-entropy leads to optimization of the model. In the situation above we have found a cross-entropy of 0.889, which is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Based on your results, compute the WtP of the average decision maker to reduce the share of foreigners in a neighbourhood by 1 percentage point in terms of the distance to the grocery stores (0.5 pts)\n",
    "\n",
    "Thus, the answer must be of the following form: .... [minutes/percentage point].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Willingness-to-Pay estimates\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  33.91 min per percentage point\n"
     ]
    }
   ],
   "source": [
    "## Wtp for less foreigners in a neighbourhood compared to distance to grocery stores. So B_foreign/B_stores\n",
    "# Get the results in a pandas table\n",
    "print('Willingness-to-Pay estimates')\n",
    "print('----------')\n",
    "WtP_foreign_stores = betas1['B_foreign']/betas1['B_stores']\n",
    "\n",
    "print('Willingness to Pay; reduction in foreigners at an expense of store distance = ', \"{:.2f}\".format(WtP_foreign_stores),'min per percentage point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q3** <br>\n",
    "We could see from the beta-values already that people don't attach a lot of value to a short distance towards grocery stores (beta = -0.034432), while they do think a lower percentage of foreigners is important (beta = -1.195431). We can see from the Willingness-to-pay that for every percentage of less foreigners, people are willing to add 34.7 min to the walking distance towards the nearest grocery store. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Train a hybrid RUM-MNL-ANN model (1.5 pts)\n",
    "\n",
    "Since we are interested in the WtP of Q3, make sure when building the hybrid model to place the features of the share of foreigners and of the distance to the grocery stores in the *MNL part of the model*. For the *ANN part of the model* use 2 hidden layers, with 5 nodes each. \n",
    "\n",
    "\n",
    "**To get the scores, address the following:**\n",
    "\n",
    "\n",
    "- (A) Build the model, plot the loss as a function of the epochs & report the cross entropy of your final model based on the test data. (1.0 pt)\n",
    "- (B) Compare the model performance to that of the discrete choice model. Interpret the result. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_RUM_MNL_ANN_model(NALT, no_X_MNL, no_X_ANN, num_nodes, seed=None):\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    #######################\n",
    "    ### DEFINE MNL PART ###\n",
    "    #######################\n",
    "    # INPUT FOR MNL PART\n",
    "    X_MNL = Input((no_X_MNL, NALT, 1), name = 'Features2MNL')\n",
    "\n",
    "    # COMPUTE UTILITY FOR MNL\n",
    "    V_MNL = Conv2D(filters = 1, kernel_size = [no_X_MNL,1], strides = (1,1), padding = 'valid', name = 'MNL_layer', use_bias = False, trainable = True)(X_MNL)\n",
    "\n",
    "    #######################\n",
    "    ### DEFINE ANN PART ###\n",
    "    #######################\n",
    "    # INPUT FOR ANN PART\n",
    "    X_ANN = Input((no_X_ANN), name ='Features2ANN')\n",
    "\n",
    "    # CREATE HIDDEN LAYER(S) OF ANN\n",
    "    layer1_ANN = Dense(units = num_nodes, name = \"ANN_layer1\", use_bias = True)(X_ANN) \n",
    "    layer2_ANN = Dense(units = num_nodes, name = \"ANN_layer2\", use_bias = True)(layer1_ANN)\n",
    "\n",
    "    # COMPUTE UTILITY FOR ANN \n",
    "    V_ANN = Dense(units = NALT, name = \"V_ANN\")(layer2_ANN) \n",
    "\n",
    "    ####################\n",
    "    ### DEFINE MODEL ###\n",
    "    ####################\n",
    "    # RESHAPE TENSORS TO [1 X NALT]\n",
    "    V_MNL = Reshape([NALT], name = 'Flatten_Dim_MNL')(V_MNL)\n",
    "    V_ANN = Reshape([NALT], name = 'Flatten_Dim_ANN')(V_ANN) \n",
    "\n",
    "    # SUM THE UTILITIES OF BOTH MODEL PARTS\n",
    "    V_MNL_ANN = Add(name = \"Combining_Vs\")([V_MNL,V_ANN])\n",
    "\n",
    "    # CREATE LOGIT (AKA SOFTMAX ) OUTPUT LAYER\n",
    "    logits = Activation('softmax', name = 'Probability')(V_MNL_ANN)\n",
    "\n",
    "    # BUILD THE MODEL\n",
    "    model = Model(inputs = [X_MNL, X_ANN], outputs = logits)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NALT = 3                                            # Number of alterantives in the data set.\n",
    "no_X_MNL = 2                                        # Number of attributes with behavioural interest (-->MNL model part).  In this example we are particularly interested in the WtP for extra storage space --> Cost & Storage\n",
    "no_X_ANN = (df.columns.size - 1) - NALT*no_X_MNL    # Number of features without behavioural interest (-->ANN model part). In this example we are not behaviourall interested in Camera, Size, and the socio demographic variables\n",
    "num_nodes = 5                                       # Number of nodes in hidden layer(s). Again we use 2 hidden layers with *num_nodes* nodes each\n",
    "nEpoch = 500                                        # Number epochs for training (max). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ANN_data(X, Y):\n",
    "    Y_cat = to_categorical(Y-1, num_classes = 3)\n",
    "\n",
    "    # Create x input for MNL layer, and rescale\n",
    "    scale = 1 # We cannot just use the sklearn scaler here, as it is import for the interpretation later how the input data are scaled. \n",
    "    x_mnl = np.array([[np.divide(X['STORES1'], scale), np.divide(X['FOREIGN1'], scale)],\n",
    "                      [np.divide(X['STORES2'], scale), np.divide(X['FOREIGN2'], scale)],\n",
    "                      [np.divide(X['STORES3'], scale), np.divide(X['FOREIGN3'], scale)]])\n",
    "    x_mnl = np.swapaxes(x_mnl, 0, 2)\n",
    "    x_mnl = np.expand_dims(x_mnl, 3)\n",
    "    print('Shape of x_mnl', x_mnl.shape)\n",
    "\n",
    "    # Create x input for ANN layer\n",
    "    x_ann = np.array([[X['TRANSPORT1'], X['CITY1'], X['NOISE1'], X['GREEN1'], X['TRANSPORT2'], X['CITY2'], X['NOISE2'], X['GREEN2'], X['TRANSPORT3'], X['CITY3'], X['NOISE3'], X['GREEN3'], X['SSTADT'], X['WOMAN'], X['AGE'], X['ENVCONC']]])\n",
    "    x_ann = np.squeeze(np.swapaxes(x_ann, 0, 2))\n",
    "\n",
    "    # Rescale input for the ANN part\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(x_ann)  \n",
    "    x_ann = scaler.transform(x_ann)  \n",
    "    print('Shape of x_ann',x_ann.shape)\n",
    "    return x_mnl, x_ann, Y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl (9656, 2, 3, 1)\n",
      "Shape of x_ann (9656, 16)\n",
      "\n",
      "Total number of obervations in the data set =  9656\n",
      "Number of obervations in the training set   =  6276\n",
      "Number of obervations in the test set       =  3380\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training and test part\n",
    "X = df.drop(['CHOICE'], axis=1)\n",
    "Y = df['CHOICE']\n",
    "x_mnl, x_ann, Y_cat = preprocess_ANN_data(X, Y)\n",
    "\n",
    "X_mnl_train, X_mnl_test, Y_train, Y_test = train_test_split(x_mnl, Y_cat, random_state = 1, test_size = 0.35)\n",
    "X_ann_train, X_ann_test, Y_train, Y_test = train_test_split(x_ann, Y_cat, random_state = 1, test_size = 0.35)\n",
    "print('\\nTotal number of obervations in the data set = ', len(x_mnl))\n",
    "print('Number of obervations in the training set   = ', len(X_mnl_train))\n",
    "print('Number of obervations in the test set       = ', len(X_mnl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 19:11:07.388565: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 19:11:07.626362: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 2.4728 - accuracy: 0.4144 - val_loss: 2.4094 - val_accuracy: 0.4053\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 2.3725 - accuracy: 0.4181 - val_loss: 2.3176 - val_accuracy: 0.4059\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 2.2787 - accuracy: 0.4192 - val_loss: 2.2306 - val_accuracy: 0.4065\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 2.1900 - accuracy: 0.4210 - val_loss: 2.1482 - val_accuracy: 0.4107\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.1062 - accuracy: 0.4242 - val_loss: 2.0701 - val_accuracy: 0.4213\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.0272 - accuracy: 0.4304 - val_loss: 1.9966 - val_accuracy: 0.4293\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.9529 - accuracy: 0.4359 - val_loss: 1.9276 - val_accuracy: 0.4393\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.8836 - accuracy: 0.4402 - val_loss: 1.8634 - val_accuracy: 0.4432\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.8193 - accuracy: 0.4426 - val_loss: 1.8040 - val_accuracy: 0.4473\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.7601 - accuracy: 0.4517 - val_loss: 1.7493 - val_accuracy: 0.4565\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7059 - accuracy: 0.4611 - val_loss: 1.6989 - val_accuracy: 0.4651\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6564 - accuracy: 0.4704 - val_loss: 1.6524 - val_accuracy: 0.4725\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.6108 - accuracy: 0.4772 - val_loss: 1.6090 - val_accuracy: 0.4805\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.5686 - accuracy: 0.4836 - val_loss: 1.5682 - val_accuracy: 0.4899\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.5290 - accuracy: 0.4917 - val_loss: 1.5295 - val_accuracy: 0.4938\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4917 - accuracy: 0.4970 - val_loss: 1.4926 - val_accuracy: 0.4962\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4562 - accuracy: 0.5037 - val_loss: 1.4572 - val_accuracy: 0.4982\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4222 - accuracy: 0.5078 - val_loss: 1.4230 - val_accuracy: 0.5006\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3894 - accuracy: 0.5080 - val_loss: 1.3897 - val_accuracy: 0.5038\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3576 - accuracy: 0.5089 - val_loss: 1.3573 - val_accuracy: 0.5068\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3266 - accuracy: 0.5108 - val_loss: 1.3257 - val_accuracy: 0.5089\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2965 - accuracy: 0.5145 - val_loss: 1.2949 - val_accuracy: 0.5107\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2672 - accuracy: 0.5172 - val_loss: 1.2651 - val_accuracy: 0.5115\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.2389 - accuracy: 0.5231 - val_loss: 1.2363 - val_accuracy: 0.5133\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2115 - accuracy: 0.5274 - val_loss: 1.2086 - val_accuracy: 0.5148\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1853 - accuracy: 0.5322 - val_loss: 1.1820 - val_accuracy: 0.5180\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1601 - accuracy: 0.5335 - val_loss: 1.1564 - val_accuracy: 0.5207\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1360 - accuracy: 0.5374 - val_loss: 1.1320 - val_accuracy: 0.5272\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.1130 - accuracy: 0.5405 - val_loss: 1.1088 - val_accuracy: 0.5337\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.0911 - accuracy: 0.5451 - val_loss: 1.0869 - val_accuracy: 0.5349\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0705 - accuracy: 0.5468 - val_loss: 1.0665 - val_accuracy: 0.5361\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0513 - accuracy: 0.5470 - val_loss: 1.0477 - val_accuracy: 0.5382\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0336 - accuracy: 0.5504 - val_loss: 1.0304 - val_accuracy: 0.5447\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0173 - accuracy: 0.5534 - val_loss: 1.0147 - val_accuracy: 0.5503\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0025 - accuracy: 0.5550 - val_loss: 1.0004 - val_accuracy: 0.5618\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9891 - accuracy: 0.5604 - val_loss: 0.9874 - val_accuracy: 0.5698\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9769 - accuracy: 0.5636 - val_loss: 0.9755 - val_accuracy: 0.5713\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9657 - accuracy: 0.5628 - val_loss: 0.9644 - val_accuracy: 0.5698\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.9553 - accuracy: 0.5633 - val_loss: 0.9541 - val_accuracy: 0.5669\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9456 - accuracy: 0.5612 - val_loss: 0.9443 - val_accuracy: 0.5627\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9365 - accuracy: 0.5620 - val_loss: 0.9350 - val_accuracy: 0.5651\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9279 - accuracy: 0.5594 - val_loss: 0.9261 - val_accuracy: 0.5645\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9197 - accuracy: 0.5599 - val_loss: 0.9178 - val_accuracy: 0.5660\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9120 - accuracy: 0.5598 - val_loss: 0.9100 - val_accuracy: 0.5689\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9049 - accuracy: 0.5607 - val_loss: 0.9028 - val_accuracy: 0.5698\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8983 - accuracy: 0.5594 - val_loss: 0.8961 - val_accuracy: 0.5728\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8922 - accuracy: 0.5591 - val_loss: 0.8898 - val_accuracy: 0.5740\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8866 - accuracy: 0.5617 - val_loss: 0.8841 - val_accuracy: 0.5760\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8814 - accuracy: 0.5639 - val_loss: 0.8788 - val_accuracy: 0.5769\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8767 - accuracy: 0.5677 - val_loss: 0.8738 - val_accuracy: 0.5781\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8723 - accuracy: 0.5685 - val_loss: 0.8692 - val_accuracy: 0.5781\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8682 - accuracy: 0.5693 - val_loss: 0.8650 - val_accuracy: 0.5781\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8646 - accuracy: 0.5712 - val_loss: 0.8611 - val_accuracy: 0.5787\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8612 - accuracy: 0.5722 - val_loss: 0.8575 - val_accuracy: 0.5822\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8582 - accuracy: 0.5738 - val_loss: 0.8543 - val_accuracy: 0.5852\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8555 - accuracy: 0.5778 - val_loss: 0.8513 - val_accuracy: 0.5932\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8530 - accuracy: 0.5811 - val_loss: 0.8487 - val_accuracy: 0.5947\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8509 - accuracy: 0.5838 - val_loss: 0.8464 - val_accuracy: 0.5976\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8491 - accuracy: 0.5868 - val_loss: 0.8444 - val_accuracy: 0.5997\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8474 - accuracy: 0.5886 - val_loss: 0.8426 - val_accuracy: 0.6033\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8460 - accuracy: 0.5921 - val_loss: 0.8410 - val_accuracy: 0.6050\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8448 - accuracy: 0.5953 - val_loss: 0.8396 - val_accuracy: 0.6101\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8437 - accuracy: 0.5970 - val_loss: 0.8385 - val_accuracy: 0.6109\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8428 - accuracy: 0.5994 - val_loss: 0.8375 - val_accuracy: 0.6130\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8420 - accuracy: 0.6017 - val_loss: 0.8367 - val_accuracy: 0.6139\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8414 - accuracy: 0.6037 - val_loss: 0.8361 - val_accuracy: 0.6151\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8408 - accuracy: 0.6036 - val_loss: 0.8355 - val_accuracy: 0.6157\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8404 - accuracy: 0.6039 - val_loss: 0.8351 - val_accuracy: 0.6160\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8401 - accuracy: 0.6040 - val_loss: 0.8348 - val_accuracy: 0.6160\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8398 - accuracy: 0.6042 - val_loss: 0.8346 - val_accuracy: 0.6160\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8396 - accuracy: 0.6052 - val_loss: 0.8344 - val_accuracy: 0.6160\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8394 - accuracy: 0.6052 - val_loss: 0.8343 - val_accuracy: 0.6160\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8392 - accuracy: 0.6053 - val_loss: 0.8342 - val_accuracy: 0.6169\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8391 - accuracy: 0.6055 - val_loss: 0.8341 - val_accuracy: 0.6175\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8390 - accuracy: 0.6064 - val_loss: 0.8341 - val_accuracy: 0.6180\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8388 - accuracy: 0.6064 - val_loss: 0.8341 - val_accuracy: 0.6198\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8387 - accuracy: 0.6076 - val_loss: 0.8340 - val_accuracy: 0.6204\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8386 - accuracy: 0.6069 - val_loss: 0.8340 - val_accuracy: 0.6207\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8384 - accuracy: 0.6074 - val_loss: 0.8340 - val_accuracy: 0.6210\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8383 - accuracy: 0.6080 - val_loss: 0.8340 - val_accuracy: 0.6210\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8381 - accuracy: 0.6083 - val_loss: 0.8340 - val_accuracy: 0.6213\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8380 - accuracy: 0.6080 - val_loss: 0.8339 - val_accuracy: 0.6198\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8378 - accuracy: 0.6082 - val_loss: 0.8339 - val_accuracy: 0.6192\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8377 - accuracy: 0.6082 - val_loss: 0.8339 - val_accuracy: 0.6204\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8375 - accuracy: 0.6080 - val_loss: 0.8338 - val_accuracy: 0.6222\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8373 - accuracy: 0.6085 - val_loss: 0.8337 - val_accuracy: 0.6216\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8372 - accuracy: 0.6091 - val_loss: 0.8336 - val_accuracy: 0.6210\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8370 - accuracy: 0.6091 - val_loss: 0.8336 - val_accuracy: 0.6213\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8369 - accuracy: 0.6090 - val_loss: 0.8335 - val_accuracy: 0.6213\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8367 - accuracy: 0.6088 - val_loss: 0.8334 - val_accuracy: 0.6198\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8366 - accuracy: 0.6080 - val_loss: 0.8333 - val_accuracy: 0.6207\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.8364 - accuracy: 0.6087 - val_loss: 0.8332 - val_accuracy: 0.6195\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8363 - accuracy: 0.6085 - val_loss: 0.8331 - val_accuracy: 0.6180\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8362 - accuracy: 0.6082 - val_loss: 0.8330 - val_accuracy: 0.6180\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.8360 - accuracy: 0.6077 - val_loss: 0.8329 - val_accuracy: 0.6189\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8359 - accuracy: 0.6090 - val_loss: 0.8329 - val_accuracy: 0.6189\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8358 - accuracy: 0.6103 - val_loss: 0.8328 - val_accuracy: 0.6195\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8357 - accuracy: 0.6096 - val_loss: 0.8328 - val_accuracy: 0.6201\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8356 - accuracy: 0.6093 - val_loss: 0.8328 - val_accuracy: 0.6207\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8355 - accuracy: 0.6085 - val_loss: 0.8327 - val_accuracy: 0.6216\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8354 - accuracy: 0.6080 - val_loss: 0.8327 - val_accuracy: 0.6228\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8353 - accuracy: 0.6080 - val_loss: 0.8327 - val_accuracy: 0.6237\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8353 - accuracy: 0.6079 - val_loss: 0.8327 - val_accuracy: 0.6237\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.8352 - accuracy: 0.6076 - val_loss: 0.8327 - val_accuracy: 0.6234\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8351 - accuracy: 0.6064 - val_loss: 0.8327 - val_accuracy: 0.6231\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8351 - accuracy: 0.6066 - val_loss: 0.8327 - val_accuracy: 0.6237\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8350 - accuracy: 0.6064 - val_loss: 0.8327 - val_accuracy: 0.6234\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.835\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model = hybrid_RUM_MNL_ANN_model(NALT, no_X_MNL, no_X_ANN, num_nodes, seed=0)\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-2), metrics = [\"accuracy\"], loss = 'categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(patience = 4, monitor = 'val_loss')\n",
    "history = model.fit([X_mnl_train, X_ann_train],Y_train, batch_size=len(X_mnl_train), epochs = nEpoch, verbose = 1, validation_data = ([X_mnl_test, X_ann_test], Y_test), callbacks = [early_stopping])\n",
    "\n",
    "betas_layer = model.get_layer(name = 'MNL_layer')\n",
    "betas = betas_layer.get_weights()\n",
    "print('The cross-entropy on the test data of the tensor flow ANN is',\"{:.3f}\".format(history.history['loss'][-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3XElEQVR4nO3deXxV1bn/8c83JyMJQxhlBhEEtYoWcUJFrQOWOrS3t2i1aquUW21tq63a1l5tr9VOVr1OtQ51aLX+HFGp84TXAaHFgUlmCHOYE0Km8/z+WDvkEBNyIAknOXner9d+nX3Wnp51As/ZZ+2915KZ4ZxzLn1lpDoA55xzLcsTvXPOpTlP9M45l+Y80TvnXJrzRO+cc2nOE71zzqU5T/TOOZfmPNG7ZifpXEnTJZVIWiXpn5LGpDCeJZLKonhqptuT3PZNSRe3dIzJkHShpHdSHYdrezJTHYBLL5J+DFwNTAJeAiqA04Azgc8lKUmZZla1F0L7ipm92tw73YvxO7fH/IzeNRtJnYFfAZea2VNmVmpmlWb2nJn9JFrnOklPSHpE0hbgQkl9JE2WtEHSAkmXJOxzdPTrYIukNZJujspzo32sl7RJ0oeSeu1BzBdKekfSHyRtlLRY0rho2Q3AscDtib8CJJmkSyXNB+ZHZZdEsW+I6tIn4Rgm6QeSFkkqlvR7SRmScqL1v5Cwbs/o10eP3azH0dFnsDl6PbpOHRdJ2hrV75tR+X6S3oq2KZb0j939/FwbYWY++dQsE+HMvQrI3MU61wGVwFmEE4084C3gTiAXGAmsA06K1n8POD+aLwCOjOa/CzwHdABiwBeBTg0ccwnwpQaWXRjFc0m0n/8CVgKKlr8JXFxnGwNeAbpG8Z8IFAOHATnA/wJv11n/jWj9AcBnNfuM6v3bhHUvB57bRazv1FPeFdgInE/4lX5O9L4bkA9sAfaP1u0NHBjNPwr8PPo75AJjUv1vyKeWmfyM3jWnbkCxNd6U8Z6ZPWNmcaA7MAa4ysy2m9lM4F5C0oKQhPeT1N3MSszs/YTybsB+ZlZtZjPMbMsujvlMdOZfM12SsGypmf3FzKqBBwnJsLFfBzea2QYzKwO+CdxvZv8ys3LgGuAoSYMS1v9ttP4y4BZCMiY63rmSav4vng883Mix6/oyMN/MHjazKjN7FJgLfCVaHgcOkpRnZqvMbFZUXgkMBPpEn723/6cpT/SuOa0Huktq7NrP8oT5PsAGM9uaULYU6BvNfwcYBsyNmiTGR+UPE64BPCZppaTfScraxTHPMrMuCdNfEpatrpkxs23RbMFu1mFpwj5KCJ9F3wbWXxptg5l9AJQCx0saDuwHTG7k2HXtdPyEY/Q1s1LgG4RrJqskvRAdB+CngIBpkmZJ+vZuHte1EZ7oXXN6D9hOaJbZlcQuU1cCXSV1TCgbAKwAMLP5ZnYO0BP4LfCEpHwLbf/Xm9kBwNHAeOBbzVONBmNtqHwl4cwYAEn5hF8bKxLW6Z8wPyDapsaDwHmEs/knzGz7bsa40/ETjlHzGb5kZicTfqnMBf4Sla82s0vMrA+hKexOSfvt5rFdG+CJ3jUbM9sM/BK4Q9JZkjpIypI0TtLvGthmOfAucGN0gfVgwln83wAknSepR9TMsynarFrSCZK+IClGaIOuBKpboFprgH0bWefvwEWSRkrKAX4DfGBmSxLW+YmkQkn9Ce3wiRc+HwbOJiT7hxo5lqLPaccETAGGKdzWminpG8ABwPOSekk6I/ryKQdKiD4nSV+X1C/a70bCl1dLfIYu1VJ9kcCn9JsIbdbTCU0Sq4EXgKOjZdcBj9RZvx/wPLABWAhMSlj2CLCWkKBmEZpgILRxz4uOsQa4jQYuAhMuxpZF+6iZno6WXUidC5yEhLdfNH8U4eLpRuC2ussTtpkUxb4hqku/Ovv7AbCI0KTzRyBWZ/tXozi1i8/1wmhfdadMwnWOGcDm6HVMtE1vwsXuzYQvyjeBA6JlvyOc9ZdEsU9M9b8dn1pmqrmzwDnXQiQZMNTMFuxinfuBlWb2i70XmWsv/IEp51Isujvnq8ChKQ7FpalG2+gl3S9praRPG1guSbdFD4t8LOmwhGWnSZoXLbu6OQN3Lh1I+jXwKfB7M1uc6nhcemq06UbScYQ2vIfM7KB6lp8OfB84HTgCuNXMjogukn0GnAwUAR8C55jZ7OatgnPOuV1p9IzezN4mXGBqyJmELwGz8DBLF0m9gdHAAjNbZGYVwGPRus455/ai5mij78vOD4MURWX1lR/R0E4kTQQmAuTn539x+PDhDa3qWrOtW+Gzz1iV2Z/eh/RMdTTOtRszZswoNrN6+0hqjkSvespsF+X1MrN7gHsARo0aZdOnT2+G0NxeZ8a6g8ZSOXs+Uy+byjcuzEt1RM61C5LqPh29Q3M8MFXEzk/99SM8qddQuUtnEt1u/xV9WMWiq/9MtT9+41zKNUeinwx8K7r75khgs5mtIlx8HSppsKRsYAK734eHa4MyTjieNQedyLfX3MgzfytNdTjOtXvJ3F75KKEPk/0lFUn6jqRJkiZFq0whPPG3gNCHxvcALPRgeBmh46k5wONW22ueS3Pdb7+eXqxl8VV3EY+nOhrn2rdW+WSst9Gnh1WHnErmx//i9XsW8o1LOqU6HOfSmqQZZjaqvmXeqZlrMb3+cgM9KGbtlb+jvDzV0TjXfnmidy0mY/QoVp14Lhdv+SMP/aYo1eE41255onctqvd9NxDLMApu+gWbN6c6GufaJ0/0rmUNGsTG837ANyoe4qEfz0x1NM61S57oXYvrdevPKM0u5MC/XsmSxa3v4r9z6c4TvWt5XbpQ9YvrOTH+Go9PeCrV0TjX7niid3tF4TWTWLPPwUyY9iNem+wPUTm3N3mid3tHZiaFf7uDASxn/rdvpKIi1QE51354ond7TfaJYygaex4Xrf89D/9yfqrDca7d8ETv9qp+f/8d1Zk5DPjD91m21C/MOrc3eKJ3e1fv3pT97H84ufol/nHWo7TCHjicSzue6N1e1+2Xl7JqwBFcMPOHPHPf+lSH41za80Tv9r5YjJ7P/oWu2kj5969gw64GqnTONVlSiV7SaZLmSVog6ep6lhdKelrSx5KmSTooYdkSSZ9IminJu6R0AMRGfoH13/4pE7Y/yL0TXk11OM6ltWT6o48BdwDjgAOAcyQdUGe1nwEzzexg4FvArXWWn2BmIxvqQtO1T71uv5Z1XYfx9Vcu4YXHtqY6HOfSVjJn9KOBBWa2yMwqgMeAM+uscwDwGoCZzQUGSerVrJG69JObS5cn72cgSyn+9k8pLk51QM6lp2QSfV9gecL7oqgs0UfAVwEkjQYGEsaIhTAg+MuSZkia2NBBJE2UNF3S9HXr1iUbv2vjssYew/oLruCCsru562uv+F04zrWAZBK96imr+9/xJqBQ0kzg+8C/gapo2TFmdhih6edSScfVdxAzu8fMRpnZqB49eiQVvEsPPe76FcU9hnPB29/hifu8L2Pnmlsyib4I6J/wvh+wMnEFM9tiZheZ2UhCG30PYHG0bGX0uhZ4mtAU5FytvDy6PP1X+rKCiu9dzpIlqQ7IufSSTKL/EBgqabCkbGACMDlxBUldomUAFwNvm9kWSfmSOkbr5AOnAJ82X/guXWQecwRbvv9zvln5IPee8jhVVY1v45xLTqOJ3syqgMuAl4A5wONmNkvSJEmTotVGALMkzSU00VwelfcC3pH0ETANeMHMXmzuSrj0UPjHayne7wiumP9dbrlieeMbOOeSImuFV79GjRpl06f7Lfft0sKFlA0fyftVo9CrrzL2pFiqI3KuTZA0o6Fb2P3JWNe6DBmCbruNE3iT9876LatXpzog59o+T/Su1cmddCGbxk3gpyXX8ptxU7293rkm8kTvWh+JLo/9mdJeQ/jpzHP47ZX+XIVzTeGJ3rVOnTrR6cXH6RUr5rBbv8XkZ+Kpjsi5NssTvWu9Ro7E/nQr43iRT77xP8yZk+qAnGubPNG7Vi37somUfvV8rqm4jj+d9DybNqU6IufaHk/0rnWTyH/kz2wbOpLfrTqPK86YT3V1qoNyrm3xRO9av7w8Cl5+itz8TH489SyuuXRLqiNyrk3xRO/ahkGDyH32HwzXPI7/8zncdrPfc+lcsjzRu7bjpJPQ7bfzZabAFVfw7LOpDsi5tsETvWtTMr43icpLf8gPuI03vn4n776b6oica/080bs2J+vWP1B+ylf4Y+X3uf2UZ/nkk1RH5Fzr5onetT2xGDlP/p2qQ0Zxf+kEfjn2bRYtSnVQzrVeSSV6SadJmidpgaSr61leKOlpSR9LmibpoGS3dW6PFBSQ8+oLaPBA/rrxDC477mOWe8/GztWr0UQvKQbcQehn/gDgHEkH1FntZ8BMMzuYMMLUrbuxrXN7pnt3ct58mbweBTyw8hQuOnqeJ3vn6pHMGf1oYIGZLTKzCuAx4Mw66xwAvAZgZnOBQZJ6Jbmtc3tuwACy33yFrl2Mh1acyAXHLPBk71wdyST6vkDif52iqCzRR8BXASSNBgYSxpZNZlui7SZKmi5p+rp13luh2w0jRpD19mv06FzBQ0Un8M2jFjF/fqqDcq71SCbRq56yusNS3QQUSpoJfB/4N1CV5Lah0OweMxtlZqN69OiRRFjOJTjoILLefJV9Om3j0VXHc8GR85g5M9VBOdc6JJPoi4D+Ce/7ASsTVzCzLWZ2kZmNJLTR9wAWJ7Otc83mkEPIfOt1ehVWMHnTsVw2ZiZvvZXqoJxLvWQS/YfAUEmDJWUDE4DJiStI6hItA7gYeNvMtiSzrXPN6pBDyHx3Kl32yWVK2Vh+edL/8fDDqQ7KudRqNNGbWRVwGfASMAd43MxmSZokaVK02ghglqS5hDtsLt/Vts1fDecSDBtG5nvvkL9vL16xk3jmW09y7bUQ97FLXDsls3qbzFNq1KhRNn369FSH4dq64mLiXzkD3n+fK/kDS8/+EQ/8VXTqlOrAnGt+kmaY2aj6lvmTsS59de9Oxuuvof/4GjdzBac8818cc3gFs2enOjDn9i5P9C695eWhf/wDrr6a79qf+cvikxh/+BoeeSTVgTm393iid+kvIwNuvBEefZTRsRm8VzWK/z3/A847D7b4GCauHfBE79qPCRPIePf/6Nk7xruxY+nx91sYeYgxdWqqA3OuZXmid+3LoYeif/+b2PjT+ZP9iLvXns3Zx63n8suhtDTVwTnXMjzRu/ansBCefhr+9CdOrpzCwvwvMPe2lzj4YHjxxVQH51zz80Tv2icJfvhD9MEHdB5YyEucxq/WX8p/jCvh61+HoqJUB+hc8/FE79q3Qw+FGTPgRz/i3C13UdTlILY/+xL77w/XX+/NOS49eKJ3LjcXbr4ZTZ1Kl33yeK7yNP7Z/Xzuum41w4bBffdBVVWqg3Ruz3mid67GMcfAzJlw7bUct+ofFHUYxk8zb2bSxZWMGAGPPALV1akO0rnd54neuUQ5OfCrX8GsWWQeP4bLl13Bhr5fYHzV05x/vjF8OPz5z1BWlupAnUueJ3rn6jN0KLzwAkyeTMeO4k9Lvkrx/sdwYuwtJk2CgQPhuutgxYpUB+pc45prcPDOkp6T9JGkWZIuSli2RNInkmZK8p7KXNshwVe+Ap98An/5C922LuXP88ay8eDjuWTfV/nV9cbAgfDVr4bvhMrKVAfsXP2aa3DwS4HZZnYIMBb4Y0L/9AAnmNnIhnpWc65Vy8yEiy+GBQvg1lvpsn4hN3xwMtu+MJqHx/2d996uZPx46NsXLr8c/u//vEtk17o01+DgBnSUJKAA2EAYStC59JGXBz/4ASxcCHffTW75Fs55/puszB3MnHN+xVmjirj7bhgzBvr1g+99L5zp+y2aLtWaa3Dw2wmDj6wEPgEuN7OacxoDXpY0Q9LEJsbrXOrl5MB3vwtz5sALL6ADD2T4o//NPS8NpOSE8Uz9weOMHb2NBx+E8eOha1f40pfgf/4H3nkHystTXQHX3mQmsU4yA3yfCswETgSGAK9ImhoNJ3iMma2U1DMqn2tmb3/uIOFLYCLAgAEDdqMKzqVIRgacfnqYFi+G++4j64EHGPPSC4wpKKD6jDP5dNhX+cemU3n+jXyuvTZslpMTntM64gg4/PAwP2xYaCFyriU0OsKUpKOA68zs1Oj9NQBmdmPCOi8AN5nZ1Oj968DVZjatzr6uA0rM7A+7OqaPMOXarOpqePtt+Pvf4cknYePG8EDWSSdROuZU3ut4Ci8uGsYH08SMGbW3aebmwgEHhGnEiJD499sPhgyBjh1TWyXXNuxqhKlkEn0m8BlwErCCMOD3uYljv0q6C1hjZtdJ6gX8CzgEKAMyzGyrpHzgFeBXZrbLrqM80bu0UFkZ2mqeeQaefx4WLQrl/fvDscdSffSxLNznGKZtHcG/P8lk1iyYPRuWL995N127hk0GDIA+faB37zD16AHdu0O3bqGftsLC8IXh2qcmJfpoB6cDtwAx4H4zu6FmYHAzu1tSH+CvQG9CU89NZvaIpH2Bp6PdZAJ/N7MbGjueJ3qXlhYuhFdegddfD18Aq1aF8g4dQvvNYYfBF75A6eCDWJQzgnlrurBwISxdGpL/smVhk3XrGj5Ednb4BdCxIxQUhF3n54fryHl54YsgNzc0H9VM2dm1U1ZW7WvilFiWmbnz+7rb1d1fZma4U9W1rCYn+r3NE71Le2bhDP/99+HDD8P08cdQUlK7Ts+e4cGtwYNh0KDwlFafPlR2701xVm/WVHWjeHMWxcWwaVPttHVrmEpKYNu2cNdPWRls3x5ey8vDfHk5VFSEqaUlJv+mTjk5O3+h1P1yaehLq+4XWN33mZk7v7a1LydP9M61BfF4OH3/5BOYNw8++yxMS5aEfpPruzm/c+fQdtOlS5jv3Dmcytecztc9jU/MglFWs1gmVRajmhiV8RhV8Yydp2pRWSWqqhOmKnbMV1aF9xWV0ftKdqxfWRnKK6szqKwSFZWioirMl1dmUFGVQUVlmC+vilFemcH2yoTXqhjbK2NsKw/z2yoyo/kM6r9PpPlkZNQm/sQpFmv4tb4pI+Pz72vKEl8zMkLz2x137Fm8u0r0fp3fudYiIyOcvQ8e/PlllZWwcmVou1m1ClavhuLi2mnz5jAtXBhO4WtO58vKGu2JTUBWNLWlJn5LyLIWqzNlxIhnZGIZmcRjmcQV3scVq52IESeDaoXXODGqyQjzlkHcFJaTQTwu4ggzhXIT8biwcqL3YCbMwo+1eOI8YZ647SirOb8O6wJRWWWHznue6XfBE71zbUFWVmi6GThw97etrAxtNRUVte01lZVhqqoKXwQ1r/F47atZmE/MTokZqr73Dc2b1e6zZr7mfc184rGrq+ufauKsrkZVVaEO1dWounrHPAnl1C1P3NeO45TvfPyG4mvoc0h83dU8NN4e1L377v99k+CJ3rl0V9NM49ot773SOefSnCd655xLc57onXMuzXmid865NOeJ3jnn0pwneuecS3Oe6J1zLs15onfOuTTnid4559JcUole0mmS5klaIOnqepZ3lvScpI8kzZJ0UbLbOueca1mNJnpJMeAOYBxwAHCOpAPqrHYpMNvMDgHGAn+UlJ3kts4551pQMmf0o4EFZrbIzCqAx4Az66xjQEdJAgqADUBVkts655xrQcl0atYXSBzcrAg4os46twOTgZVAR+AbZhaXlMy2wM6DgwMlkuYlEVt9ugPFe7htW9Ee6gjto57toY7QPuqZ6jo22LVpMom+vn41645WciowEzgRGAK8ImlqktuGQrN7gHuSiGeXJE1vqPP9dNEe6gjto57toY7QPurZmuuYTNNNEdA/4X0/wpl7oouApyxYACwGhie5rXPOuRaUTKL/EBgqabCkbGACoZkm0TLgJABJvYD9gUVJbuucc64FNdp0Y2ZVki4DXgJiwP1mNkvSpGj53cCvgb9K+oTQXHOVmRUD1Ldty1RlhyY3/7QB7aGO0D7q2R7qCO2jnq22jq1ycHDnnHPNx5+Mdc65NOeJ3jnn0lzaJPp07WpBUn9Jb0iaE3UvcXlU3lXSK5LmR6+FqY61qSTFJP1b0vPR+7Sqo6Qukp6QNDf6ex6VbnUEkPSj6N/qp5IelZTb1usp6X5JayV9mlDWYJ0kXRPlonmSTk1N1LXSItGneVcLVcAVZjYCOBK4NKrb1cBrZjYUeC1639ZdDsxJeJ9udbwVeNHMhgOHEOqaVnWMHpL8ATDKzA4i3IQxgbZfz78Cp9Upq7dO0f/PCcCB0TZ3RjkqZdIi0ZPGXS2Y2Soz+1c0v5WQHPoS6vdgtNqDwFkpCbCZSOoHfBm4N6E4beooqRNwHHAfgJlVmNkm0qiOCTKBPEmZQAfCszNtup5m9jaha5dEDdXpTOAxMys3s8XAAkKOSpl0SfT1dbXQN0WxtBhJg4BDgQ+AXma2CsKXAdAzhaE1h1uAnwLxhLJ0quO+wDrggah56l5J+aRXHTGzFcAfCM/WrAI2m9nLpFk9Iw3VqdXlo3RJ9El3tdBWSSoAngR+aGZbUh1Pc5I0HlhrZjNSHUsLygQOA+4ys0OBUtpe80WjonbqM4HBQB8gX9J5qY1qr2t1+ShdEn1ad7UgKYuQ5P9mZk9FxWsk9Y6W9wbWpiq+ZnAMcIakJYRmtxMlPUJ61bEIKDKzD6L3TxASfzrVEeBLwGIzW2dmlcBTwNGkXz2h4Tq1unyULok+bbtaiLp+vg+YY2Y3JyyaDFwQzV8APLu3Y2suZnaNmfUzs0GEv93rZnYe6VXH1cBySftHRScBs0mjOkaWAUdK6hD92z2JcF0p3eoJDddpMjBBUo6kwcBQYFoK4qtlZmkxAacDnwELgZ+nOp5mrNcYws++jwk9hM6M6tqNcKV/fvTaNdWxNlN9xwLPR/NpVUdgJDA9+ls+AxSmWx2jel4PzAU+BR4Gctp6PYFHCdccKgln7N/ZVZ2An0e5aB4wLtXxexcIzjmX5tKl6cY551wDPNE751ya80TvnHNpzhO9c86lOU/0zjmX5jzRO+dcmvNE75xzac4TvXPOpTlP9M45l+Y80TvnXJrzRO+cc2nOE71zzqU5T/SuSSRdF/Ud31L7nyVpbDQvSQ9I2ihpmqRjJc1rgWMOkFSS6nE+nWsunuhdoySdK2l6lPxWSfqnpDF749hmdqCZvRm9HQOcDPQzs9FmNtXM9m946+RIWiLpSwnHXGZmBWZW3dR9N3A8SVokaXZL7N+5ujzRu12S9GPCeK6/AXoBA4A7Sc3g6wOBJWZWmoJjN6fjCOOL7ivp8L154GjAbtfOeKJ3DZLUGfgVcKmZPWVmpWZWaWbPmdlPGtjm/0laLWmzpLclHZiw7HRJsyVtlbRC0pVReXdJz0vaJGmDpKmSMqJlSyR9SdJ3gHuBo6JfFtdLGiupKGH//SU9JWmdpPWSbo/Kh0h6PSorlvQ3SV2iZQ8Tvryei/b7U0mDJFlNUpTUR9LkKLYFki5JOOZ1kh6X9FBUr1mSRjXy0daMRjSF2hGKavZ3oKRXomOtkfSzqDwm6WeSFkbHmRHVd6dYo3XflHRxNH+hpP+T9CdJG4DrdvV5NPQ5RqMlbZD0hYT1ekoqk9Sjkfq6FPNE73blKCAXeHo3tvknYei0nsC/gL8lLLsP+K6ZdQQOAl6Pyq8gjNrTg/Cr4WfUGUzZzO4DJgHvRc0q/524PGpPfx5YCgwC+hLGn4UwWPONhMGqRxDG87wu2u/5hOHvvhLt93f11OnRKL4+wH8Av5F0UsLyM6JjdSEMI3d7Qx+OpA7RPv4WTRMUhr9EUkfgVeDF6Fj7EUYuAvgxcA5hdLFOwLeBbQ0dp44jgEWEv8kN7OLzaOhzNLPyqI6JA32fA7xqZuuSjMOliCd6tyvdgGIzq0p2AzO738y2RonhOuCQ6JcBhGHYDpDUycw2mtm/Esp7AwOjXwxTbfeHPhtNSFw/iX55bDezd6KYFpjZK2ZWHiWlm4Hjk9mppP6EawNXRfucSfhlcX7Cau+Y2ZSoTf9h4JBd7PKrQDnwMiGhZgJfjpaNB1ab2R+jY2212sHELwZ+YWbzLPjIzNYnUwdgpZn9r5lVmVlZI59Hg58j8CBwbs2vregzeDjJGFwKeaJ3u7Ie6J5su27UvHBT1LywBVgSLeoevX6NcEa6VNJbko6Kyn8PLABeji5SXr0HsfYHltb3pRQ1MTwWNRdtAR5JiKkxfYANZrY1oWwp4Uy3xuqE+W1A7i4+swuAx6OkWw48RW3zTX/COKP12dWyxixPfNPI59Hg5xh96ZQCx0saTvjFMXkPY3J7kSd6tyvvAduBs5Jc/1zCRdovAZ0JP/0hNBVgZh+a2ZmEJoRngMej8q1mdoWZ7Qt8BfhxnaaRZCwHBjSQYG8kNAUdbGadCM0PSli+q18PK4GuUbNKjQHAit2MD0n9gBOB86LrGKsJzTinS+oe1WFIA5s3tKzmwnSHhLJ96qxTt367+jx29TlCOKs/j3A2/4SZbW9gPdeKeKJ3DTKzzcAvgTsknSWpg6QsSeMk1deW3ZHQLLGekHh+U7NAUrakb0rqbGaVwBagOlo2XtJ+kpRQvru3Nk4DVgE3ScqXlCvpmIS4SoBNkvoCdS8krwH2beAzWA68C9wY7fNg4DvsfO0hWecDnwH7AyOjaRih/f8cQlPOPpJ+GF387CjpiGjbe4FfSxqq4GBJ3aKmlxWEL4+YpG/T8JdFjV19Hrv6HCE01ZxNSPYP7cFn4FLAE73bJTO7mXAh8BfAOsIZ32WEM/K6HiI0a6wAZgPv11l+PrAkai6YRO2FvaGEi5AlhF8RdybcO59snNWEXwP7ES6uFgHfiBZfDxwGbAZeIDSXJLoR+IXCXT9X1rP7cwi/TlYSLkz/t5m9sjvxRS4g1G114gTcDVwQNQ+dHNVjNTAfOCHa9mbCL6CXCV+G9wF50bJLCMl6PXAg4YtpVxr8PBr5HDGzIsJFdgOm7v5H4FJBu3/NyznXnkm6n3CB9xepjsUlxx+ecM4lTdIgwp1Dh6Y4FLcbmtR0I+k0SfOih0g+d6eEpM6SnpP0UfQgyUVNOZ5zLnUk/Rr4FPi9mS1OdTwueXvcdBM9WPEZoU2xCPgQOMfMZies8zOgs5ldFT09Nw/Yx8wqmhy5c865pDTljH40sMDMFkWJ+zE+3/+JAR2juykKgA1A0g/fOOeca7qmtNH3ZecHMYoIj1onup3wQMVKwi1d3zCzeH07kzQRmAiQn5//xeHDhzchNOeca19mzJhRbGb19jvUlESvesrqtgOdCswkPCQyBHhF0lQz2/K5Dc3uAe4BGDVqlE2fPr0JoTnnXPsiaWlDy5rSdFNEeFy6Rj/CmXuii4Cnor45FgCLAT9Vd865vagpif5DYKikwVHvexP4fL8Xy4CTACT1IjwRuKgJx3TOObeb9rjpxsyqJF0GvATEgPvNbJakSdHyu4FfA3+V9AmhqecqMytuhridc84lqUkPTJnZFMLgCYlldyfMrwROacoxnHPONY33deOcc2nOE71zzqU5T/TOOZfmPNE751ya80TvnHNpzhO9c86lOU/0zjmX5jzRO+dcmvNE75xzac4TvXPOpTlP9M45l+Y80TvnXJprUqdmkk4DbiX0Xnmvmd1UzzpjgVuALKDYzI5vyjGdcy2gqgoqKsJUWVk7X1YGGzfChg1QUlJbXlUF1dW1UzweXmuY1S4zg44doVOn8JqTA1lZIEFpaZi2bAnH2LgxHD87O6yTnV071ewznjBInVS77w4dYPv2EHM8Dvn5YapZ3qkT5ObWxldTv+3bw/ua8pr6132tmcrLa7fbtq22Dtu21ZbXjTEW23mSwn4rK8NnmZERyrt3h8cea/Y/7x4n+mhw8DtIGBxc0uQ6g4N3Ae4ETjOzZZJ6NjFe59LP9u3w6aewenVIFGVlsGkTFBeHqbS0NoHVJJXS0p0Tc2JSTZZZbdJKTNIpZJ06YVnZO5KrqipRVescZtoyMrC8DtAhH6v5UsnJxXJzQ9Im9M2ueBwqy1G8GtV8UcXjtV9ksVj4/CsqYOvWFom1KWf0OwYHB5BUMzj47IR1ziWMMLUMwMzWNuF4zrU9VVWwfn1I4osWhamoqPYsefFimDOn3kRrEvEuXanKLaAyM4+KjFzKMgooVRe2WR+qYjlU52RTnZdJNTGqiREnAywa09NCLjcLeaWqKkw7vgoMKnJz2F6YR7lyqVAOVWRRQRbbqnIoqchmWzyHzSpkc0Yhm+Md2VSWw+aybCrimcSyY8SyY1RZjPKqGOWVGVTFa0cY3REPkE8pndlMR7aSRSXZVCCMUvIpoYCtdGQznane8vmUJOJkU4GhHfu0aCTTDOIUUEIntpBPKdvJpYw84mSQTyn5lNKJLXRkK53ZTDYVO/ZbQTZl5FFODtXEdpRXkkUF2VSSRTk5O+YTX8vIozKeBaWCUmBdcv8ccnLC90FeXnhfc+IvhanXdpiR3K52S0sPDj4MyJL0JmFw8FvN7KEmHNO51mX5cnjpJVi5MjQ/bNoEK1aEZL5iRUjodVhBAdWdu1KWW8jG/IEsPvosPomNZH75ANaV5LF2ax6LN3ZhyeYuxDfGPrd9LAadO4df+zWJoqZFICMjTDWJo6aVIDsb8jqFBBNL2GXi+omveXmhJSQ7G7IFPYDemSFJdegQ9lHTiiGFk9PMzJ1bWjIza2OKxztTXd2ZeHznY+34TKy2ZSYWC9vW7C8nJ4OsrFwyMj6/fjwew6wz8XhnqqpCPOXl4QstO7sHOTnhWDX7TmxRqqqqbTnJzQ0tPDUtPR07hs+gZp8VFbWtU5WVoWz79tpjVVbu3FqT+AWbeLyaH2VlZbV/I6l23U6dmvbPsSEtPTh4JvBFwnCCecB7kt43s88+tzNpIjARYMCAAU0Iy7kWsGlTOBtfsiQk8aVL4fXXYebMHatYhw5U53die9e+bO40hHUHHs/q6p6s2N6NJdt6Mqd8X2aV7cuC9YVUldTuWoI+fWCffaDrPtBtBOzfHXr1ClPPnmHq0SNMNUneuWQ1JdEnMzh4EeECbClQKult4BDgc4nezO4B7gEYNWrUbjQ0ujZh+/ZwSpOfv/OpXHMxg82bwxn2+vXhwmFpaTijLi6uLUts6y4pCfP1tWvH41BRgVVUYOs3kLFxw06Lq7NyWN3vcN4/4nc8Z+N5Z81QlhRlUr2NnX7G5+bCgAHQty907QpjCuHsHrDvvmEaNAj69Qtnrs61lKYk+h2DgwMrCIODn1tnnWeB2yVlAtmEpp0/NeGYri1YtQqefx6eew4++ADbtAlVhLZRy8ggXtCJ6sLuVPbsR3mv/tigfckZOYIOh+5PhlVTvXINVavWkZ0NyokuVpWU1N6ZUVQUEvratbWJe+PGsE4DrGNH4h0KqM7KoyKWyzblsyVewJaKTlTGM8L1sWqojq6TVVWLkoocSquy2UInFjKEhQxhKQNZTn+KK7vDYlG4CYYNgyOOgQmDaxN3nz5h6tatZb7XnNsdLTo4uJnNkfQi8DEQJ9yC+WlzBO5aj6oqWLPaqPjna3R+4BYK35+CzFiVO4g3GM+yih7hQhsxOsa30nnLZnpuWUv/pcvpz5v04xEyElr9YtFUnziiOHMf1mT3Z31sICXWgdJ4HlvVmeLu/dnUsT+lHXpQkZVPRVY+K8oKmbeuG0XrcojXuaEhJyck5oKCcOadkxNec3NDO3S3buEsvHNnGJYHh+SFdQsLQ1n//uFuOOdaO9nu3I61l4waNcqmT5+e6jDarXg8NEEvWxZOlDdurL3VuLo63ECyZLFRNXcB+yx5n6Ebp3Eir3EAc1hDT/7Md3kq9p/EDj6QkYeKwYNh4MCQNCsqam8zrrmAV76pjOq584ktnEd1RjaVXXtR0bkHGzZlsHFNBVvWV1KeVUB5bmcqcjpSrcwdrS0dOoSLZjW3ZG/dGvZfcwGsU6fQ9r3PPju3d++7bzjzjjX0jeJcGyNphpmNqm9Zkx6Ycm1XPB5aQObNgwULQkvIsmWwYL6xaFYZlJaQTykFhNdCNtKdYnqyltH6kMsz3qJn9WoAyrPyKR58OB+efBWbx01gfO8cfnpA7bMpjcsDDo4m51xz80SfpszCHX+zZ8Mnn8BHH4X5mqbsTZvCrWG9WM3xvMUJeosLM99iv8o5OzWj1LvvPn3R8SfC8cfD0UeTM2IEfWMx+u6dqjnndpMn+jSwbVtI6h9/DO++C++/H5L7li1heTblHN5zGSf2W8rgHivo2W0VfXstZNiaqRSumQeA5RegMWPgsLNCe0fNk34FBeG1sDA0SHfvjrp08SuMzrUhnuhbkcrK0HyS2B6+fTtsKzUq1m5i27JiylcUU7a8mK3LNlK2aiOV67ei8jJy2U4ntnB0xkbOKdhAj5wtdOqxmQ6Vm8netA7WEqYaXbvCUUfB2Ivh+OPRoYeGBnPnXNrx/9kpYhaaUt56uZyZr62neNYaypetoUd8NQNYxiCWMJCl9Gc5X6CIDpQ1uK94Rozq7DysoCOZPQrJKOwCXXpB52Hh7Lxv33B7yYAB4Qpk797hKqZzrl3wRN/SNmyAadOomD2flW98Rum85WjtGjpsXUP/eDHfo/5OjMoK+7Ct50Aqeh7K+t5nUNy7Dzn9e9JhQHfyB3Qjo1thaE7p1ImMrCzvb9o51yBP9C2hrAx7YQoldz9ChzdfIFZdSTZQSCe2MpDSjr3YOnhfSvbtSZ+Du9N1aPdwz1/NM+99+5KXm0tequvhnEsLnuiby4oVrHlgCmWPP0fv2a+SU13GVnpzD9/nve5nMOTLwzlxQk+OH6vduO3QOeeazhP9norH4b332PTgM1RMfpGeaz6lF7CEgfyt4GLWHXUmPb4+ljPGxvjxfn6TinMudTzR7454HN59l7IHHiP+xFPkb1lFB7KYznHMG3QBXc85lVEXHsRFQ+WJ3TnXaniib4gZrFsHc+dic+ayffonVD/1LAUblmPk8SLj+LD/1+j57fF87aJOfGlgqgN2zrn6eaJPUDL132z60wNkTX+XTqvnk1cZnjgSYOTxFifwSvcb6XTeGfzHRR35mj+x75xrA9ptoo/HYdFC45P/N5fqpydz0CePMrz8IzLJYSrHsiT3W5T2H0rloGFUDBlBzn79GXNcBn86wtvbnXNtS5MSvaTTgFsJvcrea2Y3NbDe4cD7wDfM7ImmHHNXajrqWrgwDAa0eXPt+BKbNtWOQVG5aDmnLL+PCfG/cTYLAPis8+FMOfkOci44h0OOK+RkH8bcOZcm9jjRS4oBdwAnE0aS+lDSZDObXc96vyX0W99iqquhsFM1ldsqyCZMNYMQd8ks5ZD8BYzOmsuR1e9w9KYpYMbKEV9i1devoNd3xjNsQD+GtWSAzjmXIk05ox8NLDCzRQCSHgPOBGbXWe/7wJPA4U04VqNiMVhfUUAW2z+/sArYHM0PGAD/dTVccgn9Bg1qyZCcc65VaEqi7wssT3hfRBgqcAdJfYGzgRNpJNE3x+DgWf9zXZjJzg6jWtS85ubCkCEwfHjLDbPunHOtVFMSfX2XJOt2ZH4LcJWZVauRK5jNMjj4VVft0WbOOZfOmpLoi4D+Ce/7ASvrrDMKeCxK8t2B0yVVmdkzTTiuc8653dCURP8hMFTSYGAFMAE4N3EFMxtcMy/pr8DznuSdc27v2uNEb2ZVki4j3E0TA+43s1mSJkXL726mGJ1zzjVBk+6jN7MpwJQ6ZfUmeDO7sCnHcs45t2fazJOxlZWVFBUVsX17PbdPppHc3Fz69etHVlZWqkNxzqWJNpPoi4qK6NixI4MGDaKxO3jaKjNj/fr1FBUVMXjw4MY3cM65JLSZEei2b99Ot27d0jbJA0iiW7duaf+rxTm3d7WZRA+kdZKv0R7q6Jzbu9pUonfOObf7PNEnadOmTdx55527vd3pp5/Opk2bmj8g55xLkif6JDWU6Kurq3e53ZQpU+jSpUsLReWcc41rM3fdJPrhD2HmzObd58iRcMstDS+/+uqrWbhwISNHjiQrK4uCggJ69+7NzJkzmT17NmeddRbLly9n+/btXH755UycOBGAQYMGMX36dEpKShg3bhxjxozh3XffpW/fvjz77LPk5eU1b0Wcc64OP6NP0k033cSQIUOYOXMmv//975k2bRo33HADs2eHXpnvv/9+ZsyYwfTp07nttttYv3795/Yxf/58Lr30UmbNmkWXLl148skn93Y1nHPtUJs8o9/VmffeMnr06J3udb/tttt4+umnAVi+fDnz58+nW7duO20zePBgRo4cCcAXv/hFlixZsrfCdc61Y20y0bcG+fn5O+bffPNNXn31Vd577z06dOjA2LFj670XPicnZ8d8LBajrKxsr8TqnGvfvOkmSR07dmTr1q31Ltu8eTOFhYV06NCBuXPn8v777+/l6JxzrmF+Rp+kbt26ccwxx3DQQQeRl5dHr169diw77bTTuPvuuzn44IPZf//9OfLII1MYqXPO7UxmezaYE4Ck04BbCd0U32tmN9VZ/k2gZtinEuC/zOyjxvY7atQomz59+k5lc+bMYcSIEXsca1vSnurqnGsekmaY2aj6lu1x042kGHAHMA44ADhH0gF1VlsMHG9mBwO/Jhoq0Dnn3N7TlDb60cACM1tkZhXAY8CZiSuY2btmtjF6+z5huEHnnHN7UVMSfV9gecL7oqisId8B/tnQQkkTJU2XNH3dunVNCMs551yipiT6+rpZrLfBX9IJhER/VX3LAczsHjMbZWajevTo0YSwnHPOJWrKXTdFQP+E9/2AlXVXknQwcC8wzsw+/7ioc865FtWUM/oPgaGSBkvKBiYAkxNXkDQAeAo438w+a8KxnHPO7aE9TvRmVgVcBrwEzAEeN7NZkiZJmhSt9kugG3CnpJmSpjewu1ZvT7spBrjlllvYtm1bM0fknHPJadKTsWY2xcyGmdkQM7shKrvbzO6O5i82s0IzGxlN9d7j2RZ4onfOtVVt88nYFPRTnNhN8cknn0zPnj15/PHHKS8v5+yzz+b666+ntLSU//zP/6SoqIjq6mquvfZa1qxZw8qVKznhhBPo3r07b7zxRvPG7ZxzjWibiT4FbrrpJj799FNmzpzJyy+/zBNPPMG0adMwM8444wzefvtt1q1bR58+fXjhhReA0AdO586dufnmm3njjTfo3r17imvhnGuP2maiT3E/xS+//DIvv/wyhx56KAAlJSXMnz+fY489liuvvJKrrrqK8ePHc+yxx6Y0Tuecg7aa6FPMzLjmmmv47ne/+7llM2bMYMqUKVxzzTWccsop/PKXv0xBhM45V8u7KU5SYjfFp556Kvfffz8lJSUArFixgrVr17Jy5Uo6dOjAeeedx5VXXsm//vWvz23rnHN7m5/RJymxm+Jx48Zx7rnnctRRRwFQUFDAI488woIFC/jJT35CRkYGWVlZ3HXXXQBMnDiRcePG0bt3b78Y65zb65rUTXFL8W6K209dnXPNo0W6KXbOOdc2eKJ3zrk016YSfWtsZmpu7aGOzrm9q80k+tzcXNavX5/WidDMWL9+Pbm5uakOxTmXRtrMXTf9+vWjqKiIdB+UJDc3l379fCAu51zzaTOJPisri8GDB6c6DOeca3Oa1HQj6TRJ8yQtkHR1Pcsl6bZo+ceSDmvK8Zxzzu2+PU70kmLAHcA44ADgHEkH1FltHDA0miYCd+3p8Zxzzu2ZppzRjwYWmNkiM6sAHgPOrLPOmcBDFrwPdJHUuwnHdM45t5ua0kbfF1ie8L4IOCKJdfoCq+ruTNJEwlk/QImkeXsYV3egeA+3bSvaQx2hfdSzPdQR2kc9U13HgQ0taEqiVz1lde99TGadUGh2D3BPE+IJB5Smt+WRrJLRHuoI7aOe7aGO0D7q2Zrr2JSmmyKgf8L7fsDKPVjHOedcC2pKov8QGCppsKRsYAIwuc46k4FvRXffHAlsNrPPNds455xrOXvcdGNmVZIuA14CYsD9ZjZL0qRo+d3AFOB0YAGwDbio6SE3qsnNP21Ae6gjtI96toc6QvuoZ6utY6vsptg551zzaTN93TjnnNsznuidcy7NpU2ib6w7hrZKUn9Jb0iaI2mWpMuj8q6SXpE0P3otTHWsTSUpJunfkp6P3qdVHSV1kfSEpLnR3/OodKsjgKQfRf9WP5X0qKTctl5PSfdLWivp04SyBusk6ZooF82TdGpqoq6VFok+ye4Y2qoq4AozGwEcCVwa1e1q4DUzGwq8Fr1v6y4H5iS8T7c63gq8aGbDgUMIdU2rOkrqC/wAGGVmBxFu1JhA26/nX4HT6pTVW6fo/+cE4MBomzujHJUyaZHoSa47hjbJzFaZ2b+i+a2E5NCXUL8Ho9UeBM5KSYDNRFI/4MvAvQnFaVNHSZ2A44D7AMyswsw2kUZ1TJAJ5EnKBDoQnp1p0/U0s7eBDXWKG6rTmcBjZlZuZosJdx2O3htxNiRdEn1DXS2kFUmDgEOBD4BeNc8kRK89Uxhac7gF+CkQTyhLpzruC6wDHoiap+6VlE961REzWwH8AVhG6Opks5m9TJrVM9JQnVpdPkqXRJ90VwttlaQC4Engh2a2JdXxNCdJ44G1ZjYj1bG0oEzgMOAuMzsUKKXtNV80KmqnPhMYDPQB8iWdl9qo9rpWl4/SJdGndVcLkrIISf5vZvZUVLympifQ6HVtquJrBscAZ0haQmh2O1HSI6RXHYuAIjP7IHr/BCHxp1MdAb4ELDazdWZWCTwFHE361RMarlOry0fpkuiT6Y6hTZIkQrvuHDO7OWHRZOCCaP4C4Nm9HVtzMbNrzKyfmQ0i/O1eN7PzSK86rgaWS9o/KjoJmE0a1TGyDDhSUofo3+5JhOtK6VZPaLhOk4EJknIkDSaMxzEtBfHVMrO0mAhdLXwGLAR+nup4mrFeYwg/+z4GZkbT6UA3wpX++dFr11TH2kz1HQs8H82nVR2BkcD06G/5DFCYbnWM6nk9MBf4FHgYyGnr9QQeJVxzqCScsX9nV3UCfh7lonnAuFTH710gOOdcmkuXphvnnHMN8ETvnHNpzhO9c86lOU/0zjmX5jzRO+dcmvNE75xzac4TvXPOpbn/D/D8UiHrFjNhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss as a function of epochs\n",
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.ylim(0.8,1)\n",
    "\n",
    "# plot accuracy\n",
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label = 'test')\n",
    "plt.ylim(0, 0.8)\n",
    "plt.legend()\n",
    "\n",
    "# Tweak spacing between subplots to prevent labels from overlapping\n",
    "plt.subplots_adjust(hspace = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q4** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Compute the WtP of the average decision maker to reduce the share of foreigners in a neighbourhood by 1 percentage point using the results from the hybrid model. Compare the outcome with the results of your discrete choice model (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta_STORES    =  -0.045\n",
      "Beta_FOREIGN =  -1.492\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  33.49 min per percentage point\n"
     ]
    }
   ],
   "source": [
    "# Show the trained taste parameters, from the MNL part\n",
    "beta_STORES = np.squeeze((betas[0][0]))\n",
    "beta_FOREIGN = np.squeeze((betas[0][1]))\n",
    "print('Beta_STORES    = ', \"{:.3f}\".format(beta_STORES )) \n",
    "print('Beta_FOREIGN = ', \"{:.3f}\".format(beta_FOREIGN ))\n",
    "\n",
    "# Compute the Willingness to Pay for a Gb extra storage space\n",
    "WtP_foreign_stores_mnl = beta_FOREIGN/beta_STORES\n",
    "print('Willingness-to-Pay estimates Hybrid model')\n",
    "print('----------')\n",
    "\n",
    "print('Willingness to Pay; reduction in foreigners at an expense of store distance = ', \"{:.2f}\".format(WtP_foreign_stores_mnl),'min per percentage point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy training data at final epoch  =  0.835\n",
      "Log-likelihood training data at final epoch =  -5240.5\n",
      "rho square training data at final epoch     =  0.24\n",
      "\n",
      "Cross-entropy test data at final epoch     =  0.833\n",
      "Log-likelihood test data at final epoch    =  -2814.6\n",
      "rho square test data at final epoch        =  0.24\n"
     ]
    }
   ],
   "source": [
    "# For comparison convert the loss to log-likelihood and rho^2\n",
    "hist_loss_train = history.history.get('loss')\n",
    "LL_final_train = -np.array(hist_loss_train[len(hist_loss_train)-1]) *len(Y_train)\n",
    "print('Cross-entropy training data at final epoch  = ', \"{:.3f}\".format(hist_loss_train[len(hist_loss_train)-1]))\n",
    "print('Log-likelihood training data at final epoch = ', \"{:.1f}\".format(LL_final_train))\n",
    "print('rho square training data at final epoch     = ', \"{:.2f}\".format(1 - LL_final_train / -(len(Y_train)*np.log(3))))\n",
    "print()\n",
    "\n",
    "hist_loss_test = history.history.get('val_loss')\n",
    "LL_final_test = -np.array(hist_loss_test[len(hist_loss_test)-1]) *len(Y_test)\n",
    "print('Cross-entropy test data at final epoch     = ', \"{:.3f}\".format(hist_loss_test[len(hist_loss_test)-1]))\n",
    "print('Log-likelihood test data at final epoch    = ', \"{:.1f}\".format(LL_final_test))\n",
    "print('rho square test data at final epoch        = ', \"{:.2f}\".format(1 - LL_final_test / -(len(Y_test)*np.log(3))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q5** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Explore whether, or not, the preferences of the inhabitants of the four cities regarding the trade-off between share of foreigners and distance to grocery stores are equal across the four cities. (1.5 pts)\n",
    "\n",
    "Perform a series of (clever) analyses, and interpret the findings. In other words, can we conclude that the inhabintants of all cities are equally xenophobic? For these analysis, use hybrid models, and/or DCMs.\n",
    "\n",
    "**Hint:** create new features capturing for the share of foreigners *per city*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the hybrid model because the cross entropy is the lowest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl (2272, 2, 3, 1)\n",
      "Shape of x_ann (2272, 16)\n",
      "\n",
      "Total number of obervations in the data set =  2272\n",
      "Number of obervations in the training set   =  1476\n",
      "Number of obervations in the test set       =  796\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 2.3994 - accuracy: 0.4282 - val_loss: 2.4662 - val_accuracy: 0.3894\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.3072 - accuracy: 0.4343 - val_loss: 2.3710 - val_accuracy: 0.3869\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2195 - accuracy: 0.4350 - val_loss: 2.2812 - val_accuracy: 0.3894\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1360 - accuracy: 0.4343 - val_loss: 2.1966 - val_accuracy: 0.3957\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.0564 - accuracy: 0.4390 - val_loss: 2.1171 - val_accuracy: 0.4083\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9808 - accuracy: 0.4424 - val_loss: 2.0429 - val_accuracy: 0.4133\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9093 - accuracy: 0.4533 - val_loss: 1.9743 - val_accuracy: 0.4196\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.8423 - accuracy: 0.4560 - val_loss: 1.9113 - val_accuracy: 0.4309\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.7802 - accuracy: 0.4614 - val_loss: 1.8540 - val_accuracy: 0.4347\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.7232 - accuracy: 0.4648 - val_loss: 1.8019 - val_accuracy: 0.4472\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6712 - accuracy: 0.4743 - val_loss: 1.7543 - val_accuracy: 0.4686\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6238 - accuracy: 0.5068 - val_loss: 1.7102 - val_accuracy: 0.4698\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.5800 - accuracy: 0.5047 - val_loss: 1.6685 - val_accuracy: 0.4673\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5392 - accuracy: 0.5027 - val_loss: 1.6284 - val_accuracy: 0.4698\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5005 - accuracy: 0.5054 - val_loss: 1.5892 - val_accuracy: 0.4749\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4636 - accuracy: 0.5047 - val_loss: 1.5505 - val_accuracy: 0.4761\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4280 - accuracy: 0.5014 - val_loss: 1.5122 - val_accuracy: 0.4824\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3935 - accuracy: 0.5102 - val_loss: 1.4743 - val_accuracy: 0.4862\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3601 - accuracy: 0.5190 - val_loss: 1.4368 - val_accuracy: 0.4912\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3277 - accuracy: 0.5224 - val_loss: 1.4000 - val_accuracy: 0.4987\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2962 - accuracy: 0.5264 - val_loss: 1.3641 - val_accuracy: 0.5025\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2657 - accuracy: 0.5285 - val_loss: 1.3291 - val_accuracy: 0.5050\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.2362 - accuracy: 0.5325 - val_loss: 1.2953 - val_accuracy: 0.5101\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2077 - accuracy: 0.5373 - val_loss: 1.2628 - val_accuracy: 0.5101\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1802 - accuracy: 0.5373 - val_loss: 1.2316 - val_accuracy: 0.5163\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1538 - accuracy: 0.5440 - val_loss: 1.2020 - val_accuracy: 0.5214\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1287 - accuracy: 0.5440 - val_loss: 1.1740 - val_accuracy: 0.5302\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1049 - accuracy: 0.5461 - val_loss: 1.1477 - val_accuracy: 0.5327\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0826 - accuracy: 0.5522 - val_loss: 1.1231 - val_accuracy: 0.5327\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0619 - accuracy: 0.5522 - val_loss: 1.1004 - val_accuracy: 0.5327\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0427 - accuracy: 0.5589 - val_loss: 1.0793 - val_accuracy: 0.5415\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0251 - accuracy: 0.5684 - val_loss: 1.0599 - val_accuracy: 0.5452\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0090 - accuracy: 0.5745 - val_loss: 1.0420 - val_accuracy: 0.5477\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9943 - accuracy: 0.5772 - val_loss: 1.0255 - val_accuracy: 0.5503\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9808 - accuracy: 0.5813 - val_loss: 1.0103 - val_accuracy: 0.5603\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9684 - accuracy: 0.5793 - val_loss: 0.9962 - val_accuracy: 0.5628\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9569 - accuracy: 0.5908 - val_loss: 0.9831 - val_accuracy: 0.5704\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9462 - accuracy: 0.5874 - val_loss: 0.9711 - val_accuracy: 0.5716\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9361 - accuracy: 0.5881 - val_loss: 0.9599 - val_accuracy: 0.5616\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9266 - accuracy: 0.5874 - val_loss: 0.9497 - val_accuracy: 0.5590\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9176 - accuracy: 0.5847 - val_loss: 0.9404 - val_accuracy: 0.5590\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9092 - accuracy: 0.5840 - val_loss: 0.9318 - val_accuracy: 0.5565\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9013 - accuracy: 0.5813 - val_loss: 0.9240 - val_accuracy: 0.5503\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8940 - accuracy: 0.5820 - val_loss: 0.9169 - val_accuracy: 0.5490\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8871 - accuracy: 0.5806 - val_loss: 0.9104 - val_accuracy: 0.5503\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8807 - accuracy: 0.5766 - val_loss: 0.9044 - val_accuracy: 0.5503\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8748 - accuracy: 0.5766 - val_loss: 0.8989 - val_accuracy: 0.5528\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8693 - accuracy: 0.5752 - val_loss: 0.8938 - val_accuracy: 0.5503\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8643 - accuracy: 0.5718 - val_loss: 0.8891 - val_accuracy: 0.5528\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8596 - accuracy: 0.5732 - val_loss: 0.8848 - val_accuracy: 0.5553\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8553 - accuracy: 0.5772 - val_loss: 0.8807 - val_accuracy: 0.5565\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8515 - accuracy: 0.5799 - val_loss: 0.8770 - val_accuracy: 0.5616\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8480 - accuracy: 0.5894 - val_loss: 0.8736 - val_accuracy: 0.5666\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8448 - accuracy: 0.5908 - val_loss: 0.8705 - val_accuracy: 0.5741\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8420 - accuracy: 0.5962 - val_loss: 0.8677 - val_accuracy: 0.5791\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8395 - accuracy: 0.6030 - val_loss: 0.8652 - val_accuracy: 0.5817\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8373 - accuracy: 0.6003 - val_loss: 0.8630 - val_accuracy: 0.5854\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8354 - accuracy: 0.6064 - val_loss: 0.8611 - val_accuracy: 0.5829\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8337 - accuracy: 0.6138 - val_loss: 0.8593 - val_accuracy: 0.5842\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8322 - accuracy: 0.6152 - val_loss: 0.8578 - val_accuracy: 0.5854\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8310 - accuracy: 0.6192 - val_loss: 0.8566 - val_accuracy: 0.5917\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8299 - accuracy: 0.6213 - val_loss: 0.8555 - val_accuracy: 0.6068\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8290 - accuracy: 0.6206 - val_loss: 0.8545 - val_accuracy: 0.6030\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8282 - accuracy: 0.6226 - val_loss: 0.8538 - val_accuracy: 0.6068\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8275 - accuracy: 0.6267 - val_loss: 0.8532 - val_accuracy: 0.6068\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8270 - accuracy: 0.6247 - val_loss: 0.8528 - val_accuracy: 0.6055\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8265 - accuracy: 0.6260 - val_loss: 0.8525 - val_accuracy: 0.6118\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8262 - accuracy: 0.6280 - val_loss: 0.8522 - val_accuracy: 0.6131\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8259 - accuracy: 0.6280 - val_loss: 0.8521 - val_accuracy: 0.6131\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8256 - accuracy: 0.6280 - val_loss: 0.8521 - val_accuracy: 0.6156\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8254 - accuracy: 0.6308 - val_loss: 0.8521 - val_accuracy: 0.6168\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8252 - accuracy: 0.6348 - val_loss: 0.8521 - val_accuracy: 0.6181\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8251 - accuracy: 0.6328 - val_loss: 0.8521 - val_accuracy: 0.6181\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8249 - accuracy: 0.6321 - val_loss: 0.8521 - val_accuracy: 0.6206\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8248 - accuracy: 0.6328 - val_loss: 0.8521 - val_accuracy: 0.6193\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.825\n",
      "Shape of x_mnl (1704, 2, 3, 1)\n",
      "Shape of x_ann (1704, 16)\n",
      "\n",
      "Total number of obervations in the data set =  1704\n",
      "Number of obervations in the training set   =  1107\n",
      "Number of obervations in the test set       =  597\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 2.4731 - accuracy: 0.4110 - val_loss: 2.4390 - val_accuracy: 0.3936\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.3687 - accuracy: 0.4173 - val_loss: 2.3474 - val_accuracy: 0.3920\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2708 - accuracy: 0.4246 - val_loss: 2.2598 - val_accuracy: 0.3936\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1784 - accuracy: 0.4327 - val_loss: 2.1757 - val_accuracy: 0.4003\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.0906 - accuracy: 0.4372 - val_loss: 2.0953 - val_accuracy: 0.4020\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.0071 - accuracy: 0.4417 - val_loss: 2.0189 - val_accuracy: 0.4020\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.9279 - accuracy: 0.4444 - val_loss: 1.9474 - val_accuracy: 0.4104\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.8536 - accuracy: 0.4535 - val_loss: 1.8812 - val_accuracy: 0.4188\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.7845 - accuracy: 0.4562 - val_loss: 1.8207 - val_accuracy: 0.4271\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.7209 - accuracy: 0.4607 - val_loss: 1.7656 - val_accuracy: 0.4422\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6628 - accuracy: 0.4652 - val_loss: 1.7157 - val_accuracy: 0.4523\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6100 - accuracy: 0.4770 - val_loss: 1.6705 - val_accuracy: 0.4556\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5623 - accuracy: 0.4878 - val_loss: 1.6296 - val_accuracy: 0.4791\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5192 - accuracy: 0.5131 - val_loss: 1.5924 - val_accuracy: 0.4925\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4804 - accuracy: 0.5212 - val_loss: 1.5583 - val_accuracy: 0.5042\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4450 - accuracy: 0.5276 - val_loss: 1.5266 - val_accuracy: 0.5109\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4123 - accuracy: 0.5357 - val_loss: 1.4966 - val_accuracy: 0.5276\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3816 - accuracy: 0.5393 - val_loss: 1.4678 - val_accuracy: 0.5327\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3524 - accuracy: 0.5429 - val_loss: 1.4396 - val_accuracy: 0.5377\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.3243 - accuracy: 0.5474 - val_loss: 1.4117 - val_accuracy: 0.5427\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2968 - accuracy: 0.5547 - val_loss: 1.3839 - val_accuracy: 0.5410\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2698 - accuracy: 0.5619 - val_loss: 1.3563 - val_accuracy: 0.5444\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2433 - accuracy: 0.5664 - val_loss: 1.3287 - val_accuracy: 0.5494\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2171 - accuracy: 0.5700 - val_loss: 1.3014 - val_accuracy: 0.5461\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1913 - accuracy: 0.5763 - val_loss: 1.2745 - val_accuracy: 0.5477\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1658 - accuracy: 0.5863 - val_loss: 1.2481 - val_accuracy: 0.5528\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1409 - accuracy: 0.5935 - val_loss: 1.2225 - val_accuracy: 0.5595\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1166 - accuracy: 0.5935 - val_loss: 1.1978 - val_accuracy: 0.5611\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0930 - accuracy: 0.5989 - val_loss: 1.1742 - val_accuracy: 0.5628\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0703 - accuracy: 0.6043 - val_loss: 1.1519 - val_accuracy: 0.5662\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0487 - accuracy: 0.6043 - val_loss: 1.1310 - val_accuracy: 0.5645\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0282 - accuracy: 0.6052 - val_loss: 1.1115 - val_accuracy: 0.5645\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.0090 - accuracy: 0.6043 - val_loss: 1.0935 - val_accuracy: 0.5645\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9911 - accuracy: 0.6089 - val_loss: 1.0769 - val_accuracy: 0.5662\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9747 - accuracy: 0.6107 - val_loss: 1.0617 - val_accuracy: 0.5662\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9596 - accuracy: 0.6134 - val_loss: 1.0478 - val_accuracy: 0.5712\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9457 - accuracy: 0.6206 - val_loss: 1.0348 - val_accuracy: 0.5779\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9329 - accuracy: 0.6179 - val_loss: 1.0227 - val_accuracy: 0.5946\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9211 - accuracy: 0.6305 - val_loss: 1.0113 - val_accuracy: 0.5963\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9102 - accuracy: 0.6305 - val_loss: 1.0004 - val_accuracy: 0.5980\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9000 - accuracy: 0.6242 - val_loss: 0.9899 - val_accuracy: 0.5963\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8904 - accuracy: 0.6242 - val_loss: 0.9798 - val_accuracy: 0.5963\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8814 - accuracy: 0.6242 - val_loss: 0.9701 - val_accuracy: 0.5946\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8730 - accuracy: 0.6224 - val_loss: 0.9607 - val_accuracy: 0.5963\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8651 - accuracy: 0.6251 - val_loss: 0.9516 - val_accuracy: 0.5997\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8578 - accuracy: 0.6287 - val_loss: 0.9430 - val_accuracy: 0.6013\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8510 - accuracy: 0.6278 - val_loss: 0.9347 - val_accuracy: 0.6030\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8447 - accuracy: 0.6287 - val_loss: 0.9269 - val_accuracy: 0.6030\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8388 - accuracy: 0.6269 - val_loss: 0.9195 - val_accuracy: 0.6013\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8334 - accuracy: 0.6332 - val_loss: 0.9126 - val_accuracy: 0.6013\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8284 - accuracy: 0.6332 - val_loss: 0.9062 - val_accuracy: 0.5997\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8237 - accuracy: 0.6341 - val_loss: 0.9004 - val_accuracy: 0.5997\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8195 - accuracy: 0.6314 - val_loss: 0.8950 - val_accuracy: 0.5980\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8156 - accuracy: 0.6314 - val_loss: 0.8902 - val_accuracy: 0.5963\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8121 - accuracy: 0.6360 - val_loss: 0.8860 - val_accuracy: 0.5997\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8088 - accuracy: 0.6360 - val_loss: 0.8822 - val_accuracy: 0.6030\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8059 - accuracy: 0.6360 - val_loss: 0.8789 - val_accuracy: 0.6080\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8032 - accuracy: 0.6287 - val_loss: 0.8761 - val_accuracy: 0.6030\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8008 - accuracy: 0.6305 - val_loss: 0.8737 - val_accuracy: 0.6030\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7986 - accuracy: 0.6269 - val_loss: 0.8717 - val_accuracy: 0.6080\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7966 - accuracy: 0.6278 - val_loss: 0.8701 - val_accuracy: 0.6047\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7948 - accuracy: 0.6314 - val_loss: 0.8688 - val_accuracy: 0.6080\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7931 - accuracy: 0.6332 - val_loss: 0.8678 - val_accuracy: 0.6064\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7917 - accuracy: 0.6350 - val_loss: 0.8670 - val_accuracy: 0.6064\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7904 - accuracy: 0.6350 - val_loss: 0.8664 - val_accuracy: 0.6047\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7892 - accuracy: 0.6360 - val_loss: 0.8660 - val_accuracy: 0.6047\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7882 - accuracy: 0.6369 - val_loss: 0.8657 - val_accuracy: 0.6064\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7873 - accuracy: 0.6369 - val_loss: 0.8655 - val_accuracy: 0.6013\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7865 - accuracy: 0.6396 - val_loss: 0.8654 - val_accuracy: 0.5997\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7858 - accuracy: 0.6387 - val_loss: 0.8654 - val_accuracy: 0.5997\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7851 - accuracy: 0.6378 - val_loss: 0.8654 - val_accuracy: 0.6013\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7845 - accuracy: 0.6350 - val_loss: 0.8655 - val_accuracy: 0.5997\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7840 - accuracy: 0.6350 - val_loss: 0.8656 - val_accuracy: 0.5997\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7836 - accuracy: 0.6360 - val_loss: 0.8658 - val_accuracy: 0.5997\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.784\n",
      "Shape of x_mnl (3144, 2, 3, 1)\n",
      "Shape of x_ann (3144, 16)\n",
      "\n",
      "Total number of obervations in the data set =  3144\n",
      "Number of obervations in the training set   =  2043\n",
      "Number of obervations in the test set       =  1101\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 518ms/step - loss: 2.4666 - accuracy: 0.4121 - val_loss: 2.5499 - val_accuracy: 0.3942\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3647 - accuracy: 0.4161 - val_loss: 2.4522 - val_accuracy: 0.3951\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.2683 - accuracy: 0.4141 - val_loss: 2.3605 - val_accuracy: 0.3869\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1768 - accuracy: 0.4131 - val_loss: 2.2739 - val_accuracy: 0.3924\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0899 - accuracy: 0.4190 - val_loss: 2.1922 - val_accuracy: 0.3960\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0071 - accuracy: 0.4293 - val_loss: 2.1152 - val_accuracy: 0.4024\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9288 - accuracy: 0.4381 - val_loss: 2.0430 - val_accuracy: 0.4096\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8552 - accuracy: 0.4425 - val_loss: 1.9758 - val_accuracy: 0.4169\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.7866 - accuracy: 0.4479 - val_loss: 1.9138 - val_accuracy: 0.4323\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7236 - accuracy: 0.4552 - val_loss: 1.8568 - val_accuracy: 0.4432\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.6664 - accuracy: 0.4743 - val_loss: 1.8043 - val_accuracy: 0.4478\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6147 - accuracy: 0.4851 - val_loss: 1.7555 - val_accuracy: 0.4696\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5678 - accuracy: 0.4934 - val_loss: 1.7094 - val_accuracy: 0.4759\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5248 - accuracy: 0.5091 - val_loss: 1.6651 - val_accuracy: 0.4823\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4844 - accuracy: 0.5169 - val_loss: 1.6219 - val_accuracy: 0.4796\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4460 - accuracy: 0.5218 - val_loss: 1.5796 - val_accuracy: 0.4796\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4090 - accuracy: 0.5252 - val_loss: 1.5381 - val_accuracy: 0.4805\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3733 - accuracy: 0.5311 - val_loss: 1.4977 - val_accuracy: 0.4805\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3390 - accuracy: 0.5301 - val_loss: 1.4587 - val_accuracy: 0.4814\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3064 - accuracy: 0.5291 - val_loss: 1.4215 - val_accuracy: 0.4787\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2757 - accuracy: 0.5247 - val_loss: 1.3860 - val_accuracy: 0.4796\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2470 - accuracy: 0.5233 - val_loss: 1.3525 - val_accuracy: 0.4787\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2203 - accuracy: 0.5247 - val_loss: 1.3206 - val_accuracy: 0.4787\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1952 - accuracy: 0.5242 - val_loss: 1.2900 - val_accuracy: 0.4886\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1713 - accuracy: 0.5316 - val_loss: 1.2606 - val_accuracy: 0.5032\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1482 - accuracy: 0.5370 - val_loss: 1.2322 - val_accuracy: 0.5005\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1258 - accuracy: 0.5355 - val_loss: 1.2047 - val_accuracy: 0.5023\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.1040 - accuracy: 0.5370 - val_loss: 1.1782 - val_accuracy: 0.4995\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0828 - accuracy: 0.5399 - val_loss: 1.1529 - val_accuracy: 0.5086\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0624 - accuracy: 0.5482 - val_loss: 1.1289 - val_accuracy: 0.5077\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.0429 - accuracy: 0.5433 - val_loss: 1.1065 - val_accuracy: 0.5086\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0245 - accuracy: 0.5438 - val_loss: 1.0858 - val_accuracy: 0.5032\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0074 - accuracy: 0.5458 - val_loss: 1.0669 - val_accuracy: 0.5132\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9915 - accuracy: 0.5512 - val_loss: 1.0497 - val_accuracy: 0.5232\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9769 - accuracy: 0.5595 - val_loss: 1.0342 - val_accuracy: 0.5277\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9635 - accuracy: 0.5658 - val_loss: 1.0202 - val_accuracy: 0.5350\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9514 - accuracy: 0.5649 - val_loss: 1.0075 - val_accuracy: 0.5404\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9402 - accuracy: 0.5727 - val_loss: 0.9961 - val_accuracy: 0.5468\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9301 - accuracy: 0.5746 - val_loss: 0.9858 - val_accuracy: 0.5559\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9208 - accuracy: 0.5786 - val_loss: 0.9762 - val_accuracy: 0.5595\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9123 - accuracy: 0.5805 - val_loss: 0.9674 - val_accuracy: 0.5613\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9045 - accuracy: 0.5830 - val_loss: 0.9591 - val_accuracy: 0.5649\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8973 - accuracy: 0.5820 - val_loss: 0.9513 - val_accuracy: 0.5640\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8905 - accuracy: 0.5810 - val_loss: 0.9438 - val_accuracy: 0.5631\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8841 - accuracy: 0.5839 - val_loss: 0.9366 - val_accuracy: 0.5613\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8782 - accuracy: 0.5844 - val_loss: 0.9297 - val_accuracy: 0.5595\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8726 - accuracy: 0.5859 - val_loss: 0.9231 - val_accuracy: 0.5604\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8674 - accuracy: 0.5854 - val_loss: 0.9167 - val_accuracy: 0.5631\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8625 - accuracy: 0.5874 - val_loss: 0.9106 - val_accuracy: 0.5658\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.8580 - accuracy: 0.5879 - val_loss: 0.9047 - val_accuracy: 0.5640\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8538 - accuracy: 0.5923 - val_loss: 0.8989 - val_accuracy: 0.5649\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8498 - accuracy: 0.5913 - val_loss: 0.8935 - val_accuracy: 0.5668\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8462 - accuracy: 0.5928 - val_loss: 0.8882 - val_accuracy: 0.5640\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8428 - accuracy: 0.5913 - val_loss: 0.8831 - val_accuracy: 0.5686\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8397 - accuracy: 0.5977 - val_loss: 0.8784 - val_accuracy: 0.5731\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8368 - accuracy: 0.5952 - val_loss: 0.8738 - val_accuracy: 0.5777\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8343 - accuracy: 0.5977 - val_loss: 0.8696 - val_accuracy: 0.5758\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8319 - accuracy: 0.6001 - val_loss: 0.8657 - val_accuracy: 0.5749\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8299 - accuracy: 0.5986 - val_loss: 0.8620 - val_accuracy: 0.5777\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8280 - accuracy: 0.6006 - val_loss: 0.8586 - val_accuracy: 0.5849\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8264 - accuracy: 0.6025 - val_loss: 0.8555 - val_accuracy: 0.5886\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8249 - accuracy: 0.6035 - val_loss: 0.8526 - val_accuracy: 0.5931\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8236 - accuracy: 0.6065 - val_loss: 0.8500 - val_accuracy: 0.5995\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8225 - accuracy: 0.6074 - val_loss: 0.8476 - val_accuracy: 0.5976\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8215 - accuracy: 0.6070 - val_loss: 0.8455 - val_accuracy: 0.5995\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8207 - accuracy: 0.6084 - val_loss: 0.8435 - val_accuracy: 0.6013\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8199 - accuracy: 0.6055 - val_loss: 0.8417 - val_accuracy: 0.6031\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8193 - accuracy: 0.6094 - val_loss: 0.8400 - val_accuracy: 0.6085\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8187 - accuracy: 0.6104 - val_loss: 0.8386 - val_accuracy: 0.6122\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8183 - accuracy: 0.6148 - val_loss: 0.8373 - val_accuracy: 0.6167\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8179 - accuracy: 0.6163 - val_loss: 0.8361 - val_accuracy: 0.6194\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8175 - accuracy: 0.6172 - val_loss: 0.8351 - val_accuracy: 0.6203\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8172 - accuracy: 0.6167 - val_loss: 0.8342 - val_accuracy: 0.6276\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8170 - accuracy: 0.6182 - val_loss: 0.8335 - val_accuracy: 0.6312\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8168 - accuracy: 0.6163 - val_loss: 0.8329 - val_accuracy: 0.6358\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8166 - accuracy: 0.6163 - val_loss: 0.8323 - val_accuracy: 0.6367\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8164 - accuracy: 0.6148 - val_loss: 0.8319 - val_accuracy: 0.6403\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8162 - accuracy: 0.6167 - val_loss: 0.8315 - val_accuracy: 0.6394\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8160 - accuracy: 0.6158 - val_loss: 0.8312 - val_accuracy: 0.6403\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.8159 - accuracy: 0.6177 - val_loss: 0.8309 - val_accuracy: 0.6403\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8157 - accuracy: 0.6187 - val_loss: 0.8307 - val_accuracy: 0.6394\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8155 - accuracy: 0.6172 - val_loss: 0.8305 - val_accuracy: 0.6385\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8154 - accuracy: 0.6187 - val_loss: 0.8303 - val_accuracy: 0.6394\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8152 - accuracy: 0.6197 - val_loss: 0.8302 - val_accuracy: 0.6403\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.8150 - accuracy: 0.6202 - val_loss: 0.8300 - val_accuracy: 0.6394\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8149 - accuracy: 0.6197 - val_loss: 0.8299 - val_accuracy: 0.6403\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8147 - accuracy: 0.6197 - val_loss: 0.8299 - val_accuracy: 0.6403\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8145 - accuracy: 0.6192 - val_loss: 0.8298 - val_accuracy: 0.6403\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8144 - accuracy: 0.6197 - val_loss: 0.8298 - val_accuracy: 0.6394\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8142 - accuracy: 0.6197 - val_loss: 0.8298 - val_accuracy: 0.6394\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8140 - accuracy: 0.6192 - val_loss: 0.8298 - val_accuracy: 0.6376\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8139 - accuracy: 0.6211 - val_loss: 0.8299 - val_accuracy: 0.6367\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8137 - accuracy: 0.6197 - val_loss: 0.8299 - val_accuracy: 0.6358\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.814\n",
      "Shape of x_mnl (2536, 2, 3, 1)\n",
      "Shape of x_ann (2536, 16)\n",
      "\n",
      "Total number of obervations in the data set =  2536\n",
      "Number of obervations in the training set   =  1648\n",
      "Number of obervations in the test set       =  888\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 2.4008 - accuracy: 0.4254 - val_loss: 2.4214 - val_accuracy: 0.4189\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.2981 - accuracy: 0.4278 - val_loss: 2.3301 - val_accuracy: 0.4200\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2014 - accuracy: 0.4302 - val_loss: 2.2445 - val_accuracy: 0.4167\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.1104 - accuracy: 0.4333 - val_loss: 2.1643 - val_accuracy: 0.4212\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.0248 - accuracy: 0.4351 - val_loss: 2.0896 - val_accuracy: 0.4268\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9446 - accuracy: 0.4363 - val_loss: 2.0206 - val_accuracy: 0.4302\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8702 - accuracy: 0.4454 - val_loss: 1.9580 - val_accuracy: 0.4437\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8022 - accuracy: 0.4557 - val_loss: 1.9019 - val_accuracy: 0.4516\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.7410 - accuracy: 0.4660 - val_loss: 1.8519 - val_accuracy: 0.4606\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6866 - accuracy: 0.4757 - val_loss: 1.8074 - val_accuracy: 0.4718\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6386 - accuracy: 0.4836 - val_loss: 1.7670 - val_accuracy: 0.4752\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5960 - accuracy: 0.4970 - val_loss: 1.7290 - val_accuracy: 0.4842\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.5576 - accuracy: 0.4988 - val_loss: 1.6924 - val_accuracy: 0.4932\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.5222 - accuracy: 0.5073 - val_loss: 1.6560 - val_accuracy: 0.4989\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4886 - accuracy: 0.5133 - val_loss: 1.6195 - val_accuracy: 0.4955\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4563 - accuracy: 0.5164 - val_loss: 1.5827 - val_accuracy: 0.5045\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4248 - accuracy: 0.5176 - val_loss: 1.5458 - val_accuracy: 0.5034\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3939 - accuracy: 0.5255 - val_loss: 1.5091 - val_accuracy: 0.5045\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3636 - accuracy: 0.5303 - val_loss: 1.4727 - val_accuracy: 0.5068\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3338 - accuracy: 0.5352 - val_loss: 1.4367 - val_accuracy: 0.5090\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3046 - accuracy: 0.5346 - val_loss: 1.4014 - val_accuracy: 0.5034\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.2760 - accuracy: 0.5370 - val_loss: 1.3666 - val_accuracy: 0.5045\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2479 - accuracy: 0.5394 - val_loss: 1.3326 - val_accuracy: 0.5101\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2203 - accuracy: 0.5388 - val_loss: 1.2994 - val_accuracy: 0.5090\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1933 - accuracy: 0.5437 - val_loss: 1.2671 - val_accuracy: 0.5124\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1670 - accuracy: 0.5455 - val_loss: 1.2361 - val_accuracy: 0.5124\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1414 - accuracy: 0.5461 - val_loss: 1.2063 - val_accuracy: 0.5180\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.1168 - accuracy: 0.5467 - val_loss: 1.1781 - val_accuracy: 0.5180\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0932 - accuracy: 0.5455 - val_loss: 1.1515 - val_accuracy: 0.5191\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0708 - accuracy: 0.5528 - val_loss: 1.1265 - val_accuracy: 0.5203\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0496 - accuracy: 0.5546 - val_loss: 1.1033 - val_accuracy: 0.5236\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0297 - accuracy: 0.5540 - val_loss: 1.0819 - val_accuracy: 0.5248\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0113 - accuracy: 0.5583 - val_loss: 1.0623 - val_accuracy: 0.5282\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9942 - accuracy: 0.5583 - val_loss: 1.0444 - val_accuracy: 0.5293\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9785 - accuracy: 0.5601 - val_loss: 1.0283 - val_accuracy: 0.5282\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9642 - accuracy: 0.5607 - val_loss: 1.0137 - val_accuracy: 0.5282\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9511 - accuracy: 0.5674 - val_loss: 1.0007 - val_accuracy: 0.5417\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9393 - accuracy: 0.5813 - val_loss: 0.9889 - val_accuracy: 0.5574\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9284 - accuracy: 0.5874 - val_loss: 0.9783 - val_accuracy: 0.5608\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9184 - accuracy: 0.5934 - val_loss: 0.9686 - val_accuracy: 0.5552\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9091 - accuracy: 0.5910 - val_loss: 0.9597 - val_accuracy: 0.5552\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9005 - accuracy: 0.5934 - val_loss: 0.9515 - val_accuracy: 0.5552\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8923 - accuracy: 0.5965 - val_loss: 0.9440 - val_accuracy: 0.5552\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8847 - accuracy: 0.6001 - val_loss: 0.9370 - val_accuracy: 0.5518\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8775 - accuracy: 0.6001 - val_loss: 0.9305 - val_accuracy: 0.5619\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8708 - accuracy: 0.6001 - val_loss: 0.9246 - val_accuracy: 0.5653\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8646 - accuracy: 0.5983 - val_loss: 0.9191 - val_accuracy: 0.5597\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8589 - accuracy: 0.6001 - val_loss: 0.9142 - val_accuracy: 0.5563\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8537 - accuracy: 0.5953 - val_loss: 0.9097 - val_accuracy: 0.5586\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8491 - accuracy: 0.5995 - val_loss: 0.9057 - val_accuracy: 0.5563\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8449 - accuracy: 0.6044 - val_loss: 0.9020 - val_accuracy: 0.5653\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8411 - accuracy: 0.6080 - val_loss: 0.8988 - val_accuracy: 0.5642\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8378 - accuracy: 0.6123 - val_loss: 0.8958 - val_accuracy: 0.5631\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8348 - accuracy: 0.6104 - val_loss: 0.8932 - val_accuracy: 0.5676\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8322 - accuracy: 0.6129 - val_loss: 0.8909 - val_accuracy: 0.5687\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8298 - accuracy: 0.6110 - val_loss: 0.8888 - val_accuracy: 0.5743\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8277 - accuracy: 0.6098 - val_loss: 0.8871 - val_accuracy: 0.5777\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8258 - accuracy: 0.6110 - val_loss: 0.8855 - val_accuracy: 0.5766\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8242 - accuracy: 0.6159 - val_loss: 0.8842 - val_accuracy: 0.5766\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8228 - accuracy: 0.6141 - val_loss: 0.8832 - val_accuracy: 0.5777\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8217 - accuracy: 0.6183 - val_loss: 0.8823 - val_accuracy: 0.5743\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8207 - accuracy: 0.6226 - val_loss: 0.8817 - val_accuracy: 0.5800\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8199 - accuracy: 0.6232 - val_loss: 0.8812 - val_accuracy: 0.5788\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8192 - accuracy: 0.6262 - val_loss: 0.8808 - val_accuracy: 0.5788\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8187 - accuracy: 0.6268 - val_loss: 0.8805 - val_accuracy: 0.5833\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8182 - accuracy: 0.6286 - val_loss: 0.8803 - val_accuracy: 0.5833\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8179 - accuracy: 0.6286 - val_loss: 0.8802 - val_accuracy: 0.5867\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8176 - accuracy: 0.6256 - val_loss: 0.8801 - val_accuracy: 0.5878\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8174 - accuracy: 0.6280 - val_loss: 0.8800 - val_accuracy: 0.5856\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8172 - accuracy: 0.6305 - val_loss: 0.8800 - val_accuracy: 0.5845\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8170 - accuracy: 0.6305 - val_loss: 0.8800 - val_accuracy: 0.5890\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8168 - accuracy: 0.6317 - val_loss: 0.8801 - val_accuracy: 0.5890\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8166 - accuracy: 0.6311 - val_loss: 0.8801 - val_accuracy: 0.5878\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.8165 - accuracy: 0.6341 - val_loss: 0.8802 - val_accuracy: 0.5867\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.816\n"
     ]
    }
   ],
   "source": [
    "df_city1 = df[(df.SSTADT == 1)]\n",
    "df_city2 = df[(df.SSTADT == 2)]\n",
    "df_city3 = df[(df.SSTADT == 3)]\n",
    "df_city4 = df[(df.SSTADT == 4)]\n",
    "cities = [df_city1, df_city2, df_city3, df_city4]\n",
    "\n",
    "dict_cities = {}\n",
    "\n",
    "for count, city in enumerate(cities):\n",
    "    X = city.drop(['CHOICE'], axis=1)\n",
    "    Y = city['CHOICE']\n",
    "    x_mnl, x_ann, Y_cat = preprocess_ANN_data(X, Y)\n",
    "\n",
    "    # Split the data into a training and test part\n",
    "    X_mnl_train, X_mnl_test, Y_train, Y_test = train_test_split(x_mnl, Y_cat, random_state = 1, test_size = 0.35)\n",
    "    X_ann_train, X_ann_test, Y_train, Y_test = train_test_split(x_ann, Y_cat, random_state = 1, test_size = 0.35)\n",
    "    print('\\nTotal number of obervations in the data set = ', len(x_mnl))\n",
    "    print('Number of obervations in the training set   = ', len(X_mnl_train))\n",
    "    print('Number of obervations in the test set       = ', len(X_mnl_test))\n",
    "\n",
    "    # Compile the model\n",
    "    model = hybrid_RUM_MNL_ANN_model(NALT, no_X_MNL, no_X_ANN, num_nodes, seed=0)\n",
    "    model.compile(optimizer = Adam(learning_rate = 1e-2), metrics = [\"accuracy\"], loss = 'categorical_crossentropy')\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(patience = 4, monitor = 'val_loss')\n",
    "    history = model.fit([X_mnl_train, X_ann_train],Y_train, batch_size=len(X_mnl_train), epochs = nEpoch, verbose = 1, validation_data = ([X_mnl_test, X_ann_test], Y_test), callbacks = [early_stopping])\n",
    "\n",
    "    betas_layer = model.get_layer(name = 'MNL_layer')\n",
    "    betas = betas_layer.get_weights()\n",
    "    print('The cross-entropy on the test data of the tensor flow ANN is',\"{:.3f}\".format(history.history['loss'][-1]))\n",
    "\n",
    "    dict_cities[count] = betas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([[[[-0.03817703]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.3938229 ]]]], dtype=float32)],\n",
       " 1: [array([[[[-0.03266556]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.4173497 ]]]], dtype=float32)],\n",
       " 2: [array([[[[-0.04574197]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.3808821 ]]]], dtype=float32)],\n",
       " 3: [array([[[[-0.04153115]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.2065728 ]]]], dtype=float32)]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beta_STORES    =  -0.038\n",
      "Beta_FOREIGN =  -1.394\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  36.51 min per percentage point\n",
      "\n",
      "Beta_STORES    =  -0.033\n",
      "Beta_FOREIGN =  -1.417\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  43.39 min per percentage point\n",
      "\n",
      "Beta_STORES    =  -0.046\n",
      "Beta_FOREIGN =  -1.381\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  30.19 min per percentage point\n",
      "\n",
      "Beta_STORES    =  -0.042\n",
      "Beta_FOREIGN =  -1.207\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  29.05 min per percentage point\n"
     ]
    }
   ],
   "source": [
    "WTPs = {}\n",
    "for count, city in enumerate(dict_cities.values()):\n",
    "    # print(city)\n",
    "    # Show the trained taste parameters, from the MNL part\n",
    "    beta_STORES = np.squeeze((city[0][0]))\n",
    "    beta_FOREIGN = np.squeeze((city[0][1]))\n",
    "    print('\\nBeta_STORES    = ', \"{:.3f}\".format(beta_STORES )) \n",
    "    print('Beta_FOREIGN = ', \"{:.3f}\".format(beta_FOREIGN ))\n",
    "\n",
    "    # Compute the Willingness to Pay for a Gb extra storage space\n",
    "    WtP_foreign_stores_mnl = beta_FOREIGN/beta_STORES\n",
    "    print('Willingness-to-Pay estimates Hybrid model')\n",
    "    print('----------')\n",
    "\n",
    "    print('Willingness to Pay; reduction in foreigners at an expense of store distance = ', \"{:.2f}\".format(WtP_foreign_stores_mnl),'min per percentage point')\n",
    "    WTPs[count] = WtP_foreign_stores_mnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 36.509464, 1: 43.389725, 2: 30.188517, 3: 29.052237}\n"
     ]
    }
   ],
   "source": [
    "print(WTPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = list(WTPs.keys())\n",
    "values = list(WTPs.values())\n",
    "\n",
    "plt.bar(range(len(WTPs)), values, tick_label=names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for city 0: \n",
      "     B_foreign/B_stores    = 50.57419337900384, \n",
      "     B_foreign/B_green     = -4.260348025032118, \n",
      "     B_foreign/B_transport = 29.153607982693305, \n",
      "     B_foreign/B_noise     = 3.990615506609305, \n",
      "     B_foreign/B_city      = 13.497560658243382\n",
      "for city 1: \n",
      "     B_foreign/B_stores    = 91.7409889575811, \n",
      "     B_foreign/B_green     = -5.081478181204524, \n",
      "     B_foreign/B_transport = 49.267254400591646, \n",
      "     B_foreign/B_noise     = 5.524995579538477, \n",
      "     B_foreign/B_city      = 40.05729964794569\n",
      "for city 2: \n",
      "     B_foreign/B_stores    = 17.22912635616378, \n",
      "     B_foreign/B_green     = -1.3736205508144612, \n",
      "     B_foreign/B_transport = 6.3257653048298845, \n",
      "     B_foreign/B_noise     = 1.2217864343582738, \n",
      "     B_foreign/B_city      = 2.2196087923025063\n",
      "for city 3: \n",
      "     B_foreign/B_stores    = 12.70693055960464, \n",
      "     B_foreign/B_green     = -1.3352471519300062, \n",
      "     B_foreign/B_transport = 6.125015073606175, \n",
      "     B_foreign/B_noise     = 1.234017035690836, \n",
      "     B_foreign/B_city      = 2.966866176999533\n"
     ]
    }
   ],
   "source": [
    "# Using DCM. \n",
    "Wtp_stores = np.zeros((4,1))\n",
    "Wtp_green =  np.zeros((4,1))\n",
    "Wtp_city =  np.zeros((4,1))\n",
    "Wtp_noise =  np.zeros((4,1))\n",
    "Wtp_transport =  np.zeros((4,1))\n",
    "\n",
    "for i in range(4): \n",
    "    B_stores = Beta('B_stores', 0, None, None, 0)\n",
    "    B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "    B_city = Beta('B_city', 0, None, None, 0)\n",
    "    B_noise = Beta('B_noise', 0, None, None, 0)\n",
    "    B_green = Beta('B_green', 0, None, None, 0)\n",
    "    B_foreign = Beta('B_foreign', 0, None, None, 0)\n",
    "    \n",
    "    # Create a DataFrame with pandas and database variable for Biogeme estimation\n",
    "    database = db.Database('residential_choicedata2021', cities[i])\n",
    "    # The following statement allows you to use the names of the variable stored in Biogeme as Python variables.\n",
    "    globals().update(database.variables)\n",
    "\n",
    "    # Utility functions\n",
    "    V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "    V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "    V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3\n",
    "    # Associate utility functions with the numbering of alternatives in df.CHOICE\n",
    "    V = {1: V1, 2: V2, 3: V3}\n",
    "\n",
    "    # Associate the availability conditions with the alternatives\n",
    "    av = {1:1, 2:1, 3:1}\n",
    "    # Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "    prob = models.loglogit(V, av, CHOICE)\n",
    "\n",
    "    # Create the Biogeme object\n",
    "    biogeme = bio.BIOGEME(database, prob)\n",
    "    biogeme.modelName = 'My first discrete choice model'\n",
    "    biogeme.generatePickle = False\n",
    "    biogeme.generateHtml = False\n",
    "\n",
    "    # Calculate the null log likelihood for reporting.\n",
    "    biogeme.calculateNullLoglikelihood(av)\n",
    "    # Estimate the parameters\n",
    "    results1 = biogeme.estimate()\n",
    "    # Report the results in a pandas table\n",
    "    betas1 = results1.getBetaValues()\n",
    "    # different relationships \n",
    "    Wtp_stores[i] = betas1['B_foreign']/betas1['B_stores']\n",
    "    Wtp_green[i] = betas1['B_foreign']/betas1['B_green']\n",
    "    Wtp_transport[i] = betas1['B_foreign']/betas1['B_transport']\n",
    "    Wtp_noise[i] = betas1['B_foreign']/betas1['B_noise']\n",
    "    Wtp_city[i] = betas1['B_foreign']/betas1['B_city']\n",
    "    print('for city {}: \\n \\\n",
    "    B_foreign/B_stores    = {}, \\n \\\n",
    "    B_foreign/B_green     = {}, \\n \\\n",
    "    B_foreign/B_transport = {}, \\n \\\n",
    "    B_foreign/B_noise     = {}, \\n \\\n",
    "    B_foreign/B_city      = {}'.format(i, Wtp_stores[i][0], Wtp_green[i][0], Wtp_transport[i][0], Wtp_noise[i][0], Wtp_city[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Willingness to pay for one percent point less of foreigners\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create barplot for each Wtp. \n",
    "colors = ['b', 'r', 'g', 'orange']\n",
    "labels = ['city 0', 'city 1', 'city 2', 'city 3']\n",
    "\n",
    "print('Willingness to pay for one percent point less of foreigners')\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(3,2,1)\n",
    "plt.bar(range(len(cities)), Wtp_city[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP distance to city [km/percentage point]')\n",
    "plt.subplot(3,2,2)\n",
    "plt.bar(range(len(cities)), Wtp_transport[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP distance to public transport [min walking/percentage point]')\n",
    "plt.subplot(3,2,3)\n",
    "plt.bar(range(len(cities)), Wtp_stores[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP distance to stores [min walking/percentage point')\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "plt.bar(range(len(cities)), Wtp_green[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP percentage of green areas [green area level/percentage point]')\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "plt.bar(range(len(cities)), Wtp_noise[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP noise level [noise level/percentage point]')\n",
    "plt.subplots_adjust(hspace=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q6** <br>\n",
    "For the hybrid model we can only get two beta-values out each time. Therefore it is hard to say whether a city is xenophobic when comparing only the wtp for the share of foreigners compared to the walking distance to the stores. As the output might also be interpretable as people really don't mind how far away from the store they live. <br>\n",
    "Using the DCM we can compare the wtp of the share of foreigners to all the other beta values to get a more complete picture of what people want. \n",
    "\n",
    "<br> From the barplots of the DCM model we can conclude that city 1 is the most xenophobic city, as they are willing to give in on all other aspects for a smaller percentage of foreigners in their city. After that city 0 is most xenophobic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cab132ea358786bca809bd44131ddd0564f8abae658fe95d8fa3ee53812826fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('myenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
