{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4305TU: Week 6 - Artificial Neural Network - Assignment\n",
    "## Investigating neighbourhood choice behaviour using ANNs\n",
    "**7 & 11 October 2021**\n",
    "\n",
    "- Sander van Cranenburgh\n",
    "- Francisco Garrido-Valenzuela "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information\n",
    "\n",
    "* For this assignment we will use *Stated Choice data* on residential location choice, collected in:\n",
    "    - Mainz, Germany\n",
    "    - Hanover, Germany\n",
    "    - Bern, Switzerland\n",
    "    - Zurich, Switzerland \n",
    "\n",
    "- For more details on the data, see the description provided on [Brightspace](https://brightspace.tudelft.nl/d2l/le/content/399675/viewContent/2506146/View). \n",
    "\n",
    "- In total you can earn **6.0** points in this assignment. \n",
    "\n",
    "- Add **Code cells** to complement your analyses. You can draw a lot form the snippets of codes we used for the in-class exercises.\n",
    "\n",
    "### Submission instructions\n",
    "\n",
    "- Answer the questions (code and/or text) in this notebook\n",
    "- Rename this file by adding your group nomber (e.g. Assignment_groupXX.ipynb)\n",
    "- Submit your answers both in ipynb and html format\n",
    "\n",
    "**Provide your answers in the allocated markdown boxes** (with the red font color)\n",
    "\n",
    "\n",
    "### Set up your environment\n",
    "\n",
    "You need to set up your environment based on which platform you would like to use. In this case we offer two options:\n",
    "\n",
    "- Google Colaboratory (Colab)\n",
    "- Jupyter Lab or Notebooks (Local)\n",
    "\n",
    "#### Using Colab\n",
    "\n",
    "Students using **Colab**, just need to install **Biogeme**. Biogeme is a Python package designed for the maximum likelihood estimation of parametric models in general, with a special emphasis on discrete choice models. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using Google Colab (keep the exclamation mark)\n",
    "#!pip install biogeme\n",
    "#!git clone https://github.com/cs4305tu/assignment\n",
    "#root = 'assignment/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using local environment\n",
    "\n",
    "Students using their *local environments*, need to install all the dependencies used in this *Week 6*, to ensure compatibility, they also need to check the versions of each dependency. All dependencies are contained in the text file: **requirements.txt**. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using your local environment (keep the exclamation mark)\n",
    "# !pip3 install -r requirements.txt\n",
    "# root = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Python packages\n",
    "\n",
    "In the following cell add all the packages you need to finish this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow  2.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from heatmap import corrplot\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.database as db\n",
    "import biogeme.optimization as opt\n",
    "import biogeme.messaging as msg\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Using tensorflow \",tf.__version__)\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import ML packaged and modules\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID2</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>SSTADT</th>\n",
       "      <th>RESPCITY</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ENVCONC</th>\n",
       "      <th>COMPLETE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  ID2  STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  \\\n",
       "0   2    5       10           5      1       2       2       0.4       15   \n",
       "1   2    6       15           5      4       4       1       0.1        2   \n",
       "2   2    7       10          15      1       3       1       0.4       15   \n",
       "3   2    8       15          15      5       4       4       0.4        2   \n",
       "4   3    9       15           5      5       1       3       0.4        2   \n",
       "\n",
       "   TRANSPORT2  ...  NOISE3  GREEN3  FOREIGN3  CHOICE  SSTADT  RESPCITY  WOMAN  \\\n",
       "0          10  ...       4       4       0.2       1       3         3      0   \n",
       "1          10  ...       2       3       0.3       2       3         3      0   \n",
       "2           2  ...       1       3       0.2       3       3         3      0   \n",
       "3           2  ...       2       2       0.2       2       3         3      0   \n",
       "4          10  ...       3       1       0.2       2       2         2      1   \n",
       "\n",
       "   AGE  ENVCONC  COMPLETE  \n",
       "0   42      3.0         1  \n",
       "1   42      3.0         1  \n",
       "2   42      3.0         1  \n",
       "3   42      3.0         1  \n",
       "4   41      4.5         1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a dataframe\n",
    "root = ''\n",
    "df_raw = pd.read_csv(f'{root}datasets/neighbourhood_choice2018.dat', sep='\\t')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Do a proper descriptive analysis of the data set (1.0 pt)\n",
    "\n",
    "It is good practice to do a descriptive analysis of the data you want to model, prior to the real modelling. So inspect e.g. what levels the attributes (features) take, correlations, class (im)balances, redudant variables, missing values, etc. to attain a good feeling for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice features are: ['STORES', 'TRANSPORT', 'CITY', 'NOISE', 'GREEN', 'FOREIGN']\n",
      "Other available features are: ['WOMAN', 'AGE', 'SSTADT', 'RESPCITY', 'ENVCONC']\n",
      "The evaluation metric is ['CHOICE']\n",
      "\n",
      "Total number of Nan values: 0\n",
      "Total number of empty (None) values: 0\n",
      "Total number of incomplete responses: 0\n",
      "\n",
      "Check the levels that each feature can take:\n",
      "Choice features:\n",
      "\tSTORES can take: [ 2  5 10 15]\n",
      "\tTRANSPORT can take: [ 2  5 10 15]\n",
      "\tCITY can take: [1 2 4 5]\n",
      "\tNOISE can take: [1 2 3 4]\n",
      "\tGREEN can take: [1 2 3 4]\n",
      "\tFOREIGN can take: [0.1 0.2 0.3 0.4]\n",
      "Other features\n",
      "\tWOMAN can take: [    0     1 99999]\n",
      "\tAGE can take: [   18    19    20    21    22    23    24    25    26    27    28    29\n",
      "    30    31    32    33    34    35    36    37    38    39    40    41\n",
      "    42    43    44    45    46    47    48    49    50    51    52    53\n",
      "    54    55    56    57    58    59    60    61    62    63    64    65\n",
      "    66    67    68    69    70 99999]\n",
      "\tSSTADT can take: [1 2 3 4]\n",
      "\tRESPCITY can take: [1 2 3 4]\n",
      "\tENVCONC can take: [1.00000000e+00 1.16666663e+00 1.33333337e+00 1.50000000e+00\n",
      " 1.66666663e+00 1.83333337e+00 2.00000000e+00 2.16666675e+00\n",
      " 2.33333325e+00 2.50000000e+00 2.66666675e+00 2.83333325e+00\n",
      " 3.00000000e+00 3.16666675e+00 3.33333325e+00 3.50000000e+00\n",
      " 3.66666675e+00 3.75000000e+00 3.83333325e+00 4.00000000e+00\n",
      " 4.16666651e+00 4.33333349e+00 4.50000000e+00 4.66666651e+00\n",
      " 4.75000000e+00 4.83333349e+00 5.00000000e+00 9.99990000e+04]\n",
      "\n",
      "Total number of 99999 values in AGE: 64\n",
      "Total number of 99999 values in WOMAN: 20\n",
      "Total number of 9.99990000e+04 values in ENVCONC: 188\n",
      "\n",
      "Rows containing faulty values are removed in \"df\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>...</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>SSTADT</th>\n",
       "      <th>RESPCITY</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ENVCONC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  TRANSPORT2  \\\n",
       "0       10           5      1       2       2       0.4       15          10   \n",
       "1       15           5      4       4       1       0.1        2          10   \n",
       "2       10          15      1       3       1       0.4       15           2   \n",
       "3       15          15      5       4       4       0.4        2           2   \n",
       "4       15           5      5       1       3       0.4        2          10   \n",
       "\n",
       "   CITY2  NOISE2  ...  CITY3  NOISE3  GREEN3  FOREIGN3  CHOICE  SSTADT  \\\n",
       "0      2       3  ...      4       4       4       0.2       1       3   \n",
       "1      5       1  ...      1       2       3       0.3       2       3   \n",
       "2      2       4  ...      4       1       3       0.2       3       3   \n",
       "3      1       1  ...      2       2       2       0.2       2       3   \n",
       "4      1       2  ...      2       3       1       0.2       2       2   \n",
       "\n",
       "   RESPCITY  WOMAN  AGE  ENVCONC  \n",
       "0         3      0   42      3.0  \n",
       "1         3      0   42      3.0  \n",
       "2         3      0   42      3.0  \n",
       "3         3      0   42      3.0  \n",
       "4         2      1   41      4.5  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All features in dataset, devided into the choice feature, and additional feaures.\n",
    "features_choices = ['STORES', 'TRANSPORT', 'CITY', 'NOISE', 'GREEN', 'FOREIGN']\n",
    "features_other = ['WOMAN', 'AGE', 'SSTADT', 'RESPCITY', 'ENVCONC']\n",
    "print(f'The choice features are: {features_choices}')\n",
    "print(f'Other available features are: {features_other}')\n",
    "print(f\"The evaluation metric is ['CHOICE']\")\n",
    "\n",
    "# Check for Nan values in dataset\n",
    "print(f'\\nTotal number of Nan values: {df_raw.isna().sum().sum()}')\n",
    "# Check for empty (None) values in dataset\n",
    "print(f'Total number of empty (None) values: {int(df_raw[df_raw==None].sum().sum())}')\n",
    "# Check for complete responses\n",
    "print(f'Total number of incomplete responses: {df_raw.COMPLETE[df_raw.COMPLETE==0].sum()}')\n",
    "\n",
    "# Check the various levels that each feature can take\n",
    "print('\\nCheck the levels that each feature can take:')\n",
    "print('Choice features:')\n",
    "for feature in features_choices:\n",
    "    feature_choice = [feature+str(choice) for choice in range(1, 4)]\n",
    "    levels = np.unique(df_raw[feature_choice].to_numpy().flatten())\n",
    "    print(f\"\\t{feature} can take: {levels}\")\n",
    "print('Other features')\n",
    "for feature in features_other:\n",
    "    levels = np.unique(df_raw[feature].to_numpy().flatten())\n",
    "    print(f\"\\t{feature} can take: {levels}\")\n",
    "\n",
    "# Check for faulty values\n",
    "print(f'\\nTotal number of 99999 values in AGE: {df_raw.AGE[df_raw.AGE==99999].size}')\n",
    "print(f'Total number of 99999 values in WOMAN: {df_raw.WOMAN[df_raw.WOMAN==99999].size}')\n",
    "print(f'Total number of 9.99990000e+04 values in ENVCONC: {df_raw.ENVCONC[df_raw.ENVCONC==9.99990000e+04].size}')\n",
    "# Remove faulty values\n",
    "df = df_raw[(df_raw.WOMAN != 99999) & (df_raw.AGE != 99999) & (df_raw.ENVCONC != 99990000e+04)]\n",
    "print(f'\\nRows containing faulty values are removed in \"df\"')\n",
    "\n",
    "# Remove irrelevant features\n",
    "df = df.drop(['ID', 'ID2', 'COMPLETE'], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of choices: 9656\n",
      "--------------------------------\n",
      "\t Number of choices equal to 1: 3419 --> 35.41% of total\n",
      "\t Number of choices equal to 2: 3246 --> 33.62% of total\n",
      "\t Number of choices equal to 3: 2991 --> 30.98% of total\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEzCAYAAABddCYbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAxOAAAMTgF/d4wjAAAt3klEQVR4nO3de1QUZ54+8Kcb5CKg0IhgbKCBBvHeMmo0Iy0YLwSVcYNIjKIZosSIJjk4uMbENZNVd80y5EgGR5OZGEWjzSoJaiJqVoLjxAvGNWqIylVkFFBQFCEq8P7+8GctLagNsW2oPJ9z+pyueuvyfemWx6p6qVIIIQSIiIhkQmnpAoiIiJ4kBhsREckKg42IiGSFwUZERLLCYCMiIllhsBERkaww2IiISFYYbNQhfPvtt1AoFGhoaLB0KQCA+Ph4qFQqKBQKlJSUtGndJ9GXV155BTNnzmz3+nLw2WefQa1WW7qMNtFoNPjrX/9q6TJ+9RhsJAkJCYFCocC+ffuM5s+cOROvvPKKZYqygIMHD+KTTz7BV199hcuXL8PT0/Op17BmzRqkpqY+9f12ZB3pe1hQUNDqf3pyc3MxY8YMyxRFEgYbGbGzs8O7775r6TKeiNu3b7drvaKiIvTq1QsjR46Eh4cHrKysnnBlj9e9e3d07979qe/XHNr7OZhDU1OTWc8KuLm5wd7e3mzbJ9Mw2MhITEwM8vLy8OWXXz50GYVCgW+++UaaLikpgUKhQEFBAYD/O4W0bds2+Pj4wNHREQsXLkRjYyOWLVsGV1dXqNVqbN68ucW29+3bh4CAANjb2+PFF1/E9evXpbb766vVajg5OSEkJASnTp2S2t977z2MGjUKH374IXr37o2hQ4e2Wn9DQwMWL16Mnj17wt7eHuPGjUN+fr60jd///vcoLS2FQqGARqN56M8hJSUFWq0Wtra28PX1bXEKKicnB/369YOTkxOmTJmCa9euSW23bt3CnDlz4OLiAkdHR0RGRqKiokJqf/BU5K1bt7BgwQJ4eHjA3t4eQUFBOHr0qNS+bds29OvXD/b29hgwYAC2b98utVVVVSEqKgoqlQoODg4YPHgwDh8+3Gqf7n+W6enp0Ol0sLOzw5gxY3Dx4sUWfff19UXXrl0xbNgwfPvtt1Lb/c//888/h5+fH9zc3Frd13fffYfQ0FA4OzvDzc0N06dPx9WrV1td9r333sOWLVuwceNGKBQKKBQKqe2bb77B0KFDYW9vj4CAAKMj3fv92b59O4YPHw47OzucPHkSISEhWLx4MV577TU4OTlBo9Fg27Zt0noVFRWYOnUqPDw84OTkBL1ej5MnT0rt/v7+AAAfHx8oFAq89957AIxPRQ4ePBgffPCBUT+2b98OlUqFu3fvAgBOnDiBkJAQ2NvbQ6PRYPny5R3mdHynJoj+v9GjR4t33nlHLF26VAwYMEA0NjYKIYSYMWOGmD17trQcALF//35puri4WAAQ+fn5QgghNmzYIOzs7MTkyZPF6dOnxe7du4WNjY0YN26cWLp0qTh37pxYsWKFsLOzE5WVlUIIIbKzswUAMXToUPHdd9+Jw4cPi759+xrtd9myZSIoKEgcPHhQ5Ofni6VLl4qePXuKmpoaIYQQy5cvFw4ODiI6OlqcOXNG5OXltdrPlStXip49e4rdu3eL06dPi8mTJ4vAwEDR0NAgbt68Kf70pz8JtVotLl++LNX3oI8//lg4OTmJTz/9VBQUFIgDBw4Ig8Fg1JeQkBBx9OhRkZubK3x9fUVCQoK0/ty5c4VWqxU5OTni+++/F88++6wYN26c1D579mwxY8YMafrll18Wffr0EXv37hUFBQVi+/bt4rvvvhNCCPE///M/okePHiI9PV0UFhaKLVu2CHt7e3H48GEhhBCvv/66mDBhgjh9+rQoKCgQO3bsEMePH2+1X/c/S61WK/bu3StOnjwpgoODxejRo6Vl/va3vwlfX1+xZ88eUVhYKFJSUoS9vb0oLi6WPn9bW1sxduxYceLECXH69OlW97V3715hMBhEfn6+yM3NFb/97W9FVFSU1L5hwwbRu3dvIYQQN2/eFJGRkWLatGni8uXL4vLly0IIIc6ePSucnJzEX//6V1FYWCh27dol3NzcxLZt24z6ExgYKPbu3Svy8/PF9evXxejRo0W3bt1EcnKyyM/PF8uXLxd2dnaioqJCWm/NmjXi1KlT4ty5c+K1114Tnp6eor6+XgghxOHDhwUAcezYMXH58mVx8+ZNIYQQ3t7e4pNPPhFCCLFq1SoRFBRk1OeoqCjx6quvCiGEuHr1qlCpVGL16tUiPz9fZGdnC61WK/7zP/+z1Z8XmY7BRpL7wXbt2jXh7OwstmzZIoRoX7ApFApRXl4uLTNhwgTRv39/abqhoUE4ODiInTt3CiH+Lwz27NkjLbN//35hbW0trl27Jurr64W9vX2LX5L+/v4iLS1NCHEv2BwdHaVfMg/j7u4uUlNTpemqqiphb28vdu/eLYQQ4pNPPhHe3t6P3IaXl5f4r//6r1bb7vfl6NGj0rxVq1aJ3/zmN0IIIW7cuCGsra3FV199JbX/9NNPAoA4c+aMEMI42AoLCwUAkZub2+r+QkNDxUcffWQ0b+7cudIv0EmTJon333//kf257/5n+Ze//EWal5+fLwBIP3sfHx+xa9cuo/XGjRsn/v3f/10Ice/zByAFnakOHz4srK2tRUNDg7Sd+8EmRMvvoRBC/P73vxeLFi0ymrdy5Urx/PPPG/Xns88+M1pm9OjR4oUXXpCm7969K7p27dqiX/fd/77m5OQIIf7vZ/JgH5sH2/3P7fz580IIIW7duiW6du0q/dv54x//KCIjI43W37Jli/Dz82v9B0Qms37KB4jUCTg7O+MPf/gDli9fjmnTprVrG25ubnB3d5em3d3dja4ZWVlZwdXVFVeuXDFab/jw4UbvGxoaUFhYCDs7O9TX12PEiBFGy9fX16OoqEia9vf3h6Oj40PrqqmpQUVFhdF2VCoV+vTpg3PnzmHixImP7dvNmzdRWlqKkJCQRy43cOBA6b2HhwcqKysB3LuG19DQYFRDYGAgnJ2dce7cOfTv399oOz/++CMcHBweemr19OnTOHz4MJYsWSLNu3PnDkaNGgUAmDt3LqKjo7Fv3z6MGzcO0dHR6NOnzyNrb/45aLVauLi44Ny5c9BoNCguLkZ0dLTR6cDbt28bjWB0cXF55GlcACgrK8Pbb7+Nf/zjH7hy5Yp0/au8vBy9e/d+5LrN+3769GmsW7dOmtfQ0IBnnnnGaLkhQ4a0WLf552NtbY0ePXpIn9Hdu3exfPlyfPHFF7h8+TIaGhpQV1fX4pTso/j6+mLYsGFIT0/HO++8g927d8PR0RGhoaFS7Tt37jT6vjY2NuLu3btoamqCUskrRe3FYKNWvfnmm1izZg0+++yzFm0KhQKi2dOO7l8vaK5Lly4t1mltXlNTU4t5rb2vra0FcG8ovbOzs9E6KpVKet+1a9eH9OjJESY+6al5f5v31dT1m++v+c/iQbW1tUhKSsKECROM5t8fxBAREYGioiLs2rULX3/9NVauXIlNmzYhOjr6odt82P5u3boFAPj8889bBLCTk5P03pTP4ZVXXsGdO3fw8ccfQ61Wo7i4GOHh4a1+nx6mtrYWCQkJiI2NNZpvbW38q621eh71fVy9ejU2btyIlJQU9OnTB3Z2dhg+fHibagOA6OhobNy4Ee+88w4MBgOmTp0qDUaqra3FSy+9hH/7t39rsR5D7ZdhsFGrHB0d8fbbb+P999/Hs88+a/SLws3NDeXl5dL06dOnn9h+jx07Jv2CPnbsGKytreHn5welUgkbGxtcvnz5oUcupujevTvc3d1x5MgRBAUFAQCqq6tx7tw5BAYGmrSNbt26wcvLC99++227avHz84O1tTWOHDmC8PBwAMDZs2dx/fr1VmsYMGAAamtrcfz48Vb3N3jwYBQVFUGr1T50n7169UJcXBzi4uIwf/58bNy48ZHBduzYMekop7CwENeuXUOfPn3Qs2dPeHh4oLS0FL/73e/a2nUjR44cwebNmzF27FgA94bKP0qXLl1aDKwYPHgwzp0798i+t7e2qKgoREZGAgAuXrxoNPjnfig2NjY+cjvR0dFITExEbm4u9uzZg6ysLKPav/nmmydeOzHY6BFef/11JCcnY/fu3Ua/BPV6PdasWYMhQ4agqqoKK1aseGL7XLZsmXRE9uabb+Lll1+WphcsWIDXX38dd+7cQVBQEMrLy7Fr1y7MmDGjxdHDo7z55pv44x//CI1GA29vb7z99tvw9vZuccTzKO+++y4WLVqEHj16QK/X45///CfKy8sRFRX12HWdnJwQGxuLt956C05OTnBwcMD8+fMxbtw49OvXr8Xyvr6+ePnllzFz5kx89NFH8PPzw6lTp+Dh4YERI0Zg6dKlmDZtGtRqNSZOnIj6+nr8/e9/h5ubG6Kjo7F8+XIMGzYM/fr1Q3V1Nf7xj39gzJgxj6zxT3/6kzSi8c0334Rer8eAAQMAAEuXLsWyZcvg6OgIvV6Pa9eu4ZtvvsHw4cMfu93m/Pz8kJaWhv79+6OwsBCrVq165PLe3t7Yvn07SkpK4OjoiB49eiAxMRHPPfcc3n33Xbz88ssQQiA3Nxd1dXWYP3++ybW0VltWVhZOnDgBAPjDH/4AOzs7qd3DwwM2NjbYt28fpk6dCgcHh1aPCtVqNZ577jnExsbCxcUFwcHBUlt8fDzWr1+PuXPnYsGCBbCzs8MPP/yA8+fPy+ZPbizGolf4qEO5P3ikuXXr1gkARhftL1y4IEJCQkTXrl1FUFCQyMzMbDF4pPlFfyFajvITwvhC+/0BFzt37hR+fn7C1tZW/O53vxPV1dXS8o2NjWLlypVCo9GILl26CLVaLWbOnCmNkFu+fLn47W9/+9h+3r17VyQmJgo3NzdhZ2cnnn/+eekCvxCmDR4RQojk5GSh0WiEjY2N8PPzE3/729+M+nL37l1p2Qd/Jjdv3hSxsbGie/fuwsHBQbz44otGg20e/HnV1taKefPmCVdXV2Fvby+CgoKMBqdkZGSIIUOGCBsbG9GjRw8xYcIEaVTk+++/L/r06SNsbW1Fz549xZw5c0RtbW2rfbo/2GLr1q1i4MCBwsbGRowePVqUlJQYLbd+/XoRGBgounTpIjw8PMS//Mu/iLNnz7ba14c5duyYGDRokLC1tRVDhw4V27dvNxqQ8eB2ysrKRHBwsLC3txfNf3Xl5OSIUaNGCTs7O+Hs7Cz0er00MOfBgU33tfZdb/59rKysFGFhYcLe3l5oNBqxdetW0bt3b7FhwwZp+TVr1ggPDw+hUCjE8uXLW2zjvo8++kgAEG+99VaLn8GpU6fEhAkThIODg3BychLDhg0TGzdufOzPjh5NIUQbT/gTkWyVlJTAx8cH+fn5PEVGnRavUBIRkaww2IiISFZ4KpKIiGSFR2xERCQrDDYiIpKVX9Xfsdna2j70TuNERNR5XLly5aGPRPpVBZubmxvKysosXQYREf1Cj3q6Ok9FEhGRrJg92MaPH49BgwZBp9MhODhYelhfSEgIfH19odPpoNPp8OGHH0rr1NXVYfr06dBqtQgICEBGRobU1tTUhIULF8LPzw9arRZr1641dxeIiKgTMfupyPT0dOlef19++SViY2Ol+6+lpKRg0qRJLdZJSkqCra0tCgoKUFxcjJEjRyI0NBQuLi7YvHkz8vLycP78edTU1CAoKAhjxowx+Qa2REQkb2Y/Ymv+iJGamhqTHsdgMBgQHx8P4N6j1/V6PTIzM6W2efPmwcrKCiqVCtOmTTN6pDsREf26PZVrbLNmzYKnpyfeffddbNy4UZqfmJiIgQMHIjo62uhhkaWlpfD29pamNRoNSktLH9v2oOTkZKjVaul1/5leREQkX08l2DZt2oSLFy9ixYoVSExMBACkpaXhp59+wqlTpxAcHNzilGTzBx0+eHOUR7U1l5CQgLKyMun1qCcrExGRPDzVUZGzZ89GdnY2qqqq4OnpCeBeSC1YsABFRUWoqqoCAHh5eaGkpERa78KFC/Dy8npsGxERkVmD7caNG7h06ZI0/cUXX8DV1RXdunVDRUWFNH/Hjh1wd3eHq6srACAqKgqpqakAgOLiYuTk5CAiIkJqW79+PRobG1FdXQ2DwfDIJwETEdGvi1lHRdbU1CAyMhL19fVQKpVwc3PD7t27cefOHUycOBG3b9+GUqlEjx49sHPnTmm9xMRExMbGQqvVQqlUIjU1FSqVCgAQExOD3NxcBAQESMv27dvXnN0gIqJO5Fd1d3+1Ws07jxARycCjfp//qm6p9SRolnxl6RI6jJL/nGjpEoiIWuAttYiISFYYbEREJCsMNiIikhUGGxERyQqDjYiIZIXBRkREssJgIyIiWWGwERGRrDDYiIhIVhhsREQkK7ylFtETwtutGeMt18hSeMRGRESywmAjIiJZYbAREZGsMNiIiEhWGGxERCQrDDYiIpIVBhsREckKg42IiGSFwUZERLLCYCMiIllhsBERkaww2IiISFbMHmzjx4/HoEGDoNPpEBwcjJMnTwIAKisrERYWBn9/fwwYMACHDh2S1qmrq8P06dOh1WoREBCAjIwMqa2pqQkLFy6En58ftFot1q5da+4uEBFRJ2L2u/unp6fD2dkZAPDll18iNjYWJ06cwJIlSzBixAhkZWUhNzcXU6dORWFhIaytrZGUlARbW1sUFBSguLgYI0eORGhoKFxcXLB582bk5eXh/PnzqKmpQVBQEMaMGYPAwEBzd4WIiDoBsx+x3Q81AKipqYFSeW+X6enpiI+PBwAMGzYM7u7u0lGbwWCQ2nx8fKDX65GZmSm1zZs3D1ZWVlCpVJg2bRq2bdtm7m4QEVEn8VSexzZr1ixkZ2cDALKyslBVVYWmpia4ublJy2g0GpSWlgIASktL4e3tbXLb8ePHn0Y3iIioE3gqwbZp0yYAwMaNG5GYmIi0tDQoFAqjZYQQRtPN29vS1lxycjKSk5Ol6dra2rYXT0T0C/EhtMbM/RDapzoqcvbs2dKRGwBcuXJFen/hwgV4eXkBALy8vFBSUtLmtgclJCSgrKxMejk6Oj7B3hARUUdk1mC7ceMGLl26JE1/8cUXcHV1hUqlQlRUFFJTUwEAubm5KC8vx6hRowDAqK24uBg5OTmIiIiQ2tavX4/GxkZUV1fDYDAgOjranN0gIqJOxKynImtqahAZGYn6+noolUq4ublh9+7dUCgUWL16NWJiYuDv7w8bGxukpaXB2vpeOYmJiYiNjYVWq4VSqURqaipUKhUAICYmBrm5uQgICJCW7du3rzm7QUREnYhZg83T0xPHjh1rtc3d3R379u1rtc3BwQEGg6HVNisrK+lojoiI6EG88wgREckKg42IiGSFwUZERLLCYCMiIllhsBERkaww2IiISFYYbEREJCsMNiIikhUGGxERyQqDjYiIZIXBRkREssJgIyIiWWGwERGRrDDYiIhIVhhsREQkKww2IiKSFQYbERHJCoONiIhkhcFGRESywmAjIiJZYbAREZGsMNiIiEhWGGxERCQrDDYiIpIVBhsREcmKWYPt559/xpQpUxAQEACdToewsDCUlJQAAEJCQuDr6wudTgedTocPP/xQWq+urg7Tp0+HVqtFQEAAMjIypLampiYsXLgQfn5+0Gq1WLt2rTm7QEREnYy1uXcQFxeHF154AQqFAn/+858RFxeHffv2AQBSUlIwadKkFuskJSXB1tYWBQUFKC4uxsiRIxEaGgoXFxds3rwZeXl5OH/+PGpqahAUFIQxY8YgMDDQ3F0hIqJOwKxHbHZ2dggPD4dCoQAAjBgxAkVFRY9dz2AwID4+HgDg4+MDvV6PzMxMqW3evHmwsrKCSqXCtGnTsG3bNvN1goiIOpWneo0tJSUFkydPlqYTExMxcOBAREdHGwVeaWkpvL29pWmNRoPS0tLHthERET21YFu1ahXy8/OxcuVKAEBaWhp++uknnDp1CsHBwS1OSd4/ygMAIYTJbc0lJydDrVZLr9ra2ifRFSIi6sCeSrAlJSUhIyMDe/bsQdeuXQEAnp6eAO6F1IIFC1BUVISqqioAgJeXlzTIBAAuXLgALy+vx7Y9KCEhAWVlZdLL0dHRDL0jIqKOxOzBlpycjK1bt2L//v1wdnYGADQ0NKCiokJaZseOHXB3d4erqysAICoqCqmpqQCA4uJi5OTkICIiQmpbv349GhsbUV1dDYPBgOjoaHN3g4iIOgmzjoosKyvDokWL4Ovri9DQUACAra0tDhw4gIkTJ+L27dtQKpXo0aMHdu7cKa2XmJiI2NhYaLVaKJVKpKamQqVSAQBiYmKQm5uLgIAAadm+ffuasxtERNSJmDXY1Gr1Q6+BHT9+/KHrOTg4wGAwtNpmZWUlHc0RERE9iHceISIiWWGwERGRrDDYiIhIVhhsREQkKww2IiKSFQYbERHJCoONiIhkhcFGRESywmAjIiJZYbAREZGsMNiIiEhWGGxERCQrDDYiIpIVBhsREckKg42IiGSFwUZERLJicrCdPXvWnHUQERE9ESYHW1hYGMaNG4fMzMyHPhWbiIjI0kwOtqKiIsybNw9r1qyBr68vPvjgA1RVVZmzNiIiojYzOdiUSiUiIyNx4MABpKen489//jM8PT0xd+5cXLp0yZw1EhERmaxNg0cKCwuxaNEivPjii5g4cSIOHToEf39/hIWFmas+IiKiNrE2dcGwsDCcP38e8+fPx+nTp+Hs7AwACAoKwqZNm8xVHxERUZuYHGxz5szBiy++CKWy5UHemTNnnmhRRERE7WXyqUhbW1vcuHFDmr527Rp2795tlqKIiIjay+RgW7ZsmXT6EQCcnZ2xbNkyc9RERETUbu2+84hCoUBTU9Mjl/n5558xZcoUBAQEQKfTISwsDCUlJQCAyspKhIWFwd/fHwMGDMChQ4ek9erq6jB9+nRotVoEBAQgIyNDamtqasLChQvh5+cHrVaLtWvXtrcLREQkQyYHW7du3XD06FFp+siRI3BycnrsenFxcTh37hxOnjyJSZMmIS4uDgCwZMkSjBgxAvn5+diwYQNmzJiBhoYGAEBSUhJsbW1RUFCAvXv3Yv78+bh27RoAYPPmzcjLy8P58+dx7NgxfPDBB7wrChERSUwOttWrV2PKlCkYO3Ysxo4di8jISCQnJz9yHTs7O4SHh0OhUAAARowYgaKiIgBAeno64uPjAQDDhg2Du7u7dNRmMBikNh8fH+j1emRmZkpt8+bNg5WVFVQqFaZNm4Zt27a1sdtERCRXJo+KHDlyJPLy8nD48GEAwHPPPWd0zc0UKSkpmDx5MqqqqtDU1AQ3NzepTaPRoLS0FABQWloKb29vk9uOHz/e6v6Sk5ONwre2trZN9RIRUedjcrABgIuLC8LDw9u1o1WrViE/Px/r1q1DfX29dBR334P3n2ze3pa25hISEpCQkCBNq9XqdtVORESdh8mnIrOyshAYGAgbGxtYWVlBqVTCysrKpHWTkpKQkZGBPXv2oGvXrnB1dQUAXLlyRVrmwoUL8PLyAgB4eXlJg0za0kZERGRysL3xxhtYs2YNrl69ihs3buDmzZtGf9f2MMnJydi6dSv2799vdOoyKioKqampAIDc3FyUl5dj1KhRLdqKi4uRk5ODiIgIqW39+vVobGxEdXU1DAYDoqOjTe4wERHJm8mnIrt164YJEya0aeNlZWVYtGgRfH19ERoaCuDeH3ofPXoUq1evRkxMDPz9/WFjY4O0tDRYW98rJzExEbGxsdBqtVAqlUhNTYVKpQIAxMTEIDc3FwEBAdKyffv2bVNdREQkXyYH28SJE7F7925MmjTJ5I2r1eqHXgNzd3fHvn37Wm1zcHCAwWBotc3Kyko6miMiInqQycG2du1aVFVVwdHREXZ2dhBCQKFQoLKy0pz1ERERtYnJwfawIfVEREQdicmDR7y9vWFvby/9HVnv3r3Rq1cvc9ZGRETUZiYHW0ZGBoYPH46YmBgAwI8//ogpU6aYqy4iIqJ2MTnYVq1ahe+//x4uLi4AgMGDB+PChQtmK4yIiKg9TA42pVIp/WH1fTY2Nk+8ICIiol/C5GBzcnJCRUWFdDur7Oxs6eiNiIioozB5VOTq1asRHh6O4uJihISEID8/H7t27TJnbURERG1mcrANHToUBw4cwHfffQchRLvu7k9ERGRubbq7f/fu3fHCCy+YqxYiIqJfzORgUyqVLR41AwCNjY1PtCAiIqJfwuRgu3nzpvS+vr4emzZtwp07d8xSFBERUXuZPCrSwcFBevXo0QMJCQnIysoyZ21ERERtZnKwPSg/Px8XL158krUQERH9YiafinRzc5OusTU2NqKhoQEpKSlmK4yIiKg92nV3f2tra3h4eMDKysosRREREbWXycHm7e1tzjqIiIieiHadimyODxwlIqKOxORgmzdvHqqrqxEXFwchBD799FP07t0bL730kjnrIyIiahOTg+3gwYPIycmRplNSUqDX6/Gv//qvZimMiIioPUwe7n/p0iVcvXpVmr569SouX75slqKIiIjay+QjtrfeeguDBw/GpEmTAABff/01li5darbCiIiI2sPkYIuPj0dwcDBycnIghMCCBQswcOBAc9ZGRETUZm26u7+Hhwd0Oh2Cg4PR0NCAO3fu8CnaRETUoZh8jS0jIwPDhw/HrFmzAAA//vgjpkyZ8tj13njjDWg0GigUCpw5c0aaHxISAl9fX+h0Ouh0Onz44YdSW11dHaZPnw6tVouAgABkZGRIbU1NTVi4cCH8/Pyg1Wqxdu1aU7tARES/AiYfsa1atQrff/89xo4dCwAYPHgwLly48Nj1pk6disWLF2PUqFEt2lJSUqRrds0lJSXB1tYWBQUFKC4uxsiRIxEaGgoXFxds3rwZeXl5OH/+PGpqahAUFIQxY8YgMDDQ1K4QEZGMmXzEplQq4erqajTPlNOQer0earW6TUUZDAbEx8cDAHx8fKDX65GZmSm1zZs3D1ZWVlCpVJg2bRq2bdvWpu0TEZF8mRxsTk5OqKiokO4+kp2dDRcXl1+088TERAwcOBDR0dEoKiqS5peWlhrdwkuj0aC0tPSxbURERCafily9ejXCw8NRXFyMkJAQ5OfnY9euXe3ecVpaGjw9PSGEQGpqKiZNmoS8vDypvfntu4QQRus+qq255ORkJCcnS9O1tbXtrpeIiDoHk47Ympqa0NjYiAMHDuDzzz/H4sWL8eOPPyIoKKjdO/b09ARwL6QWLFiAoqIiVFVVAQC8vLxQUlIiLXvhwgV4eXk9tu1BCQkJKCsrk16Ojo7trpeIiDoHk4JNqVRi4cKF6N69O1544QWEh4fD2dm53TttaGhARUWFNL1jxw64u7tL1/CioqKQmpoKACguLkZOTg4iIiKktvXr16OxsRHV1dUwGAyIjo5udy1ERCQvJp+K7Nu3L4qKiuDr69umHcTHxyMzMxPl5eUYO3YsHB0d8cMPP2DixIm4ffs2lEolevTogZ07d0rrJCYmIjY2FlqtFkqlEqmpqVCpVACAmJgY5ObmIiAgQFq2b9++baqJiIjky+Rgq6yshE6nw6hRo4xO6aWnpz9yvdTUVOnoq7nmDy59kIODAwwGQ6ttVlZWrW6PiIgIMCHY5s+fj7Vr1+Kll17ChAkTfvFISCIiInN6bLAdOXIEADB79mwEBQXhxIkTZi+KiIiovR47eKT5cPpHDa0nIiLqCB57xHb79m389NNPEEIYvb+vX79+Zi2QiIioLR4bbHV1dQgPD5emm79XKBRGdwwhIiKytMcGW/M/hiYiIuroTL5XJBERUWfAYCMiIllhsBERkaww2IiISFYYbEREJCsMNiIikhUGGxERyQqDjYiIZIXBRkREssJgIyIiWWGwERGRrDDYiIhIVhhsREQkKww2IiKSFQYbERHJCoONiIhkhcFGRESywmAjIiJZYbAREZGsmD3Y3njjDWg0GigUCpw5c0aaX1lZibCwMPj7+2PAgAE4dOiQ1FZXV4fp06dDq9UiICAAGRkZUltTUxMWLlwIPz8/aLVarF271txdICKiTsTswTZ16lQcOnQI3t7eRvOXLFmCESNGID8/Hxs2bMCMGTPQ0NAAAEhKSoKtrS0KCgqwd+9ezJ8/H9euXQMAbN68GXl5eTh//jyOHTuGDz74AGfPnjV3N4iIqJMwe7Dp9Xqo1eoW89PT0xEfHw8AGDZsGNzd3aWjNoPBILX5+PhAr9cjMzNTaps3bx6srKygUqkwbdo0bNu2zdzdICKiTsIi19iqqqrQ1NQENzc3aZ5Go0FpaSkAoLS01OgIz9S2ByUnJ0OtVkuv2tpac3SHiIg6EIsNHlEoFEbTQoiHtrelrbmEhASUlZVJL0dHx19SMhERdQIWCTZXV1cAwJUrV6R5Fy5cgJeXFwDAy8sLJSUlbW4jIiKy2BFbVFQUUlNTAQC5ubkoLy/HqFGjWrQVFxcjJycHERERUtv69evR2NiI6upqGAwGREdHW6YTRETU4Vibewfx8fHIzMxEeXk5xo4dC0dHRxQUFGD16tWIiYmBv78/bGxskJaWBmvre+UkJiYiNjYWWq0WSqUSqampUKlUAICYmBjk5uYiICBAWrZv377m7gYREXUSZg+21NRU6eirOXd3d+zbt6/VdRwcHGAwGFpts7KyanV7REREAO88QkREMsNgIyIiWWGwERGRrDDYiIhIVhhsREQkKww2IiKSFQYbERHJCoONiIhkhcFGRESywmAjIiJZYbAREZGsMNiIiEhWGGxERCQrDDYiIpIVBhsREckKg42IiGSFwUZERLLCYCMiIllhsBERkaww2IiISFYYbEREJCsMNiIikhUGGxERyQqDjYiIZIXBRkREsmLRYNNoNAgMDIROp4NOp4PBYAAAVFZWIiwsDP7+/hgwYAAOHTokrVNXV4fp06dDq9UiICAAGRkZliqfiIg6IGtLF7B9+3YMGDDAaN6SJUswYsQIZGVlITc3F1OnTkVhYSGsra2RlJQEW1tbFBQUoLi4GCNHjkRoaChcXFws1AMiIupIOuSpyPT0dMTHxwMAhg0bBnd3d+mozWAwSG0+Pj7Q6/XIzMy0WK1ERNSxWDzYZsyYgYEDB2LOnDm4cuUKqqqq0NTUBDc3N2kZjUaD0tJSAEBpaSm8vb1bbXtQcnIy1Gq19KqtrTVvZ4iIyOIsGmwHDx7EDz/8gBMnTsDV1RWzZ88GACgUCqPlhBBG083bH2xrLiEhAWVlZdLL0dHxCVZPREQdkUWDzcvLCwDQpUsXvPXWW/j73/8OV1dXAMCVK1ek5S5cuCAt6+XlhZKSklbbiIiILBZst27dwvXr16XprVu3YsiQIQCAqKgopKamAgByc3NRXl6OUaNGtWgrLi5GTk4OIiIinm7xRETUYVlsVGRFRQUiIyPR2NgIIQR8fX2xadMmAMDq1asRExMDf39/2NjYIC0tDdbW90pNTExEbGwstFotlEolUlNToVKpLNUNIiLqYCwWbL6+vvjf//3fVtvc3d2xb9++VtscHBykv3cjIiJ6kMVHRRIRET1JDDYiIpIVBhsREckKg42IiGSFwUZERLLCYCMiIllhsBERkaww2IiISFYYbEREJCsMNiIikhUGGxERyQqDjYiIZIXBRkREssJgIyIiWWGwERGRrDDYiIhIVhhsREQkKww2IiKSFQYbERHJCoONiIhkhcFGRESywmAjIiJZYbAREZGsMNiIiEhWOm2w5efn47nnnkNAQACGDx+OvLw8S5dEREQdQKcNttdeew1xcXE4f/48Fi9ejFdffdXSJRERUQfQKYOtsrISJ06cwMyZMwEAkZGRKC4uRklJiWULIyIii+uUwXbx4kU888wzsLa2BgAoFAp4eXmhtLTUwpUREZGlWVu6gPZSKBRG00KIFsskJycjOTlZmi4vL4darTZ7beZWW1sLR0dHS5cB9WZLV0Ct4feDHkZO340rV648tE0hWkuEDq6yshL+/v6oqqqCtbU1hBDo1asXjhw5Ao1GY+nyzE6tVqOsrMzSZVAHxe8HPcyv5bvRKU9F9uzZE0OGDMHmzfdif8eOHdBoNL+KUCMiokfrtKci169fj1deeQWrVq1Ct27dsHHjRkuXREREHUCnDbY+ffrg8OHDli7DIhISEixdAnVg/H7Qw/xavhud8hobERHRw3TKa2xEREQPw2AjIiJZYbB1Im+88QY0Gg0UCgXOnDlj6XKoA/n5558xZcoUBAQEQKfTISwsjHfiIcn48eMxaNAg6HQ6BAcH4+TJk5YuyawYbJ3I1KlTcejQIXh7e1u6FOqA4uLicO7cOZw8eRKTJk1CXFycpUuiDiI9PR2nTp3CyZMnsWjRIsTGxlq6JLNisHUier1eFndOoSfPzs4O4eHh0h15RowYgaKiIgtXRR2Fs7Oz9L6mpgZKpbx/9Xfa4f5E9HApKSmYPHmypcugDmTWrFnIzs4GAGRlZVm4GvNisBHJzKpVq5Cfn49169ZZuhTqQDZt2gQA2LhxIxITE/H1119buCLzkffxKNGvTFJSEjIyMrBnzx507drV0uVQBzR79mxkZ2ejqqrK0qWYDYONSCaSk5OxdetW7N+/3+iaCv263bhxA5cuXZKmv/jiC7i6ukKlUlmwKvPinUc6kfj4eGRmZqK8vBw9evSAo6MjCgoKLF0WdQBlZWXw9PSEr68vnJycAAC2trY4evSohSsjS7t48SIiIyNRX18PpVIJNzc3JCUlQafTWbo0s2GwERGRrPBUJBERyQqDjYiIZIXBRkREssJgIyIiWWGwERGRrDDYiDqIhoYGvP/++wgMDET//v0RGBiIuLg4fPnllxg6dGibt7dz504kJiaaoVKijo231CLqIF599VVUV1fj8OHDcHFxQVNTE3bs2IHq6up2bS8iIgIRERFPuEqijo9HbEQdQEFBAf77v/8bGzZsgIuLCwBAqVQiKioKvr6+aGhowPz58zF48GD0798fx48fl9ZNS0vDwIEDMWjQIEycOBH//Oc/AQCfffYZpk6dKi23YcMG6HQ6DB48GEOHDpWe17Z3716MGjUKv/nNb/Dss8/i4MGDT6/jROYgiMjiDAaDGDRoUKtt2dnZwtraWuTm5gohhPjLX/4ixo8fL4QQ4vTp08Ld3V2UlZUJIYRYsWKFCA8PF0IIsWHDBhEZGSltw8/PT1y6dEkIIcStW7fErVu3RGFhoRg5cqSoqakRQgiRn58vnnnmGXHnzh3zdZbIzHjERtQJ9OnTR7rONnLkSBQWFgIAsrOzMWnSJPTu3RsAMH/+fBw4cADigRsKffXVV5g1axZ69eoFAOjatSu6du2KrKwsFBQUQK/XQ6fTSUd4Fy9efFpdI3rieI2NqAMICgpCfn4+qqqq4Orq2qLdzs5Oem9lZYWGhgYAgBBCergoAKP3phBCICwsTHqkCZEc8IiNqAPQarWIjIzEq6++iuvXrwO4FzqbNm2Sjs5a8/zzz+Prr79GeXk5AGDdunV4/vnnWwTc5MmTsWnTJmm5uro61NXVYfz48cjKysKZM2ekZY8dO/aEe0f0dPGIjaiD+PTTT7FixQo8++yzsLa2hhACer0eYWFhD12nf//++I//+A+MHz8eAODp6YmPP/64xXJ6vR7vvvsuxo8fD4VCARsbG2zfvh3+/v7YvHkz5syZg/r6ety5cwdBQUHYsmWL2fpJZG68uz8REckKT0USEZGsMNiIiEhWGGxERCQrDDYiIpIVBhsREckKg42IiGSFwUZERLLCYCMiIllhsBERkaz8PwBefaiyqRtbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show how often each alternative is chosen\n",
    "print(f\"Total number of choices: {len(df.CHOICE)}\")\n",
    "print('--------------------------------')\n",
    "for choice in range(1, 4):\n",
    "    print(f\"\\t Number of choices equal to {choice}: {len(df.CHOICE[df.CHOICE == choice])} --> {round(len(df.CHOICE[df.CHOICE == choice])/len(df.CHOICE)*100, 2)}% of total\")\n",
    "\n",
    "fig=plt.figure(figsize=(6,4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.hist(df.CHOICE, bins = [0.75, 1.25, 1.75, 2.25, 2.75, 3.25])\n",
    "plt.xticks((1, 2, 3))\n",
    "plt.title('Number of choices per alternative')\n",
    "plt.xlabel('Choice')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of each feature to CHOICE, sorted by absolute value:\n",
      "CHOICE        1.000000\n",
      "GREEN1        0.269395\n",
      "NOISE1        0.235075\n",
      "GREEN3        0.222014\n",
      "NOISE3        0.217443\n",
      "TRANSPORT1    0.196445\n",
      "TRANSPORT3    0.187104\n",
      "NOISE2        0.168003\n",
      "CITY3         0.165390\n",
      "CITY1         0.154733\n",
      "TRANSPORT2    0.094403\n",
      "FOREIGN1      0.094172\n",
      "STORES3       0.079956\n",
      "CITY2         0.068386\n",
      "FOREIGN3      0.062488\n",
      "STORES1       0.059513\n",
      "FOREIGN2      0.049579\n",
      "GREEN2        0.025982\n",
      "AGE           0.014812\n",
      "WOMAN         0.011703\n",
      "SSTADT        0.010152\n",
      "RESPCITY      0.010152\n",
      "ENVCONC       0.004726\n",
      "STORES2       0.000912\n",
      "Name: CHOICE, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain correlations\n",
    "all_features = list(df.columns[df.columns!='CHOICE'])\n",
    "\n",
    "# get choice as first input\n",
    "corr = df[['CHOICE'] + all_features].corr()\n",
    "corr_choice = corr['CHOICE']\n",
    "abs_corr_sorted = corr_choice.abs().sort_values(ascending=False)     # sorted by largest correlation to income\n",
    "\n",
    "print('Correlation of each feature to CHOICE, sorted by absolute value:')\n",
    "print(abs_corr_sorted)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "corrplot(corr, size_scale=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reduced dataframe \"df_reduced\" of shape (9656, 19):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>GREEN2</th>\n",
       "      <th>FOREIGN2</th>\n",
       "      <th>STORES3</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  TRANSPORT2  \\\n",
       "0       10           5      1       2       2       0.4       15          10   \n",
       "1       15           5      4       4       1       0.1        2          10   \n",
       "2       10          15      1       3       1       0.4       15           2   \n",
       "3       15          15      5       4       4       0.4        2           2   \n",
       "4       15           5      5       1       3       0.4        2          10   \n",
       "\n",
       "   CITY2  NOISE2  GREEN2  FOREIGN2  STORES3  TRANSPORT3  CITY3  NOISE3  \\\n",
       "0      2       3       3       0.1        2          15      4       4   \n",
       "1      5       1       2       0.2        5          15      1       2   \n",
       "2      2       4       2       0.1        2           5      4       1   \n",
       "3      1       1       1       0.1        5           5      2       2   \n",
       "4      1       2       4       0.1        5          15      2       3   \n",
       "\n",
       "   GREEN3  FOREIGN3  CHOICE  \n",
       "0       4       0.2       1  \n",
       "1       3       0.3       2  \n",
       "2       3       0.2       3  \n",
       "3       2       0.2       2  \n",
       "4       1       0.2       2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final complete dataframe \"df\" of shape (9656, 23):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>...</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>SSTADT</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ENVCONC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  TRANSPORT2  \\\n",
       "0       10           5      1       2       2       0.4       15          10   \n",
       "1       15           5      4       4       1       0.1        2          10   \n",
       "2       10          15      1       3       1       0.4       15           2   \n",
       "3       15          15      5       4       4       0.4        2           2   \n",
       "4       15           5      5       1       3       0.4        2          10   \n",
       "\n",
       "   CITY2  NOISE2  ...  TRANSPORT3  CITY3  NOISE3  GREEN3  FOREIGN3  CHOICE  \\\n",
       "0      2       3  ...          15      4       4       4       0.2       1   \n",
       "1      5       1  ...          15      1       2       3       0.3       2   \n",
       "2      2       4  ...           5      4       1       3       0.2       3   \n",
       "3      1       1  ...           5      2       2       2       0.2       2   \n",
       "4      1       2  ...          15      2       3       1       0.2       2   \n",
       "\n",
       "   SSTADT  WOMAN  AGE  ENVCONC  \n",
       "0       3      0   42      3.0  \n",
       "1       3      0   42      3.0  \n",
       "2       3      0   42      3.0  \n",
       "3       3      0   42      3.0  \n",
       "4       2      1   41      4.5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove additional attributes\n",
    "df_reduced = df.drop(features_other, axis=1)\n",
    "print(f'Final reduced dataframe \"df_reduced\" of shape {df_reduced.shape}:')\n",
    "display(df_reduced.head())\n",
    "\n",
    "# Remove irrelevant labels\n",
    "df = df.drop(['RESPCITY'], axis=1)\n",
    "print(f'Final complete dataframe \"df\" of shape {df.shape}:')\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q1** <br>\n",
    "The dataset is seen to consist out of two main set of features. The first set is the various 'choice features' available for each of the three choices; and the second set consist of 'other features', which contain information regarding the applicant, e.g.: age, woman (yes or no), place of citizenship.\n",
    "\n",
    "Considering all the available data, the dataset is checked for Nan and empty values. It is found that none of these input types are present. It is also checked whether all choices are complete, which is done by evaluation the COMPLETE feature. This is also found to be true for all choices. Furthermore, the features ID, ID2, and COMPLETE are removed as they are not used any further in this assignment.\n",
    "\n",
    "Then, the type of levels each feature can take-on are obtained. For the choice features, no irrelevant/faulty levels are seen to exist in the dataset. For the 'other features', it can be seen that WOMAN, AGE, and ENVCONC, contain irrelevant/faulty levels, equal to 99999. The number of occurances of these irrelevant levels are obtained for the three features. As this turns out to be a relatively low number, the rows containing faulty values are removed.\n",
    "\n",
    "Furthermore, the data is seen to be nicely balanced, with a distribution of 35.41%, 33.62%, and 30.98%, for the three choices, respectively.\n",
    "\n",
    "Finally, the correlations for all features to the CHOICE are constructed. These correlations are plotted, from which it can be seen that the 'other features' (AGE, WOMAN, SSTADT, RESPCITY, ENVCONC) and STORES2 have a low correlation to the CHOICE. Since the DCM does not use the 'other features', no features have to be removed. The ANN does use all features, including the low-correlated features. As the ANN is able to capture more complex relations it is still found useful to use all features.\n",
    "\n",
    "Furthermore, the correlation plot shows that SSTADT and RESPCITY are the same feature, correlated with 1. RESPCITY can therefore be removed from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Estimate a RUM-MNL discrete choice model (1.0 pt)\n",
    "\n",
    "Assume utility is linear additive-utility: \n",
    "\n",
    "$ V_{in} = \\sum_{m}\\beta_m x_{imn}$\n",
    "\n",
    "And estimate marginal utilities (i.e. betas) for: \n",
    "\n",
    "1. Distance to Transport [min] (**Note** that distances are given in minutes)\n",
    "2. Distance to City [km]\n",
    "3. Distance to Stores [min] (**Note** that distances are given in minutes)\n",
    "4. Traffic Noise\n",
    "5. Green area\n",
    "6. Share of foreigners [%]\n",
    "\n",
    "**Note:** Do not add any other variables (features) to the model.\n",
    "\n",
    "**To get the scores, address the following:**\n",
    "\n",
    "- (A) Report the parameter estimates, and interpret them. i.e. do they have the expected sign? (0.5 pts)\n",
    "- (B) Compute and report the cross-entropy (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with pandas and database variable for Biogeme estimation\n",
    "database = db.Database('residential_choicedata2021', df_reduced)\n",
    "\n",
    "# The following statement allows you to use the names of the variable stored in Biogeme as Python variables.\n",
    "globals().update(database.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_stores = Beta('B_stores', 0, None, None, 0)\n",
    "B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "B_city = Beta('B_city', 0, None, None, 0)\n",
    "B_noise = Beta('B_noise', 0, None, None, 0)\n",
    "B_green = Beta('B_green', 0, None, None, 0)\n",
    "B_foreign = Beta('B_foreign', 0, None, None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate utility functions with the numbering of alternatives in df.CHOICE\n",
    "V = {1: V1, 2: V2, 3: V3}\n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "av = {1:1, 2:1, 3:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters\n",
      "----------\n",
      "                Value   Std err     t-test  p-value\n",
      "B_city      -0.168094  0.007977 -21.072663      0.0\n",
      "B_foreign   -1.173841  0.109769 -10.693729      0.0\n",
      "B_green      0.416031  0.011653  35.701378      0.0\n",
      "B_noise     -0.438004  0.011379 -38.490741      0.0\n",
      "B_stores    -0.034612  0.002586 -13.386340      0.0\n",
      "B_transport -0.073980  0.002556 -28.944421      0.0\n"
     ]
    }
   ],
   "source": [
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "prob = models.loglogit(V, av, CHOICE)\n",
    "\n",
    "# Create the Biogeme object\n",
    "biogeme = bio.BIOGEME(database, prob)\n",
    "biogeme.modelName = 'My first discrete choice model'\n",
    "biogeme.generatePickle = False\n",
    "biogeme.generateHtml = False\n",
    "\n",
    "# Calculate the null log likelihood for reporting.\n",
    "biogeme.calculateNullLoglikelihood(av)\n",
    "\n",
    "# Estimate the parameters\n",
    "results1 = biogeme.estimate()\n",
    "\n",
    "# Report the results in a pandas table\n",
    "print('Estimated parameters')\n",
    "print('----------')\n",
    "pandasResults = results1.getEstimatedParameters()\n",
    "print(pandasResults[['Value','Std err','t-test','p-value']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-entropy of the DCM is         0.889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Get the estimated betas from the discrete choice model\n",
    "betas1 = results1.getBetaValues()\n",
    "\n",
    "# Define compute objects\n",
    "prob_1 = models.logit(V, av, 1)\n",
    "prob_2 = models.logit(V, av, 2)\n",
    "prob_3 = models.logit(V, av, 3)\n",
    "\n",
    "# Define dictionary\n",
    "simulate_dict = {\n",
    "    'Prob_1': prob_1,\n",
    "    'Prob_2': prob_2,\n",
    "    'Prob_3': prob_3}\n",
    "\n",
    "# Create Biogeme object\n",
    "simulator = bio.BIOGEME(database, simulate_dict)\n",
    "\n",
    "# Compute probabilities using the estimated choice model\n",
    "probs_DCM = simulator.simulate(betas1)\n",
    "\n",
    "# Compute the cross-entropy for the DCM\n",
    "cross_entropy_DCM = log_loss(df_reduced.CHOICE, probs_DCM)\n",
    "\n",
    "print('The cross-entropy of the DCM is        ',\"{:.3f}\".format(cross_entropy_DCM))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q2** <br>\n",
    "The signs make sense as people in general want to be close to things as the city, stores and transport. Also they want less foreigners in their neighbourhood and less noise from traffic. They do want more green in their neighboorhood. \n",
    "We can see that people attach most value to not having a lot of foreigners close to their home and less to the other properties. After that green and noise are most important. \n",
    "    \n",
    "<br> The cross-entropy measures the performance of a classification model. The cross-entropy increases as the predicted probability diverges from the actual label. A perfect model would have a cross-entropy of 0, so minimization of the cross-entropy leads to optimization of the model. In the situation above we have found a cross-entropy of 0.889, which is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Based on your results, compute the WtP of the average decision maker to reduce the share of foreigners in a neighbourhood by 1 percentage point in terms of the distance to the grocery stores (0.5 pts)\n",
    "\n",
    "Thus, the answer must be of the following form: .... [minutes/percentage point].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Willingness-to-Pay estimates\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  33.91 min per percentage point\n"
     ]
    }
   ],
   "source": [
    "## Wtp for less foreigners in a neighbourhood compared to distance to grocery stores. So B_foreign/B_stores\n",
    "# Get the results in a pandas table\n",
    "print('Willingness-to-Pay estimates')\n",
    "print('----------')\n",
    "WtP_foreign_stores = betas1['B_foreign']/betas1['B_stores']\n",
    "\n",
    "print('Willingness to Pay; reduction in foreigners at an expense of store distance = ', \"{:.2f}\".format(WtP_foreign_stores),'min per percentage point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q3** <br>\n",
    "We could see from the beta-values already that people don't attach a lot of value to a short distance towards grocery stores (beta = -0.034432), while they do think a lower percentage of foreigners is important (beta = -1.195431). We can see from the Willingness-to-pay that for every percentage of less foreigners, people are willing to add 34.7 min to the walking distance towards the nearest grocery store. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Train a hybrid RUM-MNL-ANN model (1.5 pts)\n",
    "\n",
    "Since we are interested in the WtP of Q3, make sure when building the hybrid model to place the features of the share of foreigners and of the distance to the grocery stores in the *MNL part of the model*. For the *ANN part of the model* use 2 hidden layers, with 5 nodes each. \n",
    "\n",
    "\n",
    "**To get the scores, address the following:**\n",
    "\n",
    "\n",
    "- (A) Build the model, plot the loss as a function of the epochs & report the cross entropy of your final model based on the test data. (1.0 pt)\n",
    "- (B) Compare the model performance to that of the discrete choice model. Interpret the result. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_RUM_MNL_ANN_model(NALT, no_X_MNL, no_X_ANN, num_nodes, seed=None):\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    #######################\n",
    "    ### DEFINE MNL PART ###\n",
    "    #######################\n",
    "    # INPUT FOR MNL PART\n",
    "    X_MNL = Input((no_X_MNL, NALT, 1), name = 'Features2MNL')\n",
    "\n",
    "    # COMPUTE UTILITY FOR MNL\n",
    "    V_MNL = Conv2D(filters = 1, kernel_size = [no_X_MNL,1], strides = (1,1), padding = 'valid', name = 'MNL_layer', use_bias = False, trainable = True)(X_MNL)\n",
    "\n",
    "    #######################\n",
    "    ### DEFINE ANN PART ###\n",
    "    #######################\n",
    "    # INPUT FOR ANN PART\n",
    "    X_ANN = Input((no_X_ANN), name ='Features2ANN')\n",
    "\n",
    "    # CREATE HIDDEN LAYER(S) OF ANN\n",
    "    layer1_ANN = Dense(units = num_nodes, name = \"ANN_layer1\", use_bias = True)(X_ANN) \n",
    "    layer2_ANN = Dense(units = num_nodes, name = \"ANN_layer2\", use_bias = True)(layer1_ANN)\n",
    "\n",
    "    # COMPUTE UTILITY FOR ANN \n",
    "    V_ANN = Dense(units = NALT, name = \"V_ANN\")(layer2_ANN) \n",
    "\n",
    "    ####################\n",
    "    ### DEFINE MODEL ###\n",
    "    ####################\n",
    "    # RESHAPE TENSORS TO [1 X NALT]\n",
    "    V_MNL = Reshape([NALT], name = 'Flatten_Dim_MNL')(V_MNL)\n",
    "    V_ANN = Reshape([NALT], name = 'Flatten_Dim_ANN')(V_ANN) \n",
    "\n",
    "    # SUM THE UTILITIES OF BOTH MODEL PARTS\n",
    "    V_MNL_ANN = Add(name = \"Combining_Vs\")([V_MNL,V_ANN])\n",
    "\n",
    "    # CREATE LOGIT (AKA SOFTMAX ) OUTPUT LAYER\n",
    "    logits = Activation('softmax', name = 'Probability')(V_MNL_ANN)\n",
    "\n",
    "    # BUILD THE MODEL\n",
    "    model = Model(inputs = [X_MNL, X_ANN], outputs = logits)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NALT = 3                                            # Number of alterantives in the data set.\n",
    "no_X_MNL = 2                                        # Number of attributes with behavioural interest (-->MNL model part).  In this example we are particularly interested in the WtP for extra storage space --> Cost & Storage\n",
    "no_X_ANN = (df.columns.size - 1) - NALT*no_X_MNL    # Number of features without behavioural interest (-->ANN model part). In this example we are not behaviourall interested in Camera, Size, and the socio demographic variables\n",
    "num_nodes = 5                                       # Number of nodes in hidden layer(s). Again we use 2 hidden layers with *num_nodes* nodes each\n",
    "nEpoch = 500                                        # Number epochs for training (max). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ANN_data(X, Y):\n",
    "    Y_cat = to_categorical(Y-1, num_classes = 3)\n",
    "\n",
    "    # Create x input for MNL layer, and rescale\n",
    "    scale = 1 # We cannot just use the sklearn scaler here, as it is import for the interpretation later how the input data are scaled. \n",
    "    x_mnl = np.array([[np.divide(X['STORES1'], scale), np.divide(X['FOREIGN1'], scale)],\n",
    "                      [np.divide(X['STORES2'], scale), np.divide(X['FOREIGN2'], scale)],\n",
    "                      [np.divide(X['STORES3'], scale), np.divide(X['FOREIGN3'], scale)]])\n",
    "    x_mnl = np.swapaxes(x_mnl, 0, 2)\n",
    "    x_mnl = np.expand_dims(x_mnl, 3)\n",
    "    print('Shape of x_mnl', x_mnl.shape)\n",
    "\n",
    "    # Create x input for ANN layer\n",
    "    x_ann = np.array([[X['TRANSPORT1'], X['CITY1'], X['NOISE1'], X['GREEN1'], X['TRANSPORT2'], X['CITY2'], X['NOISE2'], X['GREEN2'], X['TRANSPORT3'], X['CITY3'], X['NOISE3'], X['GREEN3'], X['SSTADT'], X['WOMAN'], X['AGE'], X['ENVCONC']]])\n",
    "    x_ann = np.squeeze(np.swapaxes(x_ann, 0, 2))\n",
    "\n",
    "    # Rescale input for the ANN part\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(x_ann)  \n",
    "    x_ann = scaler.transform(x_ann)  \n",
    "    print('Shape of x_ann',x_ann.shape)\n",
    "    return x_mnl, x_ann, Y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl (9656, 2, 3, 1)\n",
      "Shape of x_ann (9656, 16)\n",
      "\n",
      "Total number of obervations in the data set =  9656\n",
      "Number of obervations in the training set   =  6276\n",
      "Number of obervations in the test set       =  3380\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training and test part\n",
    "X = df\n",
    "Y = df['CHOICE']\n",
    "x_mnl, x_ann, Y_cat = preprocess_ANN_data(X, Y)\n",
    "\n",
    "X_mnl_train, X_mnl_test, Y_train, Y_test = train_test_split(x_mnl, Y_cat, random_state = 1, test_size = 0.35)\n",
    "X_ann_train, X_ann_test, Y_train, Y_test = train_test_split(x_ann, Y_cat, random_state = 1, test_size = 0.35)\n",
    "print('\\nTotal number of obervations in the data set = ', len(x_mnl))\n",
    "print('Number of obervations in the training set   = ', len(X_mnl_train))\n",
    "print('Number of obervations in the test set       = ', len(X_mnl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 19:00:00.103080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 19:00:00.477022: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.4728 - accuracy: 0.4144 - val_loss: 2.4094 - val_accuracy: 0.4053\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 2.3725 - accuracy: 0.4181 - val_loss: 2.3176 - val_accuracy: 0.4059\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 2.2787 - accuracy: 0.4192 - val_loss: 2.2306 - val_accuracy: 0.4065\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 2.1900 - accuracy: 0.4210 - val_loss: 2.1482 - val_accuracy: 0.4107\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.1062 - accuracy: 0.4242 - val_loss: 2.0701 - val_accuracy: 0.4213\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0272 - accuracy: 0.4304 - val_loss: 1.9966 - val_accuracy: 0.4293\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9529 - accuracy: 0.4359 - val_loss: 1.9276 - val_accuracy: 0.4393\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8836 - accuracy: 0.4402 - val_loss: 1.8634 - val_accuracy: 0.4432\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.8193 - accuracy: 0.4426 - val_loss: 1.8040 - val_accuracy: 0.4473\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7601 - accuracy: 0.4517 - val_loss: 1.7493 - val_accuracy: 0.4565\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7059 - accuracy: 0.4611 - val_loss: 1.6989 - val_accuracy: 0.4651\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6564 - accuracy: 0.4704 - val_loss: 1.6524 - val_accuracy: 0.4725\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6108 - accuracy: 0.4772 - val_loss: 1.6090 - val_accuracy: 0.4805\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5686 - accuracy: 0.4836 - val_loss: 1.5682 - val_accuracy: 0.4899\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5290 - accuracy: 0.4917 - val_loss: 1.5295 - val_accuracy: 0.4938\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4917 - accuracy: 0.4970 - val_loss: 1.4926 - val_accuracy: 0.4962\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4562 - accuracy: 0.5037 - val_loss: 1.4572 - val_accuracy: 0.4982\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4222 - accuracy: 0.5078 - val_loss: 1.4230 - val_accuracy: 0.5006\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3894 - accuracy: 0.5080 - val_loss: 1.3897 - val_accuracy: 0.5038\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3576 - accuracy: 0.5089 - val_loss: 1.3573 - val_accuracy: 0.5068\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3266 - accuracy: 0.5108 - val_loss: 1.3257 - val_accuracy: 0.5089\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2965 - accuracy: 0.5145 - val_loss: 1.2949 - val_accuracy: 0.5107\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2672 - accuracy: 0.5172 - val_loss: 1.2651 - val_accuracy: 0.5115\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2389 - accuracy: 0.5231 - val_loss: 1.2363 - val_accuracy: 0.5133\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2115 - accuracy: 0.5274 - val_loss: 1.2086 - val_accuracy: 0.5148\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1853 - accuracy: 0.5322 - val_loss: 1.1820 - val_accuracy: 0.5180\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1601 - accuracy: 0.5335 - val_loss: 1.1564 - val_accuracy: 0.5207\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1360 - accuracy: 0.5374 - val_loss: 1.1320 - val_accuracy: 0.5272\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.1130 - accuracy: 0.5405 - val_loss: 1.1088 - val_accuracy: 0.5337\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0911 - accuracy: 0.5451 - val_loss: 1.0869 - val_accuracy: 0.5349\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.0705 - accuracy: 0.5468 - val_loss: 1.0665 - val_accuracy: 0.5361\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0513 - accuracy: 0.5470 - val_loss: 1.0477 - val_accuracy: 0.5382\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0336 - accuracy: 0.5504 - val_loss: 1.0304 - val_accuracy: 0.5447\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0173 - accuracy: 0.5534 - val_loss: 1.0147 - val_accuracy: 0.5503\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.0025 - accuracy: 0.5550 - val_loss: 1.0004 - val_accuracy: 0.5618\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9891 - accuracy: 0.5604 - val_loss: 0.9874 - val_accuracy: 0.5698\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9769 - accuracy: 0.5636 - val_loss: 0.9755 - val_accuracy: 0.5713\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9657 - accuracy: 0.5628 - val_loss: 0.9644 - val_accuracy: 0.5698\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9553 - accuracy: 0.5633 - val_loss: 0.9541 - val_accuracy: 0.5669\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9456 - accuracy: 0.5612 - val_loss: 0.9443 - val_accuracy: 0.5627\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9365 - accuracy: 0.5620 - val_loss: 0.9350 - val_accuracy: 0.5651\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9279 - accuracy: 0.5594 - val_loss: 0.9261 - val_accuracy: 0.5645\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9197 - accuracy: 0.5599 - val_loss: 0.9178 - val_accuracy: 0.5660\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9120 - accuracy: 0.5598 - val_loss: 0.9100 - val_accuracy: 0.5689\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.9049 - accuracy: 0.5607 - val_loss: 0.9028 - val_accuracy: 0.5698\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8983 - accuracy: 0.5594 - val_loss: 0.8961 - val_accuracy: 0.5728\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8922 - accuracy: 0.5591 - val_loss: 0.8898 - val_accuracy: 0.5740\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8866 - accuracy: 0.5617 - val_loss: 0.8841 - val_accuracy: 0.5760\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8814 - accuracy: 0.5639 - val_loss: 0.8788 - val_accuracy: 0.5769\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8767 - accuracy: 0.5677 - val_loss: 0.8738 - val_accuracy: 0.5781\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8723 - accuracy: 0.5685 - val_loss: 0.8692 - val_accuracy: 0.5781\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8682 - accuracy: 0.5693 - val_loss: 0.8650 - val_accuracy: 0.5781\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8646 - accuracy: 0.5712 - val_loss: 0.8611 - val_accuracy: 0.5787\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8612 - accuracy: 0.5722 - val_loss: 0.8575 - val_accuracy: 0.5822\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8582 - accuracy: 0.5738 - val_loss: 0.8543 - val_accuracy: 0.5852\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8555 - accuracy: 0.5778 - val_loss: 0.8513 - val_accuracy: 0.5932\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8530 - accuracy: 0.5811 - val_loss: 0.8487 - val_accuracy: 0.5947\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8509 - accuracy: 0.5838 - val_loss: 0.8464 - val_accuracy: 0.5976\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.8491 - accuracy: 0.5868 - val_loss: 0.8444 - val_accuracy: 0.5997\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.8474 - accuracy: 0.5886 - val_loss: 0.8426 - val_accuracy: 0.6033\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8460 - accuracy: 0.5921 - val_loss: 0.8410 - val_accuracy: 0.6050\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8448 - accuracy: 0.5953 - val_loss: 0.8396 - val_accuracy: 0.6101\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8437 - accuracy: 0.5970 - val_loss: 0.8385 - val_accuracy: 0.6109\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8428 - accuracy: 0.5994 - val_loss: 0.8375 - val_accuracy: 0.6130\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8420 - accuracy: 0.6017 - val_loss: 0.8367 - val_accuracy: 0.6139\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8414 - accuracy: 0.6037 - val_loss: 0.8361 - val_accuracy: 0.6151\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8408 - accuracy: 0.6036 - val_loss: 0.8355 - val_accuracy: 0.6157\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8404 - accuracy: 0.6039 - val_loss: 0.8351 - val_accuracy: 0.6160\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8401 - accuracy: 0.6040 - val_loss: 0.8348 - val_accuracy: 0.6160\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8398 - accuracy: 0.6042 - val_loss: 0.8346 - val_accuracy: 0.6160\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8396 - accuracy: 0.6052 - val_loss: 0.8344 - val_accuracy: 0.6160\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8394 - accuracy: 0.6052 - val_loss: 0.8343 - val_accuracy: 0.6160\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8392 - accuracy: 0.6053 - val_loss: 0.8342 - val_accuracy: 0.6169\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8391 - accuracy: 0.6055 - val_loss: 0.8341 - val_accuracy: 0.6175\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8390 - accuracy: 0.6064 - val_loss: 0.8341 - val_accuracy: 0.6180\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8388 - accuracy: 0.6064 - val_loss: 0.8341 - val_accuracy: 0.6198\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8387 - accuracy: 0.6076 - val_loss: 0.8340 - val_accuracy: 0.6204\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8386 - accuracy: 0.6069 - val_loss: 0.8340 - val_accuracy: 0.6207\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8384 - accuracy: 0.6074 - val_loss: 0.8340 - val_accuracy: 0.6210\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8383 - accuracy: 0.6080 - val_loss: 0.8340 - val_accuracy: 0.6210\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8381 - accuracy: 0.6083 - val_loss: 0.8340 - val_accuracy: 0.6213\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8380 - accuracy: 0.6080 - val_loss: 0.8339 - val_accuracy: 0.6198\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8378 - accuracy: 0.6082 - val_loss: 0.8339 - val_accuracy: 0.6192\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8377 - accuracy: 0.6082 - val_loss: 0.8339 - val_accuracy: 0.6204\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8375 - accuracy: 0.6080 - val_loss: 0.8338 - val_accuracy: 0.6222\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8373 - accuracy: 0.6085 - val_loss: 0.8337 - val_accuracy: 0.6216\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8372 - accuracy: 0.6091 - val_loss: 0.8336 - val_accuracy: 0.6210\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8370 - accuracy: 0.6091 - val_loss: 0.8336 - val_accuracy: 0.6213\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8369 - accuracy: 0.6090 - val_loss: 0.8335 - val_accuracy: 0.6213\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8367 - accuracy: 0.6088 - val_loss: 0.8334 - val_accuracy: 0.6198\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8366 - accuracy: 0.6080 - val_loss: 0.8333 - val_accuracy: 0.6207\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8364 - accuracy: 0.6087 - val_loss: 0.8332 - val_accuracy: 0.6195\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8363 - accuracy: 0.6085 - val_loss: 0.8331 - val_accuracy: 0.6180\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8362 - accuracy: 0.6082 - val_loss: 0.8330 - val_accuracy: 0.6180\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8360 - accuracy: 0.6077 - val_loss: 0.8329 - val_accuracy: 0.6189\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8359 - accuracy: 0.6090 - val_loss: 0.8329 - val_accuracy: 0.6189\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8358 - accuracy: 0.6103 - val_loss: 0.8328 - val_accuracy: 0.6195\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8357 - accuracy: 0.6096 - val_loss: 0.8328 - val_accuracy: 0.6201\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8356 - accuracy: 0.6093 - val_loss: 0.8328 - val_accuracy: 0.6207\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8355 - accuracy: 0.6085 - val_loss: 0.8327 - val_accuracy: 0.6216\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8354 - accuracy: 0.6080 - val_loss: 0.8327 - val_accuracy: 0.6228\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8353 - accuracy: 0.6080 - val_loss: 0.8327 - val_accuracy: 0.6237\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8353 - accuracy: 0.6079 - val_loss: 0.8327 - val_accuracy: 0.6237\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8352 - accuracy: 0.6076 - val_loss: 0.8327 - val_accuracy: 0.6234\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8351 - accuracy: 0.6064 - val_loss: 0.8327 - val_accuracy: 0.6231\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8351 - accuracy: 0.6066 - val_loss: 0.8327 - val_accuracy: 0.6237\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8350 - accuracy: 0.6064 - val_loss: 0.8327 - val_accuracy: 0.6234\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.835\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model = hybrid_RUM_MNL_ANN_model(NALT, no_X_MNL, no_X_ANN, num_nodes, seed=0)\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-2), metrics = [\"accuracy\"], loss = 'categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "early_stopping = EarlyStopping(patience = 4, monitor = 'val_loss')\n",
    "history = model.fit([X_mnl_train, X_ann_train],Y_train, batch_size=len(X_mnl_train), epochs = nEpoch, verbose = 1, validation_data = ([X_mnl_test, X_ann_test], Y_test), callbacks = [early_stopping])\n",
    "\n",
    "betas_layer = model.get_layer(name = 'MNL_layer')\n",
    "betas = betas_layer.get_weights()\n",
    "print('The cross-entropy on the test data of the tensor flow ANN is',\"{:.3f}\".format(history.history['loss'][-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss as a function of epochs\n",
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.ylim(0.8,1)\n",
    "\n",
    "# plot accuracy\n",
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label = 'test')\n",
    "plt.ylim(0, 0.8)\n",
    "plt.legend()\n",
    "\n",
    "# Tweak spacing between subplots to prevent labels from overlapping\n",
    "plt.subplots_adjust(hspace = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q4** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Compute the WtP of the average decision maker to reduce the share of foreigners in a neighbourhood by 1 percentage point using the results from the hybrid model. Compare the outcome with the results of your discrete choice model (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta_STORES    =  -0.045\n",
      "Beta_FOREIGN =  -1.492\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  33.49 min per percentage point\n"
     ]
    }
   ],
   "source": [
    "# Show the trained taste parameters, from the MNL part\n",
    "beta_STORES = np.squeeze((betas[0][0]))\n",
    "beta_FOREIGN = np.squeeze((betas[0][1]))\n",
    "print('Beta_STORES    = ', \"{:.3f}\".format(beta_STORES )) \n",
    "print('Beta_FOREIGN = ', \"{:.3f}\".format(beta_FOREIGN ))\n",
    "\n",
    "# Compute the Willingness to Pay for a Gb extra storage space\n",
    "WtP_foreign_stores_mnl = beta_FOREIGN/beta_STORES\n",
    "print('Willingness-to-Pay estimates Hybrid model')\n",
    "print('----------')\n",
    "\n",
    "print('Willingness to Pay; reduction in foreigners at an expense of store distance = ', \"{:.2f}\".format(WtP_foreign_stores_mnl),'min per percentage point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy training data at final epoch  =  0.835\n",
      "Log-likelihood training data at final epoch =  -5240.5\n",
      "rho square training data at final epoch     =  0.24\n",
      "\n",
      "Cross-entropy test data at final epoch     =  0.833\n",
      "Log-likelihood test data at final epoch    =  -2814.6\n",
      "rho square test data at final epoch        =  0.24\n"
     ]
    }
   ],
   "source": [
    "# For comparison convert the loss to log-likelihood and rho^2\n",
    "hist_loss_train = history.history.get('loss')\n",
    "LL_final_train = -np.array(hist_loss_train[len(hist_loss_train)-1]) *len(Y_train)\n",
    "print('Cross-entropy training data at final epoch  = ', \"{:.3f}\".format(hist_loss_train[len(hist_loss_train)-1]))\n",
    "print('Log-likelihood training data at final epoch = ', \"{:.1f}\".format(LL_final_train))\n",
    "print('rho square training data at final epoch     = ', \"{:.2f}\".format(1 - LL_final_train / -(len(Y_train)*np.log(3))))\n",
    "print()\n",
    "\n",
    "hist_loss_test = history.history.get('val_loss')\n",
    "LL_final_test = -np.array(hist_loss_test[len(hist_loss_test)-1]) *len(Y_test)\n",
    "print('Cross-entropy test data at final epoch     = ', \"{:.3f}\".format(hist_loss_test[len(hist_loss_test)-1]))\n",
    "print('Log-likelihood test data at final epoch    = ', \"{:.1f}\".format(LL_final_test))\n",
    "print('rho square test data at final epoch        = ', \"{:.2f}\".format(1 - LL_final_test / -(len(Y_test)*np.log(3))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q5** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Explore whether, or not, the preferences of the inhabitants of the four cities regarding the trade-off between share of foreigners and distance to grocery stores are equal across the four cities. (1.5 pts)\n",
    "\n",
    "Perform a series of (clever) analyses, and interpret the findings. In other words, can we conclude that the inhabintants of all cities are equally xenophobic? For these analysis, use hybrid models, and/or DCMs.\n",
    "\n",
    "**Hint:** create new features capturing for the share of foreigners *per city*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the hybrid model because the cross entropy is the lowest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl (2272, 2, 3, 1)\n",
      "Shape of x_ann (2272, 16)\n",
      "\n",
      "Total number of obervations in the data set =  2272\n",
      "Number of obervations in the training set   =  1476\n",
      "Number of obervations in the test set       =  796\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 2.3994 - accuracy: 0.4282 - val_loss: 2.4662 - val_accuracy: 0.3894\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3072 - accuracy: 0.4343 - val_loss: 2.3710 - val_accuracy: 0.3869\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2195 - accuracy: 0.4350 - val_loss: 2.2812 - val_accuracy: 0.3894\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.1360 - accuracy: 0.4343 - val_loss: 2.1966 - val_accuracy: 0.3957\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0564 - accuracy: 0.4390 - val_loss: 2.1171 - val_accuracy: 0.4083\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9808 - accuracy: 0.4424 - val_loss: 2.0429 - val_accuracy: 0.4133\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9093 - accuracy: 0.4533 - val_loss: 1.9743 - val_accuracy: 0.4196\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8423 - accuracy: 0.4560 - val_loss: 1.9113 - val_accuracy: 0.4309\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.7802 - accuracy: 0.4614 - val_loss: 1.8540 - val_accuracy: 0.4347\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.7232 - accuracy: 0.4648 - val_loss: 1.8019 - val_accuracy: 0.4472\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.6712 - accuracy: 0.4743 - val_loss: 1.7543 - val_accuracy: 0.4686\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.6238 - accuracy: 0.5068 - val_loss: 1.7102 - val_accuracy: 0.4698\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5800 - accuracy: 0.5047 - val_loss: 1.6685 - val_accuracy: 0.4673\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5392 - accuracy: 0.5027 - val_loss: 1.6284 - val_accuracy: 0.4698\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5005 - accuracy: 0.5054 - val_loss: 1.5892 - val_accuracy: 0.4749\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4636 - accuracy: 0.5047 - val_loss: 1.5505 - val_accuracy: 0.4761\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4280 - accuracy: 0.5014 - val_loss: 1.5122 - val_accuracy: 0.4824\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3935 - accuracy: 0.5102 - val_loss: 1.4743 - val_accuracy: 0.4862\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3601 - accuracy: 0.5190 - val_loss: 1.4368 - val_accuracy: 0.4912\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3277 - accuracy: 0.5224 - val_loss: 1.4000 - val_accuracy: 0.4987\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2962 - accuracy: 0.5264 - val_loss: 1.3641 - val_accuracy: 0.5025\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2657 - accuracy: 0.5285 - val_loss: 1.3291 - val_accuracy: 0.5050\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2362 - accuracy: 0.5325 - val_loss: 1.2953 - val_accuracy: 0.5101\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2077 - accuracy: 0.5373 - val_loss: 1.2628 - val_accuracy: 0.5101\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1802 - accuracy: 0.5373 - val_loss: 1.2316 - val_accuracy: 0.5163\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1538 - accuracy: 0.5440 - val_loss: 1.2020 - val_accuracy: 0.5214\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1287 - accuracy: 0.5440 - val_loss: 1.1740 - val_accuracy: 0.5302\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1049 - accuracy: 0.5461 - val_loss: 1.1477 - val_accuracy: 0.5327\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0826 - accuracy: 0.5522 - val_loss: 1.1231 - val_accuracy: 0.5327\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0619 - accuracy: 0.5522 - val_loss: 1.1004 - val_accuracy: 0.5327\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.0427 - accuracy: 0.5589 - val_loss: 1.0793 - val_accuracy: 0.5415\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.0251 - accuracy: 0.5684 - val_loss: 1.0599 - val_accuracy: 0.5452\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0090 - accuracy: 0.5745 - val_loss: 1.0420 - val_accuracy: 0.5477\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9943 - accuracy: 0.5772 - val_loss: 1.0255 - val_accuracy: 0.5503\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9808 - accuracy: 0.5813 - val_loss: 1.0103 - val_accuracy: 0.5603\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9684 - accuracy: 0.5793 - val_loss: 0.9962 - val_accuracy: 0.5628\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9569 - accuracy: 0.5908 - val_loss: 0.9831 - val_accuracy: 0.5704\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9462 - accuracy: 0.5874 - val_loss: 0.9711 - val_accuracy: 0.5716\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9361 - accuracy: 0.5881 - val_loss: 0.9599 - val_accuracy: 0.5616\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9266 - accuracy: 0.5874 - val_loss: 0.9497 - val_accuracy: 0.5590\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9176 - accuracy: 0.5847 - val_loss: 0.9404 - val_accuracy: 0.5590\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9092 - accuracy: 0.5840 - val_loss: 0.9318 - val_accuracy: 0.5565\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9013 - accuracy: 0.5813 - val_loss: 0.9240 - val_accuracy: 0.5503\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8940 - accuracy: 0.5820 - val_loss: 0.9169 - val_accuracy: 0.5490\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8871 - accuracy: 0.5806 - val_loss: 0.9104 - val_accuracy: 0.5503\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.8807 - accuracy: 0.5766 - val_loss: 0.9044 - val_accuracy: 0.5503\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8748 - accuracy: 0.5766 - val_loss: 0.8989 - val_accuracy: 0.5528\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.8693 - accuracy: 0.5752 - val_loss: 0.8938 - val_accuracy: 0.5503\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8643 - accuracy: 0.5718 - val_loss: 0.8891 - val_accuracy: 0.5528\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8596 - accuracy: 0.5732 - val_loss: 0.8848 - val_accuracy: 0.5553\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8553 - accuracy: 0.5772 - val_loss: 0.8807 - val_accuracy: 0.5565\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8515 - accuracy: 0.5799 - val_loss: 0.8770 - val_accuracy: 0.5616\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8480 - accuracy: 0.5894 - val_loss: 0.8736 - val_accuracy: 0.5666\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8448 - accuracy: 0.5908 - val_loss: 0.8705 - val_accuracy: 0.5741\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8420 - accuracy: 0.5962 - val_loss: 0.8677 - val_accuracy: 0.5791\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8395 - accuracy: 0.6030 - val_loss: 0.8652 - val_accuracy: 0.5817\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8373 - accuracy: 0.6003 - val_loss: 0.8630 - val_accuracy: 0.5854\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8354 - accuracy: 0.6064 - val_loss: 0.8611 - val_accuracy: 0.5829\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8337 - accuracy: 0.6138 - val_loss: 0.8593 - val_accuracy: 0.5842\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8322 - accuracy: 0.6152 - val_loss: 0.8578 - val_accuracy: 0.5854\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8310 - accuracy: 0.6192 - val_loss: 0.8566 - val_accuracy: 0.5917\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8299 - accuracy: 0.6213 - val_loss: 0.8555 - val_accuracy: 0.6068\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8290 - accuracy: 0.6206 - val_loss: 0.8545 - val_accuracy: 0.6030\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8282 - accuracy: 0.6226 - val_loss: 0.8538 - val_accuracy: 0.6068\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8275 - accuracy: 0.6267 - val_loss: 0.8532 - val_accuracy: 0.6068\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8270 - accuracy: 0.6247 - val_loss: 0.8528 - val_accuracy: 0.6055\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8265 - accuracy: 0.6260 - val_loss: 0.8525 - val_accuracy: 0.6118\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8262 - accuracy: 0.6280 - val_loss: 0.8522 - val_accuracy: 0.6131\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8259 - accuracy: 0.6280 - val_loss: 0.8521 - val_accuracy: 0.6131\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8256 - accuracy: 0.6280 - val_loss: 0.8521 - val_accuracy: 0.6156\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8254 - accuracy: 0.6308 - val_loss: 0.8521 - val_accuracy: 0.6168\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8252 - accuracy: 0.6348 - val_loss: 0.8521 - val_accuracy: 0.6181\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8251 - accuracy: 0.6328 - val_loss: 0.8521 - val_accuracy: 0.6181\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8249 - accuracy: 0.6321 - val_loss: 0.8521 - val_accuracy: 0.6206\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8248 - accuracy: 0.6328 - val_loss: 0.8521 - val_accuracy: 0.6193\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.825\n",
      "Shape of x_mnl (1704, 2, 3, 1)\n",
      "Shape of x_ann (1704, 16)\n",
      "\n",
      "Total number of obervations in the data set =  1704\n",
      "Number of obervations in the training set   =  1107\n",
      "Number of obervations in the test set       =  597\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 2.4731 - accuracy: 0.4110 - val_loss: 2.4390 - val_accuracy: 0.3936\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.3687 - accuracy: 0.4173 - val_loss: 2.3474 - val_accuracy: 0.3920\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2708 - accuracy: 0.4246 - val_loss: 2.2598 - val_accuracy: 0.3936\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 2.1784 - accuracy: 0.4327 - val_loss: 2.1757 - val_accuracy: 0.4003\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 2.0906 - accuracy: 0.4372 - val_loss: 2.0953 - val_accuracy: 0.4020\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 2.0071 - accuracy: 0.4417 - val_loss: 2.0189 - val_accuracy: 0.4020\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.9279 - accuracy: 0.4444 - val_loss: 1.9474 - val_accuracy: 0.4104\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8536 - accuracy: 0.4535 - val_loss: 1.8812 - val_accuracy: 0.4188\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7845 - accuracy: 0.4562 - val_loss: 1.8207 - val_accuracy: 0.4271\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7209 - accuracy: 0.4607 - val_loss: 1.7656 - val_accuracy: 0.4422\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6628 - accuracy: 0.4652 - val_loss: 1.7157 - val_accuracy: 0.4523\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6100 - accuracy: 0.4770 - val_loss: 1.6705 - val_accuracy: 0.4556\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.5623 - accuracy: 0.4878 - val_loss: 1.6296 - val_accuracy: 0.4791\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5192 - accuracy: 0.5131 - val_loss: 1.5924 - val_accuracy: 0.4925\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4804 - accuracy: 0.5212 - val_loss: 1.5583 - val_accuracy: 0.5042\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4450 - accuracy: 0.5276 - val_loss: 1.5266 - val_accuracy: 0.5109\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4123 - accuracy: 0.5357 - val_loss: 1.4966 - val_accuracy: 0.5276\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3816 - accuracy: 0.5393 - val_loss: 1.4678 - val_accuracy: 0.5327\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3524 - accuracy: 0.5429 - val_loss: 1.4396 - val_accuracy: 0.5377\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3243 - accuracy: 0.5474 - val_loss: 1.4117 - val_accuracy: 0.5427\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2968 - accuracy: 0.5547 - val_loss: 1.3839 - val_accuracy: 0.5410\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2698 - accuracy: 0.5619 - val_loss: 1.3563 - val_accuracy: 0.5444\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2433 - accuracy: 0.5664 - val_loss: 1.3287 - val_accuracy: 0.5494\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2171 - accuracy: 0.5700 - val_loss: 1.3014 - val_accuracy: 0.5461\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1913 - accuracy: 0.5763 - val_loss: 1.2745 - val_accuracy: 0.5477\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1658 - accuracy: 0.5863 - val_loss: 1.2481 - val_accuracy: 0.5528\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1409 - accuracy: 0.5935 - val_loss: 1.2225 - val_accuracy: 0.5595\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1166 - accuracy: 0.5935 - val_loss: 1.1978 - val_accuracy: 0.5611\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0930 - accuracy: 0.5989 - val_loss: 1.1742 - val_accuracy: 0.5628\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0703 - accuracy: 0.6043 - val_loss: 1.1519 - val_accuracy: 0.5662\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0487 - accuracy: 0.6043 - val_loss: 1.1310 - val_accuracy: 0.5645\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.0282 - accuracy: 0.6052 - val_loss: 1.1115 - val_accuracy: 0.5645\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.0090 - accuracy: 0.6043 - val_loss: 1.0935 - val_accuracy: 0.5645\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9911 - accuracy: 0.6089 - val_loss: 1.0769 - val_accuracy: 0.5662\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9747 - accuracy: 0.6107 - val_loss: 1.0617 - val_accuracy: 0.5662\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9596 - accuracy: 0.6134 - val_loss: 1.0478 - val_accuracy: 0.5712\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9457 - accuracy: 0.6206 - val_loss: 1.0348 - val_accuracy: 0.5779\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.9329 - accuracy: 0.6179 - val_loss: 1.0227 - val_accuracy: 0.5946\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9211 - accuracy: 0.6305 - val_loss: 1.0113 - val_accuracy: 0.5963\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.9102 - accuracy: 0.6305 - val_loss: 1.0004 - val_accuracy: 0.5980\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9000 - accuracy: 0.6242 - val_loss: 0.9899 - val_accuracy: 0.5963\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8904 - accuracy: 0.6242 - val_loss: 0.9798 - val_accuracy: 0.5963\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8814 - accuracy: 0.6242 - val_loss: 0.9701 - val_accuracy: 0.5946\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8730 - accuracy: 0.6224 - val_loss: 0.9607 - val_accuracy: 0.5963\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.8651 - accuracy: 0.6251 - val_loss: 0.9516 - val_accuracy: 0.5997\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8578 - accuracy: 0.6287 - val_loss: 0.9430 - val_accuracy: 0.6013\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8510 - accuracy: 0.6278 - val_loss: 0.9347 - val_accuracy: 0.6030\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8447 - accuracy: 0.6287 - val_loss: 0.9269 - val_accuracy: 0.6030\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8388 - accuracy: 0.6269 - val_loss: 0.9195 - val_accuracy: 0.6013\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8334 - accuracy: 0.6332 - val_loss: 0.9126 - val_accuracy: 0.6013\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8284 - accuracy: 0.6332 - val_loss: 0.9062 - val_accuracy: 0.5997\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8237 - accuracy: 0.6341 - val_loss: 0.9004 - val_accuracy: 0.5997\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8195 - accuracy: 0.6314 - val_loss: 0.8950 - val_accuracy: 0.5980\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8156 - accuracy: 0.6314 - val_loss: 0.8902 - val_accuracy: 0.5963\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8121 - accuracy: 0.6360 - val_loss: 0.8860 - val_accuracy: 0.5997\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8088 - accuracy: 0.6360 - val_loss: 0.8822 - val_accuracy: 0.6030\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8059 - accuracy: 0.6360 - val_loss: 0.8789 - val_accuracy: 0.6080\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8032 - accuracy: 0.6287 - val_loss: 0.8761 - val_accuracy: 0.6030\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8008 - accuracy: 0.6305 - val_loss: 0.8737 - val_accuracy: 0.6030\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7986 - accuracy: 0.6269 - val_loss: 0.8717 - val_accuracy: 0.6080\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7966 - accuracy: 0.6278 - val_loss: 0.8701 - val_accuracy: 0.6047\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7948 - accuracy: 0.6314 - val_loss: 0.8688 - val_accuracy: 0.6080\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7931 - accuracy: 0.6332 - val_loss: 0.8678 - val_accuracy: 0.6064\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7917 - accuracy: 0.6350 - val_loss: 0.8670 - val_accuracy: 0.6064\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7904 - accuracy: 0.6350 - val_loss: 0.8664 - val_accuracy: 0.6047\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7892 - accuracy: 0.6360 - val_loss: 0.8660 - val_accuracy: 0.6047\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7882 - accuracy: 0.6369 - val_loss: 0.8657 - val_accuracy: 0.6064\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7873 - accuracy: 0.6369 - val_loss: 0.8655 - val_accuracy: 0.6013\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7865 - accuracy: 0.6396 - val_loss: 0.8654 - val_accuracy: 0.5997\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7858 - accuracy: 0.6387 - val_loss: 0.8654 - val_accuracy: 0.5997\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7851 - accuracy: 0.6378 - val_loss: 0.8654 - val_accuracy: 0.6013\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7845 - accuracy: 0.6350 - val_loss: 0.8655 - val_accuracy: 0.5997\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7840 - accuracy: 0.6350 - val_loss: 0.8656 - val_accuracy: 0.5997\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7836 - accuracy: 0.6360 - val_loss: 0.8658 - val_accuracy: 0.5997\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.784\n",
      "Shape of x_mnl (3144, 2, 3, 1)\n",
      "Shape of x_ann (3144, 16)\n",
      "\n",
      "Total number of obervations in the data set =  3144\n",
      "Number of obervations in the training set   =  2043\n",
      "Number of obervations in the test set       =  1101\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 2.4666 - accuracy: 0.4121 - val_loss: 2.5499 - val_accuracy: 0.3942\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 2.3647 - accuracy: 0.4161 - val_loss: 2.4522 - val_accuracy: 0.3951\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2683 - accuracy: 0.4141 - val_loss: 2.3605 - val_accuracy: 0.3869\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1768 - accuracy: 0.4131 - val_loss: 2.2739 - val_accuracy: 0.3924\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0899 - accuracy: 0.4190 - val_loss: 2.1922 - val_accuracy: 0.3960\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 2.0071 - accuracy: 0.4293 - val_loss: 2.1152 - val_accuracy: 0.4024\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.9288 - accuracy: 0.4381 - val_loss: 2.0430 - val_accuracy: 0.4096\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8552 - accuracy: 0.4425 - val_loss: 1.9758 - val_accuracy: 0.4169\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.7866 - accuracy: 0.4479 - val_loss: 1.9138 - val_accuracy: 0.4323\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.7236 - accuracy: 0.4552 - val_loss: 1.8568 - val_accuracy: 0.4432\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.6664 - accuracy: 0.4743 - val_loss: 1.8043 - val_accuracy: 0.4478\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6147 - accuracy: 0.4851 - val_loss: 1.7555 - val_accuracy: 0.4696\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5678 - accuracy: 0.4934 - val_loss: 1.7094 - val_accuracy: 0.4759\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5248 - accuracy: 0.5091 - val_loss: 1.6651 - val_accuracy: 0.4823\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4844 - accuracy: 0.5169 - val_loss: 1.6219 - val_accuracy: 0.4796\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4460 - accuracy: 0.5218 - val_loss: 1.5796 - val_accuracy: 0.4796\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.4090 - accuracy: 0.5252 - val_loss: 1.5381 - val_accuracy: 0.4805\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.3733 - accuracy: 0.5311 - val_loss: 1.4977 - val_accuracy: 0.4805\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3390 - accuracy: 0.5301 - val_loss: 1.4587 - val_accuracy: 0.4814\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3064 - accuracy: 0.5291 - val_loss: 1.4215 - val_accuracy: 0.4787\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.2757 - accuracy: 0.5247 - val_loss: 1.3860 - val_accuracy: 0.4796\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2470 - accuracy: 0.5233 - val_loss: 1.3525 - val_accuracy: 0.4787\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.2203 - accuracy: 0.5247 - val_loss: 1.3206 - val_accuracy: 0.4787\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.1952 - accuracy: 0.5242 - val_loss: 1.2900 - val_accuracy: 0.4886\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1713 - accuracy: 0.5316 - val_loss: 1.2606 - val_accuracy: 0.5032\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.1482 - accuracy: 0.5370 - val_loss: 1.2322 - val_accuracy: 0.5005\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1258 - accuracy: 0.5355 - val_loss: 1.2047 - val_accuracy: 0.5023\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1040 - accuracy: 0.5370 - val_loss: 1.1782 - val_accuracy: 0.4995\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0828 - accuracy: 0.5399 - val_loss: 1.1529 - val_accuracy: 0.5086\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.0624 - accuracy: 0.5482 - val_loss: 1.1289 - val_accuracy: 0.5077\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.0429 - accuracy: 0.5433 - val_loss: 1.1065 - val_accuracy: 0.5086\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0245 - accuracy: 0.5438 - val_loss: 1.0858 - val_accuracy: 0.5032\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0074 - accuracy: 0.5458 - val_loss: 1.0669 - val_accuracy: 0.5132\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9915 - accuracy: 0.5512 - val_loss: 1.0497 - val_accuracy: 0.5232\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9769 - accuracy: 0.5595 - val_loss: 1.0342 - val_accuracy: 0.5277\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.9635 - accuracy: 0.5658 - val_loss: 1.0202 - val_accuracy: 0.5350\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9514 - accuracy: 0.5649 - val_loss: 1.0075 - val_accuracy: 0.5404\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.9402 - accuracy: 0.5727 - val_loss: 0.9961 - val_accuracy: 0.5468\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.9301 - accuracy: 0.5746 - val_loss: 0.9858 - val_accuracy: 0.5559\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.9208 - accuracy: 0.5786 - val_loss: 0.9762 - val_accuracy: 0.5595\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9123 - accuracy: 0.5805 - val_loss: 0.9674 - val_accuracy: 0.5613\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.9045 - accuracy: 0.5830 - val_loss: 0.9591 - val_accuracy: 0.5649\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8973 - accuracy: 0.5820 - val_loss: 0.9513 - val_accuracy: 0.5640\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.8905 - accuracy: 0.5810 - val_loss: 0.9438 - val_accuracy: 0.5631\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8841 - accuracy: 0.5839 - val_loss: 0.9366 - val_accuracy: 0.5613\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8782 - accuracy: 0.5844 - val_loss: 0.9297 - val_accuracy: 0.5595\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8726 - accuracy: 0.5859 - val_loss: 0.9231 - val_accuracy: 0.5604\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8674 - accuracy: 0.5854 - val_loss: 0.9167 - val_accuracy: 0.5631\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8625 - accuracy: 0.5874 - val_loss: 0.9106 - val_accuracy: 0.5658\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8580 - accuracy: 0.5879 - val_loss: 0.9047 - val_accuracy: 0.5640\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8538 - accuracy: 0.5923 - val_loss: 0.8989 - val_accuracy: 0.5649\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8498 - accuracy: 0.5913 - val_loss: 0.8935 - val_accuracy: 0.5668\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8462 - accuracy: 0.5928 - val_loss: 0.8882 - val_accuracy: 0.5640\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8428 - accuracy: 0.5913 - val_loss: 0.8831 - val_accuracy: 0.5686\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8397 - accuracy: 0.5977 - val_loss: 0.8784 - val_accuracy: 0.5731\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8368 - accuracy: 0.5952 - val_loss: 0.8738 - val_accuracy: 0.5777\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8343 - accuracy: 0.5977 - val_loss: 0.8696 - val_accuracy: 0.5758\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8319 - accuracy: 0.6001 - val_loss: 0.8657 - val_accuracy: 0.5749\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8299 - accuracy: 0.5986 - val_loss: 0.8620 - val_accuracy: 0.5777\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.8280 - accuracy: 0.6006 - val_loss: 0.8586 - val_accuracy: 0.5849\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8264 - accuracy: 0.6025 - val_loss: 0.8555 - val_accuracy: 0.5886\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8249 - accuracy: 0.6035 - val_loss: 0.8526 - val_accuracy: 0.5931\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8236 - accuracy: 0.6065 - val_loss: 0.8500 - val_accuracy: 0.5995\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8225 - accuracy: 0.6074 - val_loss: 0.8476 - val_accuracy: 0.5976\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8215 - accuracy: 0.6070 - val_loss: 0.8455 - val_accuracy: 0.5995\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8207 - accuracy: 0.6084 - val_loss: 0.8435 - val_accuracy: 0.6013\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8199 - accuracy: 0.6055 - val_loss: 0.8417 - val_accuracy: 0.6031\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8193 - accuracy: 0.6094 - val_loss: 0.8400 - val_accuracy: 0.6085\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8187 - accuracy: 0.6104 - val_loss: 0.8386 - val_accuracy: 0.6122\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8183 - accuracy: 0.6148 - val_loss: 0.8373 - val_accuracy: 0.6167\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8179 - accuracy: 0.6163 - val_loss: 0.8361 - val_accuracy: 0.6194\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.8175 - accuracy: 0.6172 - val_loss: 0.8351 - val_accuracy: 0.6203\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8172 - accuracy: 0.6167 - val_loss: 0.8342 - val_accuracy: 0.6276\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.8170 - accuracy: 0.6182 - val_loss: 0.8335 - val_accuracy: 0.6312\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8168 - accuracy: 0.6163 - val_loss: 0.8329 - val_accuracy: 0.6358\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8166 - accuracy: 0.6163 - val_loss: 0.8323 - val_accuracy: 0.6367\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8164 - accuracy: 0.6148 - val_loss: 0.8319 - val_accuracy: 0.6403\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8162 - accuracy: 0.6167 - val_loss: 0.8315 - val_accuracy: 0.6394\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8160 - accuracy: 0.6158 - val_loss: 0.8312 - val_accuracy: 0.6403\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8159 - accuracy: 0.6177 - val_loss: 0.8309 - val_accuracy: 0.6403\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8157 - accuracy: 0.6187 - val_loss: 0.8307 - val_accuracy: 0.6394\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8155 - accuracy: 0.6172 - val_loss: 0.8305 - val_accuracy: 0.6385\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8154 - accuracy: 0.6187 - val_loss: 0.8303 - val_accuracy: 0.6394\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8152 - accuracy: 0.6197 - val_loss: 0.8302 - val_accuracy: 0.6403\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8150 - accuracy: 0.6202 - val_loss: 0.8300 - val_accuracy: 0.6394\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8149 - accuracy: 0.6197 - val_loss: 0.8299 - val_accuracy: 0.6403\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8147 - accuracy: 0.6197 - val_loss: 0.8299 - val_accuracy: 0.6403\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8145 - accuracy: 0.6192 - val_loss: 0.8298 - val_accuracy: 0.6403\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8144 - accuracy: 0.6197 - val_loss: 0.8298 - val_accuracy: 0.6394\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8142 - accuracy: 0.6197 - val_loss: 0.8298 - val_accuracy: 0.6394\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8140 - accuracy: 0.6192 - val_loss: 0.8298 - val_accuracy: 0.6376\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8139 - accuracy: 0.6211 - val_loss: 0.8299 - val_accuracy: 0.6367\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8137 - accuracy: 0.6197 - val_loss: 0.8299 - val_accuracy: 0.6358\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.814\n",
      "Shape of x_mnl (2536, 2, 3, 1)\n",
      "Shape of x_ann (2536, 16)\n",
      "\n",
      "Total number of obervations in the data set =  2536\n",
      "Number of obervations in the training set   =  1648\n",
      "Number of obervations in the test set       =  888\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            85          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 135\n",
      "Trainable params: 135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 2.4008 - accuracy: 0.4254 - val_loss: 2.4214 - val_accuracy: 0.4189\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2981 - accuracy: 0.4278 - val_loss: 2.3301 - val_accuracy: 0.4200\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.2014 - accuracy: 0.4302 - val_loss: 2.2445 - val_accuracy: 0.4167\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 2.1104 - accuracy: 0.4333 - val_loss: 2.1643 - val_accuracy: 0.4212\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.0248 - accuracy: 0.4351 - val_loss: 2.0896 - val_accuracy: 0.4268\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9446 - accuracy: 0.4363 - val_loss: 2.0206 - val_accuracy: 0.4302\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8702 - accuracy: 0.4454 - val_loss: 1.9580 - val_accuracy: 0.4437\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.8022 - accuracy: 0.4557 - val_loss: 1.9019 - val_accuracy: 0.4516\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7410 - accuracy: 0.4660 - val_loss: 1.8519 - val_accuracy: 0.4606\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6866 - accuracy: 0.4757 - val_loss: 1.8074 - val_accuracy: 0.4718\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6386 - accuracy: 0.4836 - val_loss: 1.7670 - val_accuracy: 0.4752\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.5960 - accuracy: 0.4970 - val_loss: 1.7290 - val_accuracy: 0.4842\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5576 - accuracy: 0.4988 - val_loss: 1.6924 - val_accuracy: 0.4932\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.5222 - accuracy: 0.5073 - val_loss: 1.6560 - val_accuracy: 0.4989\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4886 - accuracy: 0.5133 - val_loss: 1.6195 - val_accuracy: 0.4955\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.4563 - accuracy: 0.5164 - val_loss: 1.5827 - val_accuracy: 0.5045\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4248 - accuracy: 0.5176 - val_loss: 1.5458 - val_accuracy: 0.5034\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3939 - accuracy: 0.5255 - val_loss: 1.5091 - val_accuracy: 0.5045\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3636 - accuracy: 0.5303 - val_loss: 1.4727 - val_accuracy: 0.5068\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.3338 - accuracy: 0.5352 - val_loss: 1.4367 - val_accuracy: 0.5090\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3046 - accuracy: 0.5346 - val_loss: 1.4014 - val_accuracy: 0.5034\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2760 - accuracy: 0.5370 - val_loss: 1.3666 - val_accuracy: 0.5045\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.2479 - accuracy: 0.5394 - val_loss: 1.3326 - val_accuracy: 0.5101\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2203 - accuracy: 0.5388 - val_loss: 1.2994 - val_accuracy: 0.5090\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1933 - accuracy: 0.5437 - val_loss: 1.2671 - val_accuracy: 0.5124\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1670 - accuracy: 0.5455 - val_loss: 1.2361 - val_accuracy: 0.5124\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1414 - accuracy: 0.5461 - val_loss: 1.2063 - val_accuracy: 0.5180\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1168 - accuracy: 0.5467 - val_loss: 1.1781 - val_accuracy: 0.5180\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0932 - accuracy: 0.5455 - val_loss: 1.1515 - val_accuracy: 0.5191\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0708 - accuracy: 0.5528 - val_loss: 1.1265 - val_accuracy: 0.5203\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0496 - accuracy: 0.5546 - val_loss: 1.1033 - val_accuracy: 0.5236\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0297 - accuracy: 0.5540 - val_loss: 1.0819 - val_accuracy: 0.5248\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0113 - accuracy: 0.5583 - val_loss: 1.0623 - val_accuracy: 0.5282\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9942 - accuracy: 0.5583 - val_loss: 1.0444 - val_accuracy: 0.5293\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9785 - accuracy: 0.5601 - val_loss: 1.0283 - val_accuracy: 0.5282\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9642 - accuracy: 0.5607 - val_loss: 1.0137 - val_accuracy: 0.5282\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9511 - accuracy: 0.5674 - val_loss: 1.0007 - val_accuracy: 0.5417\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9393 - accuracy: 0.5813 - val_loss: 0.9889 - val_accuracy: 0.5574\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9284 - accuracy: 0.5874 - val_loss: 0.9783 - val_accuracy: 0.5608\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9184 - accuracy: 0.5934 - val_loss: 0.9686 - val_accuracy: 0.5552\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9091 - accuracy: 0.5910 - val_loss: 0.9597 - val_accuracy: 0.5552\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9005 - accuracy: 0.5934 - val_loss: 0.9515 - val_accuracy: 0.5552\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8923 - accuracy: 0.5965 - val_loss: 0.9440 - val_accuracy: 0.5552\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8847 - accuracy: 0.6001 - val_loss: 0.9370 - val_accuracy: 0.5518\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8775 - accuracy: 0.6001 - val_loss: 0.9305 - val_accuracy: 0.5619\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.8708 - accuracy: 0.6001 - val_loss: 0.9246 - val_accuracy: 0.5653\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8646 - accuracy: 0.5983 - val_loss: 0.9191 - val_accuracy: 0.5597\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8589 - accuracy: 0.6001 - val_loss: 0.9142 - val_accuracy: 0.5563\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8537 - accuracy: 0.5953 - val_loss: 0.9097 - val_accuracy: 0.5586\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8491 - accuracy: 0.5995 - val_loss: 0.9057 - val_accuracy: 0.5563\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8449 - accuracy: 0.6044 - val_loss: 0.9020 - val_accuracy: 0.5653\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8411 - accuracy: 0.6080 - val_loss: 0.8988 - val_accuracy: 0.5642\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8378 - accuracy: 0.6123 - val_loss: 0.8958 - val_accuracy: 0.5631\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8348 - accuracy: 0.6104 - val_loss: 0.8932 - val_accuracy: 0.5676\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8322 - accuracy: 0.6129 - val_loss: 0.8909 - val_accuracy: 0.5687\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8298 - accuracy: 0.6110 - val_loss: 0.8888 - val_accuracy: 0.5743\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8277 - accuracy: 0.6098 - val_loss: 0.8871 - val_accuracy: 0.5777\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8258 - accuracy: 0.6110 - val_loss: 0.8855 - val_accuracy: 0.5766\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.8242 - accuracy: 0.6159 - val_loss: 0.8842 - val_accuracy: 0.5766\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8228 - accuracy: 0.6141 - val_loss: 0.8832 - val_accuracy: 0.5777\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8217 - accuracy: 0.6183 - val_loss: 0.8823 - val_accuracy: 0.5743\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.8207 - accuracy: 0.6226 - val_loss: 0.8817 - val_accuracy: 0.5800\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8199 - accuracy: 0.6232 - val_loss: 0.8812 - val_accuracy: 0.5788\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8192 - accuracy: 0.6262 - val_loss: 0.8808 - val_accuracy: 0.5788\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.8187 - accuracy: 0.6268 - val_loss: 0.8805 - val_accuracy: 0.5833\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8182 - accuracy: 0.6286 - val_loss: 0.8803 - val_accuracy: 0.5833\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.8179 - accuracy: 0.6286 - val_loss: 0.8802 - val_accuracy: 0.5867\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8176 - accuracy: 0.6256 - val_loss: 0.8801 - val_accuracy: 0.5878\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8174 - accuracy: 0.6280 - val_loss: 0.8800 - val_accuracy: 0.5856\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8172 - accuracy: 0.6305 - val_loss: 0.8800 - val_accuracy: 0.5845\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8170 - accuracy: 0.6305 - val_loss: 0.8800 - val_accuracy: 0.5890\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8168 - accuracy: 0.6317 - val_loss: 0.8801 - val_accuracy: 0.5890\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8166 - accuracy: 0.6311 - val_loss: 0.8801 - val_accuracy: 0.5878\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8165 - accuracy: 0.6341 - val_loss: 0.8802 - val_accuracy: 0.5867\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.816\n"
     ]
    }
   ],
   "source": [
    "df_city1 = df[(df.SSTADT == 1)]\n",
    "df_city2 = df[(df.SSTADT == 2)]\n",
    "df_city3 = df[(df.SSTADT == 3)]\n",
    "df_city4 = df[(df.SSTADT == 4)]\n",
    "cities = [df_city1, df_city2, df_city3, df_city4]\n",
    "\n",
    "dict_cities = {}\n",
    "\n",
    "for count, city in enumerate(cities):\n",
    "    X = city\n",
    "    Y = city['CHOICE']\n",
    "    x_mnl, x_ann, Y_cat = preprocess_ANN_data(X, Y)\n",
    "\n",
    "    # Split the data into a training and test part\n",
    "    X_mnl_train, X_mnl_test, Y_train, Y_test = train_test_split(x_mnl, Y_cat, random_state = 1, test_size = 0.35)\n",
    "    X_ann_train, X_ann_test, Y_train, Y_test = train_test_split(x_ann, Y_cat, random_state = 1, test_size = 0.35)\n",
    "    print('\\nTotal number of obervations in the data set = ', len(x_mnl))\n",
    "    print('Number of obervations in the training set   = ', len(X_mnl_train))\n",
    "    print('Number of obervations in the test set       = ', len(X_mnl_test))\n",
    "\n",
    "    # Compile the model\n",
    "    model = hybrid_RUM_MNL_ANN_model(NALT, no_X_MNL, no_X_ANN, num_nodes, seed=0)\n",
    "    model.compile(optimizer = Adam(learning_rate = 1e-2), metrics = [\"accuracy\"], loss = 'categorical_crossentropy')\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model\n",
    "    early_stopping = EarlyStopping(patience = 4, monitor = 'val_loss')\n",
    "    history = model.fit([X_mnl_train, X_ann_train],Y_train, batch_size=len(X_mnl_train), epochs = nEpoch, verbose = 1, validation_data = ([X_mnl_test, X_ann_test], Y_test), callbacks = [early_stopping])\n",
    "\n",
    "    betas_layer = model.get_layer(name = 'MNL_layer')\n",
    "    betas = betas_layer.get_weights()\n",
    "    print('The cross-entropy on the test data of the tensor flow ANN is',\"{:.3f}\".format(history.history['loss'][-1]))\n",
    "\n",
    "    dict_cities[count] = betas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([[[[-0.03817703]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.3938229 ]]]], dtype=float32)],\n",
       " 1: [array([[[[-0.03266556]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.4173497 ]]]], dtype=float32)],\n",
       " 2: [array([[[[-0.04574197]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.3808821 ]]]], dtype=float32)],\n",
       " 3: [array([[[[-0.04153115]]],\n",
       "  \n",
       "  \n",
       "         [[[-1.2065728 ]]]], dtype=float32)]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beta_STORES    =  -0.038\n",
      "Beta_FOREIGN =  -1.394\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  36.51 min per percentage point\n",
      "\n",
      "Beta_STORES    =  -0.033\n",
      "Beta_FOREIGN =  -1.417\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  43.39 min per percentage point\n",
      "\n",
      "Beta_STORES    =  -0.046\n",
      "Beta_FOREIGN =  -1.381\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  30.19 min per percentage point\n",
      "\n",
      "Beta_STORES    =  -0.042\n",
      "Beta_FOREIGN =  -1.207\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  29.05 min per percentage point\n"
     ]
    }
   ],
   "source": [
    "WTPs = {}\n",
    "for count, city in enumerate(dict_cities.values()):\n",
    "    # print(city)\n",
    "    # Show the trained taste parameters, from the MNL part\n",
    "    beta_STORES = np.squeeze((city[0][0]))\n",
    "    beta_FOREIGN = np.squeeze((city[0][1]))\n",
    "    print('\\nBeta_STORES    = ', \"{:.3f}\".format(beta_STORES )) \n",
    "    print('Beta_FOREIGN = ', \"{:.3f}\".format(beta_FOREIGN ))\n",
    "\n",
    "    # Compute the Willingness to Pay for a Gb extra storage space\n",
    "    WtP_foreign_stores_mnl = beta_FOREIGN/beta_STORES\n",
    "    print('Willingness-to-Pay estimates Hybrid model')\n",
    "    print('----------')\n",
    "\n",
    "    print('Willingness to Pay; reduction in foreigners at an expense of store distance = ', \"{:.2f}\".format(WtP_foreign_stores_mnl),'min per percentage point')\n",
    "    WTPs[count] = WtP_foreign_stores_mnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 36.509464, 1: 43.389725, 2: 30.188517, 3: 29.052237}\n"
     ]
    }
   ],
   "source": [
    "print(WTPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = list(WTPs.keys())\n",
    "values = list(WTPs.values())\n",
    "\n",
    "plt.bar(range(len(WTPs)), values, tick_label=names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for city 0: \n",
      "     B_foreign/B_stores    = 50.57419337900657, \n",
      "     B_foreign/B_green     = -4.260348025032131, \n",
      "     B_foreign/B_transport = 29.153607982693803, \n",
      "     B_foreign/B_noise     = 3.990615506609312, \n",
      "     B_foreign/B_city      = 13.497560658243543\n",
      "for city 1: \n",
      "     B_foreign/B_stores    = 91.74098895760476, \n",
      "     B_foreign/B_green     = -5.081478181204144, \n",
      "     B_foreign/B_transport = 49.267254400588506, \n",
      "     B_foreign/B_noise     = 5.524995579538264, \n",
      "     B_foreign/B_city      = 40.05729964794611\n",
      "for city 2: \n",
      "     B_foreign/B_stores    = 17.22912635616375, \n",
      "     B_foreign/B_green     = -1.3736205508144599, \n",
      "     B_foreign/B_transport = 6.3257653048298765, \n",
      "     B_foreign/B_noise     = 1.2217864343582716, \n",
      "     B_foreign/B_city      = 2.2196087923025036\n",
      "for city 3: \n",
      "     B_foreign/B_stores    = 12.706930559604633, \n",
      "     B_foreign/B_green     = -1.3352471519300053, \n",
      "     B_foreign/B_transport = 6.125015073606175, \n",
      "     B_foreign/B_noise     = 1.2340170356908373, \n",
      "     B_foreign/B_city      = 2.966866176999535\n"
     ]
    }
   ],
   "source": [
    "# Using DCM. \n",
    "Wtp_stores = np.zeros((4,1))\n",
    "Wtp_green =  np.zeros((4,1))\n",
    "Wtp_city =  np.zeros((4,1))\n",
    "Wtp_noise =  np.zeros((4,1))\n",
    "Wtp_transport =  np.zeros((4,1))\n",
    "\n",
    "for i in range(4): \n",
    "    B_stores = Beta('B_stores', 0, None, None, 0)\n",
    "    B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "    B_city = Beta('B_city', 0, None, None, 0)\n",
    "    B_noise = Beta('B_noise', 0, None, None, 0)\n",
    "    B_green = Beta('B_green', 0, None, None, 0)\n",
    "    B_foreign = Beta('B_foreign', 0, None, None, 0)\n",
    "    \n",
    "    # Create a DataFrame with pandas and database variable for Biogeme estimation\n",
    "    database = db.Database('residential_choicedata2021', cities[i])\n",
    "    # The following statement allows you to use the names of the variable stored in Biogeme as Python variables.\n",
    "    globals().update(database.variables)\n",
    "\n",
    "    # Utility functions\n",
    "    V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "    V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "    V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3\n",
    "    # Associate utility functions with the numbering of alternatives in df.CHOICE\n",
    "    V = {1: V1, 2: V2, 3: V3}\n",
    "\n",
    "    # Associate the availability conditions with the alternatives\n",
    "    av = {1:1, 2:1, 3:1}\n",
    "    # Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "    prob = models.loglogit(V, av, CHOICE)\n",
    "\n",
    "    # Create the Biogeme object\n",
    "    biogeme = bio.BIOGEME(database, prob)\n",
    "    biogeme.modelName = 'My first discrete choice model'\n",
    "    biogeme.generatePickle = False\n",
    "    biogeme.generateHtml = False\n",
    "\n",
    "    # Calculate the null log likelihood for reporting.\n",
    "    biogeme.calculateNullLoglikelihood(av)\n",
    "    # Estimate the parameters\n",
    "    results1 = biogeme.estimate()\n",
    "    # Report the results in a pandas table\n",
    "    betas1 = results1.getBetaValues()\n",
    "    # different relationships \n",
    "    Wtp_stores[i] = betas1['B_foreign']/betas1['B_stores']\n",
    "    Wtp_green[i] = betas1['B_foreign']/betas1['B_green']\n",
    "    Wtp_transport[i] = betas1['B_foreign']/betas1['B_transport']\n",
    "    Wtp_noise[i] = betas1['B_foreign']/betas1['B_noise']\n",
    "    Wtp_city[i] = betas1['B_foreign']/betas1['B_city']\n",
    "    print('for city {}: \\n \\\n",
    "    B_foreign/B_stores    = {}, \\n \\\n",
    "    B_foreign/B_green     = {}, \\n \\\n",
    "    B_foreign/B_transport = {}, \\n \\\n",
    "    B_foreign/B_noise     = {}, \\n \\\n",
    "    B_foreign/B_city      = {}'.format(i, Wtp_stores[i][0], Wtp_green[i][0], Wtp_transport[i][0], Wtp_noise[i][0], Wtp_city[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Willingness to pay for one percent point less of foreigners\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create barplot for each Wtp. \n",
    "colors = ['b', 'r', 'g', 'orange']\n",
    "labels = ['city 0', 'city 1', 'city 2', 'city 3']\n",
    "\n",
    "print('Willingness to pay for one percent point less of foreigners')\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(3,2,1)\n",
    "plt.bar(range(len(cities)), Wtp_city[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP distance to city [km/percentage point]')\n",
    "plt.subplot(3,2,2)\n",
    "plt.bar(range(len(cities)), Wtp_transport[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP distance to public transport [min walking/percentage point]')\n",
    "plt.subplot(3,2,3)\n",
    "plt.bar(range(len(cities)), Wtp_stores[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP distance to stores [min walking/percentage point')\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "plt.bar(range(len(cities)), Wtp_green[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP percentage of green areas [green area level/percentage point]')\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "plt.bar(range(len(cities)), Wtp_noise[:,0], color=colors, tick_label=labels)\n",
    "plt.title('WtP noise level [noise level/percentage point]')\n",
    "plt.subplots_adjust(hspace=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q6** <br>\n",
    "For the hybrid model we can only get two beta-values out each time. Therefore it is hard to say whether a city is xenophobic when comparing only the wtp for the share of foreigners compared to the walking distance to the stores. As the output might also be interpretable as people really don't mind how far away from the store they live. <br>\n",
    "Using the DCM we can compare the wtp of the share of foreigners to all the other beta values to get a more complete picture of what people want. \n",
    "\n",
    "<br> From the barplots of the DCM model we can conclude that city 1 is the most xenophobic city, as they are willing to give in on all other aspects for a smaller percentage of foreigners in their city. After that city 0 is most xenophobic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cab132ea358786bca809bd44131ddd0564f8abae658fe95d8fa3ee53812826fd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('myenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
