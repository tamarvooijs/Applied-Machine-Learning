{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4305TU: Week 6 - Artificial Neural Network - Assignment\n",
    "## Investigating neighbourhood choice behaviour using ANNs\n",
    "**7 & 11 October 2021**\n",
    "\n",
    "- Sander van Cranenburgh\n",
    "- Francisco Garrido-Valenzuela "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information\n",
    "\n",
    "* For this assignment we will use *Stated Choice data* on residential location choice, collected in:\n",
    "    - Mainz, Germany\n",
    "    - Hanover, Germany\n",
    "    - Bern, Switzerland\n",
    "    - Zurich, Switzerland \n",
    "\n",
    "- For more details on the data, see the description provided on [Brightspace](https://brightspace.tudelft.nl/d2l/le/content/399675/viewContent/2506146/View). \n",
    "\n",
    "- In total you can earn **6.0** points in this assignment. \n",
    "\n",
    "- Add **Code cells** to complement your analyses. You can draw a lot form the snippets of codes we used for the in-class exercises.\n",
    "\n",
    "### Submission instructions\n",
    "\n",
    "- Answer the questions (code and/or text) in this notebook\n",
    "- Rename this file by adding your group nomber (e.g. Assignment_groupXX.ipynb)\n",
    "- Submit your answers both in ipynb and html format\n",
    "\n",
    "**Provide your answers in the allocated markdown boxes** (with the red font color)\n",
    "\n",
    "\n",
    "### Set up your environment\n",
    "\n",
    "You need to set up your environment based on which platform you would like to use. In this case we offer two options:\n",
    "\n",
    "- Google Colaboratory (Colab)\n",
    "- Jupyter Lab or Notebooks (Local)\n",
    "\n",
    "#### Using Colab\n",
    "\n",
    "Students using **Colab**, just need to install **Biogeme**. Biogeme is a Python package designed for the maximum likelihood estimation of parametric models in general, with a special emphasis on discrete choice models. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using Google Colab (keep the exclamation mark)\n",
    "#!pip install biogeme\n",
    "#!git clone https://github.com/cs4305tu/assignment\n",
    "#root = 'assignment/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using local environment\n",
    "\n",
    "Students using their *local environments*, need to install all the dependencies used in this *Week 6*, to ensure compatibility, they also need to check the versions of each dependency. All dependencies are contained in the text file: **requirements.txt**. Just run the following notebook cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you are using your local environment (keep the exclamation mark)\n",
    "# !pip3 install -r requirements.txt\n",
    "# root = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Python packages\n",
    "\n",
    "In the following cell add all the packages you need to finish this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow  2.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from heatmap import corrplot\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.database as db\n",
    "import biogeme.optimization as opt\n",
    "import biogeme.messaging as msg\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Using tensorflow \",tf.__version__)\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import ML packaged and modules\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ID2</th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>STORES2</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>...</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>SSTADT</th>\n",
       "      <th>RESPCITY</th>\n",
       "      <th>WOMAN</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ENVCONC</th>\n",
       "      <th>COMPLETE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  ID2  STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  STORES2  \\\n",
       "0   2    5       10           5      1       2       2       0.4       15   \n",
       "1   2    6       15           5      4       4       1       0.1        2   \n",
       "2   2    7       10          15      1       3       1       0.4       15   \n",
       "3   2    8       15          15      5       4       4       0.4        2   \n",
       "4   3    9       15           5      5       1       3       0.4        2   \n",
       "\n",
       "   TRANSPORT2  ...  NOISE3  GREEN3  FOREIGN3  CHOICE  SSTADT  RESPCITY  WOMAN  \\\n",
       "0          10  ...       4       4       0.2       1       3         3      0   \n",
       "1          10  ...       2       3       0.3       2       3         3      0   \n",
       "2           2  ...       1       3       0.2       3       3         3      0   \n",
       "3           2  ...       2       2       0.2       2       3         3      0   \n",
       "4          10  ...       3       1       0.2       2       2         2      1   \n",
       "\n",
       "   AGE  ENVCONC  COMPLETE  \n",
       "0   42      3.0         1  \n",
       "1   42      3.0         1  \n",
       "2   42      3.0         1  \n",
       "3   42      3.0         1  \n",
       "4   41      4.5         1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a dataframe\n",
    "root = ''\n",
    "df = pd.read_csv(f'{root}datasets/neighbourhood_choice2018.dat', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Do a proper descriptive analysis of the data set (1.0 pt)\n",
    "\n",
    "It is good practice to do a descriptive analysis of the data you want to model, prior to the real modelling. So inspect e.g. what levels the attributes (features) take, correlations, class (im)balances, redudant variables, missing values, etc. to attain a good feeling for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The choice features are: ['STORES', 'TRANSPORT', 'CITY', 'NOISE', 'GREEN', 'FOREIGN']\n",
      "Other available features are: ['WOMAN', 'AGE', 'SSTADT', 'RESPCITY', 'ENVCONC']\n",
      "The evaluation metric is ['CHOICE']\n",
      "\n",
      "Total number of Nan values: 0\n",
      "Total number of empty (None) values: 0\n",
      "Total number of incomplete responses: 0\n",
      "\n",
      "Check the levels that each feature can take:\n",
      "Choice features:\n",
      "\tSTORES can take: [ 2  5 10 15]\n",
      "\tTRANSPORT can take: [ 2  5 10 15]\n",
      "\tCITY can take: [1 2 4 5]\n",
      "\tNOISE can take: [1 2 3 4]\n",
      "\tGREEN can take: [1 2 3 4]\n",
      "\tFOREIGN can take: [0.1 0.2 0.3 0.4]\n",
      "Other features\n",
      "\tWOMAN can take: [    0     1 99999]\n",
      "\tAGE can take: [   18    19    20    21    22    23    24    25    26    27    28    29\n",
      "    30    31    32    33    34    35    36    37    38    39    40    41\n",
      "    42    43    44    45    46    47    48    49    50    51    52    53\n",
      "    54    55    56    57    58    59    60    61    62    63    64    65\n",
      "    66    67    68    69    70 99999]\n",
      "\tSSTADT can take: [1 2 3 4]\n",
      "\tRESPCITY can take: [1 2 3 4]\n",
      "\tENVCONC can take: [1.00000000e+00 1.16666663e+00 1.33333337e+00 1.50000000e+00\n",
      " 1.66666663e+00 1.83333337e+00 2.00000000e+00 2.16666675e+00\n",
      " 2.33333325e+00 2.50000000e+00 2.66666675e+00 2.83333325e+00\n",
      " 3.00000000e+00 3.16666675e+00 3.33333325e+00 3.50000000e+00\n",
      " 3.66666675e+00 3.75000000e+00 3.83333325e+00 4.00000000e+00\n",
      " 4.16666651e+00 4.33333349e+00 4.50000000e+00 4.66666651e+00\n",
      " 4.75000000e+00 4.83333349e+00 5.00000000e+00 9.99990000e+04]\n",
      "\n",
      "Total number of 99999 values in AGE: 64\n",
      "nTotal number of 99999 values in WOMAN: 20\n",
      "nTotal number of 9.99990000e+04 values in ENVCONC: 188\n"
     ]
    }
   ],
   "source": [
    "# All features in dataset, devided into the choice feature, and additional feaures.\n",
    "features_choices = ['STORES', 'TRANSPORT', 'CITY', 'NOISE', 'GREEN', 'FOREIGN']\n",
    "features_other = ['WOMAN', 'AGE', 'SSTADT', 'RESPCITY', 'ENVCONC']\n",
    "print(f'The choice features are: {features_choices}')\n",
    "print(f'Other available features are: {features_other}')\n",
    "print(f\"The evaluation metric is ['CHOICE']\")\n",
    "\n",
    "\n",
    "# Check for Nan values in dataset\n",
    "print(f'\\nTotal number of Nan values: {df.isna().sum().sum()}')\n",
    "# Check for empty (None) values in dataset\n",
    "print(f'Total number of empty (None) values: {int(df[df==None].sum().sum())}')\n",
    "# Check for complete responses\n",
    "print(f'Total number of incomplete responses: {df.COMPLETE[df.COMPLETE==0].sum()}')\n",
    "\n",
    "# Check the various levels that each feature can take\n",
    "print('\\nCheck the levels that each feature can take:')\n",
    "print('Choice features:')\n",
    "for feature in features_choices:\n",
    "    feature_choice = [feature+str(choice) for choice in range(1, 4)]\n",
    "    levels = np.unique(df[feature_choice].to_numpy().flatten())\n",
    "    print(f\"\\t{feature} can take: {levels}\")\n",
    "print('Other features')\n",
    "for feature in features_other:\n",
    "    levels = np.unique(df[feature].to_numpy().flatten())\n",
    "    print(f\"\\t{feature} can take: {levels}\")\n",
    "\n",
    "# Check for faulty values\n",
    "print(f'\\nTotal number of 99999 values in AGE: {df.AGE[df.AGE==99999].size}')\n",
    "print(f'nTotal number of 99999 values in WOMAN: {df.WOMAN[df.WOMAN==99999].size}')\n",
    "print(f'nTotal number of 9.99990000e+04 values in ENVCONC: {df.ENVCONC[df.ENVCONC==9.99990000e+04].size}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of choices: 9720\n",
      "--------------------------------\n",
      "\t Number of choices equal to 1: 3440 --> 35.39% of total\n",
      "\t Number of choices equal to 2: 3266 --> 33.6% of total\n",
      "\t Number of choices equal to 3: 3014 --> 31.01% of total\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEyCAYAAACWKPW+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAxOAAAMTgF/d4wjAAAnp0lEQVR4nO3df1RUdf4/8OflhxLBAA4/dRgQx2FLBARJlo8/1/zZphR6KtcEkwUz11w8G7bWauZSHmnKtm11q6U1zhIm5rah5o8ocqMSFH9tCmQ0g4oQLshPheH9/cOvd8MAB2QYvD0f58w5c+/rvue+Lozz5M693isJIQSIiIgUws7WDRAREfUlBhsRESkKg42IiBSFwUZERIrCYCMiIkVhsBERkaIw2IiISFEYbGRz5eXlkCQJZWVltm4FALB//34EBwfD1dUVqampPR4/efJkPPPMM7fUg4uLCz755JNbeo3bXUJCAhYuXGjrNnpk1qxZeP75523dxk8eg40AXPswliQJ//rXvzrMX7hwIRISEmzTlI0sX74ciYmJqK+vx8aNG23SQ0NDAyZPnmyTdQ9UgYGBePPNN23dBoCu/xjbs2cPnn32WRt1Rdcx2Ejm6emJVatW4erVq7Zu5ZbdyjZ88803GDNmTB9289M2kN5PZrMZ7e3ttm6DrIzBRrKEhAS0t7fj1Vdf7XKZzv5qliQJBw4cAAB88sknkCQJ2dnZ0Ov1cHZ2xv3334/a2lo8++yz8PPzg6enJ9auXfuj187Ly8Pdd98NlUqFqVOn4ptvvpFrZrMZL730Eu666y64ubkhMjISBw8elOtvv/02NBoN/vznPyMwMBBqtbrT/s1mMzZt2gS9Xg83NzeMHTsWe/bsAQCUlJTAxcUFZrMZ999/P1xcXPDZZ591+jpff/015syZA19fX7i5uSE6Ohomk0mu19fXY8GCBXBzc4O/vz/+8pe/dBifm5uLyMhIuLm5Qa/XIz09vcMH7g9/pgBQUFCAX/ziF/D09MSQIUMwZcoUNDc3AwBqa2vx+OOPIyAgAGq1GrNnz8bZs2flsdu3b8eoUaOgUqng6emJe++9t9NtAoB169Zh/PjxePrpp+Ht7Q1fX1/87ne/Q2trq7zMuXPnsGDBAgwbNgze3t545JFHUF1dLdcnT56M5cuX4+GHH4aHhwdWrFjR6br+8Ic/QK/Xw9XVFf7+/vjNb36DpqamTpedNWsWjEYjli9fDhcXF4waNUqubdu2DWFhYXBzc8OoUaPw7rvvyrXr78d3331Xfj9WVVUhMDAQ69evx+zZs+Hq6ooRI0bg/fffl8edPHkSU6dOhZeXF9zc3DBu3Dh8/PHHcv36+sPCwuDi4oKlS5fK2379a+gFCxZgyZIlHbbjyJEjGDRoEC5evAgAOH36NH75y1/Cx8cHw4YNw7Jly9DY2Njl74csJIiEEJMmTRJr1qwR77//vlCpVOLixYtCCCF+9atfifj4eHm5gIAA8cYbb3QYC0Ds379fCCFEXl6eACAeffRRcfnyZXHx4kUxcuRIodfrxZ/+9CfR2toqCgoKhL29vfj888+FEEJ8++23AoCIiooSRqNRNDY2iiVLloi77rpLtLa2CiGEWLt2rQgLCxOnT58WZrNZ7Ny5Uzg7O4uysjIhhBAZGRnC3t5e/PrXvxb19fWisbGx0+1MT08Xw4YNE0VFRaK1tVVkZWUJR0dHUVRU1On2dKayslKo1Wrx9NNPi7q6OtHW1ia++uorUV1dLf8sVSqVOHjwoDCbzWLHjh3Czs5OlJaWCiGE+Oqrr4Sjo6PIzs4Wra2torCwUPj5+YmXX3650x5OnjwpnJycxGuvvSYaGxvFlStXRF5enmhpaRHt7e1i8uTJYsGCBaKmpka0tLSIp556Stx1113i6tWrorGxUTg6OoqDBw8KIYRobm6Wn3dm7dq1wsHBQTzzzDOipaVFfP3112L48OFiw4YNQgghWlpaRHBwsFi1apVoaGgQ9fX1YuHCheLee++VX2PSpEnC2dlZ5ObmCrPZ3OXvYtu2beK7774T7e3t4uTJk2LEiBFi9erVcj0+Pl786le/kqc7e+9lZGQIf39/cfjwYWE2m8Vnn30mXF1dxWeffSaE+N/7MTY2Vnz//feipaVFtLW1iYCAAOHv7y+KioqE2WwWL730knB1dRV1dXVCCCFOnDgh9u3bJ5qamkRLS4tYu3Zth38X19+z13+nP9z2NWvWCCGEOHjwoHBxcRH19fVyfenSpeKBBx4QQghRXV0tPD09hcFgEC0tLaK6ulpMnTpVJCYmdvn7Icsw2EgI0fEf5C9+8QuxZMkSIUTvg81oNMr1lStXCr1e32FMSEiIeOWVV4QQ//uQ+OCDD+T65cuXhb29vcjPzxdCCKFSqcTevXs7vMa9994rnn/+eSHE/4Ktqw/R6/R6vbze6+bMmSOSk5M73Z7ObNq0SYwaNarL+qRJk8TixYs7zPP09BTvvvuuEEKIpKQkERsb26FuMBhEcHBwpz088cQT4r777ut0XUVFRcLR0bHDh2dbW5twcnISn332mWhsbBTOzs7itddek4O3O2vXrhXe3t6ira1Nnvf666+LoKAgIYQQOTk5YujQoaK9vV2uV1RUCADCZDLJ2//www/fdF03MhgMIiIiQp62JNhGjx4ttmzZ0mFeYmKi/P69/n48ffp0h2UCAgLEc889J083NDQIAOKLL77osj83Nzf5PWpJsLW3t4sRI0bIPTc2Ngo3NzeRm5srhBDipZdeEtHR0R3GHzp0SAwaNKjDz596jl9F0o9s3rwZ77zzDo4ePdrr1/Dz85Of33nnnR2mr8+rr6/vMG/48OHyc1dXV3h6esJkMuHixYu4fPky5s+fD3d3d/nx+eef49y5c/IYb29vODs7d9uXyWTCiBEjOszT6XQwGo0Wb9u3336L4ODgbpcZOnRoh+kfbm9Pe+hufaWlpWhra4NGo5F/Lte/hjWZTHB2dsbevXtx4MABBAcHY/To0di8eXO3vfv7+8Pe3l6eHj58uPw1a2lpKS5evAgPDw95faNGjcLgwYM79P/D32VXtm7dioiICKjVari5uWHNmjWoqqq66bgbt3/VqlUd3hdZWVk4f/58h+U66+eHv6M777wTAOTfkdFoxMMPPwytVguVSgV3d3dcvny5R/1JkoTHHnsMb731FgDgvffeg6urK2bOnCn3XlRU1KH32bNnQ5IkVFZW9ujnQB052LoBGnhCQkKQmJiIJ598ElqttkPN1dW1wzGAGz9AbkV5eTlCQkIAXDsr8Pvvv5c/sJ2cnPDhhx9i4sSJXY63s7v532n+/v4djt0B104WuXE7uxMYGNjlsTdL9LSHwMBAlJSUdFrz9fXFoEGDUF1dDUdHx06XmTBhAiZMmAAhBD799FPMnDkTd999N6ZNm9bp8iaTCWazWQ638vJyaDQaeX0BAQE/6v9GN/tdFBQUYPny5di3bx/Gjx8PR0dHvPzyy3jppZd69Jq+vr547rnnsGjRolvq50a//vWv4ebmhsOHD8PHxwdCCHh4eED8/7t8Wfp6CQkJWLt2LU6dOoU333wTixcvlsf6+vpi/PjxHY7dUd/gHht1av369Th58iQ++uijDvPHjh2LrKws1NbW4vLly1i9enWfrXPDhg2oqKhAU1MTVq1aBZ1Oh5iYGAwePBhLly7FU089ha+//hpCCDQ3NyM/P7/LD/yuJCYmIj09HcXFxWhra8P27duxe/duJCYmWvwaixYtQkVFBZ599lnU19fDbDajsLAQ33//vUXjH3vsMeTm5iInJwdmsxlHjx7Fpk2bkJSU1Onyjz/+OPbv348tW7agubkZra2t+PTTT3HlyhWMHz8eISEhePzxx+W9if/+97/IyclBU1MTKisr8d5776G2thaSJMHd3R2SJMHBoeu/aS9duoT169fjypUrOHPmDDZt2oTFixcDAB588EG0trbi2WefRV1dHQCgqqoK2dnZFv/8AKCurg729vbw8vKCo6Mjjhw5gtdee63bMb6+vjhz5kyHeStXrsTzzz+Pw4cPo729HVeuXMHhw4dRVFTUo34668/FxQUeHh5obGzE008/jYaGBrnu5eUFOzu7H/Vzo6FDh2LWrFlITU3F559/jscee0yuLV68GEePHsXrr7+OpqYmCCFgMpmwa9euW+qdGGzUBbVajXXr1v3ow3rDhg1QqVTw9/dHZGQkHnjggT5b55IlSzBt2jT4+PigpKQE//rXv+QP4PT0dDzyyCPy15GBgYF44YUXOpytZ4mUlBQ88cQTmDdvHoYMGYKNGzdi586dGDt2rMWv4ePjg/z8fBQVFWH48OFQq9X4zW9+g5aWFovGjxs3Djt27MAf//hHeHh4YP78+VixYgWefPLJTpcPCQnBgQMHkJWVhaFDh8LHxwfr169He3s77O3tsX//fjg7O2PcuHFwdXVFWFgY3n//fUiSBCEEtmzZgqCgILi4uGDevHn44x//iClTpnTb39WrV6HRaDBx4kTExsbKf8C4urqioKAARqMRo0ePhkqlQkxMDPLz8y3++QHA9OnTsXTpUkyePBlubm74/e9/j/j4+G7H/OEPf8A///lPuLu7IzQ0FADw5JNPYt26dVi6dCmGDBmCYcOG4Xe/+90tn1n46quv4tixY/Dw8MDdd9+NYcOGyXutAHDHHXcgLS0NiYmJcHd3x7Jly7p8rcTEROTm5mLq1KkIDAyU52u1WhQUFGD//v0YMWIE3N3dMWPGDJw4ceKWeidAEoJ30Caia9atW4cDBw7g0KFDtm6FqNe4x0ZERIrCYCMiIkXhV5FERKQo3GMjIiJFYbAREZGi/GT+g/bgwYPh5eVl6zaIiOgWVVdX48qVK13WfzLB5uXlhYqKClu3QUREt+iH/6ewM/wqkoiIFIXBRkREimL1YJs+fTpCQ0MRHh6OCRMmyFeMDwwMRHBwMMLDwxEeHt7hWnOlpaWIiYmBXq9HVFQUTp06ZVGNiIjI6vdj++9//ys/37lzpwgNDRVCXLsf0tGjRzsdM2XKFJGRkSGEEOK9994TY8eOtajWnWHDhvW4dyIiGnhu9nlu9T02d3d3+XldXR0kSep2+aqqKhQWFmLhwoUAgLi4OJhMJpSVlXVbIyIiAvrprMhFixYhLy8PALB79+4O84UQuOeee/Diiy/Cy8sLJpMJfn5+8lXdJUmCVquF0WiEm5tblzWdTtcfm0JERANcv5w8sm3bNphMJmzYsAGpqakAgPz8fBw/fhxHjhyBp6fnTW9Z0VMGgwEajUZ+/PBeSkREpFz9fq3IO+64AxUVFfLt6wHgwoUL0Ov1qK+vR1VVFXQ6HS5dugQHBwcIIeDn54dDhw5BpVJ1WbvZHptGo+H/YyMiUoCbfZ5bdY+ttrYW58+fl6d37doFtVoNJycn1NbWyvOzsrIwZswYAIC3tzciIiKQmZkJAMjJyYFGo4FOp+u2RkREBFh5j+27777D/Pnz0dzcDDs7O3h5eSE9PR0qlQpxcXEwm80QQiAoKAibN2+W7y575swZJCQkoKamBiqVChkZGRg9evRNa93hHhsRkTLc7PP8J3Pbmr4ItsDVuX3UjTKUv3ifrVsgop8gm34VSURE1N8YbEREpCgMNiIiUhQGGxERKQqDjYiIFIXBRkREisJgIyIiRWGwERGRojDYiIhIURhsRESkKP1yPzainwJecu1/eLk1siXusRERkaIw2IiISFEYbEREpCgMNiIiUhQGGxERKQqDjYiIFIXBRkREisJgIyIiRWGwERGRojDYiIhIURhsRESkKAw2IiJSFAYbEREpCoONiIgUxerBNn36dISGhiI8PBwTJkzA0aNHAQClpaWIiYmBXq9HVFQUTp06JY/pbY2IiMjqwbZ9+3YcP34cxcXFSElJQUJCAgAgOTkZSUlJKCkpQWpqqjz/VmpERERWv9Gou7u7/Lyurg6SJKGqqgqFhYXYt28fACAuLg7Lly9HWVkZVCpVr2o6nc7am0JE1Cu8Ce3/9MdNaPvlDtqLFi1CXl4eAGD37t0wmUzw8/ODg8O11UuSBK1WC6PRCDc3t17Vbgw2g8EAg8EgTzc0NPTHphIRkY31y8kj27Ztg8lkwoYNG5Camtofq0RKSgoqKirkh4uLS7+sl4iIbKtfz4qMj49HXl4eNBoNLly4gLa2NgCAEAJGoxFarRb+/v69qhEREQFWDrba2lqcP39ent61axfUajW8vb0RERGBzMxMAEBOTg40Gg10Ol2va0RERICVj7HV1dVh/vz5aG5uhp2dHby8vPDhhx9CkiRs3boVCQkJSEtLg0qlQkZGhjyutzUiIiKrBltAQAC++uqrTmvBwcEoKCjo0xoRERGvPEJERIrCYCMiIkVhsBERkaIw2IiISFEYbEREpCgMNiIiUhQGGxERKQqDjYiIFIXBRkREisJgIyIiRWGwERGRojDYiIhIURhsRESkKAw2IiJSFAYbEREpCoONiIgUhcFGRESKwmAjIiJFYbAREZGiMNiIiEhRGGxERKQoDDYiIlIUBhsRESkKg42IiBTFqsHW0tKC2NhY6PV6hIWFYdq0aSgrKwMATJ48GcOHD0d4eDjCw8Px8ssvy+Oqqqowc+ZMjBw5EiEhIcjPz7eoRkRE5GDtFSQlJWHWrFmQJAmvvfYaEhMT8cknnwAAXn75ZcTGxv5ozOrVqxEdHY29e/fi8OHDeOCBB/Dtt9/C0dGx2xoREZFV99icnJwwe/ZsSJIEAIiOjkZ5eflNx23fvh1Lly4FAERFRWHo0KH49NNPb1ojIiLq12Nsmzdvxty5c+Xp1atXY/To0XjooYdw9uxZAEBNTQ1aW1vh6+srLxcYGAij0dhtjYiICOjHYEtLS0NZWRleeOEFAMA777yD06dP4/jx45gwYQJ++ctf9un6DAYDNBqN/GhoaOjT1yciooGpX4ItPT0dO3fuxJ49e+Ds7AwA8Pf3BwBIkoTly5fj7NmzqKmpgVqthoODAyorK+Xx5eXl0Gq13dZulJKSgoqKCvnh4uJi5a0kIqKBwOrBZjAYkJWVhf3798Pd3R0A0NbWhosXL8rL5OTkwMfHB2q1GgAwf/58bNmyBQBw+PBhnDt3DpMmTbppjYiIyKpnRVZUVGDVqlUICgrClClTAACDBw/Gxx9/jPvuuw9XrlyBnZ0dPD098cEHH8jjNm7ciEcffRQjR47EoEGDkJmZKZ/12F2NiIjIqsGm0WgghOi0VlhY2OU4Hx8f7Nu3r8c1IiIiXnmEiIgUhcFGRESKwmAjIiJFYbAREZGiMNiIiEhRGGxERKQoDDYiIlIUBhsRESkKg42IiBSFwUZERIrCYCMiIkVhsBERkaIw2IiISFEYbEREpCgMNiIiUhSLg+2jjz6yZh9ERER9wuJgW79+PYKDg7F582ZcvnzZmj0RERH1msXB9u9//xvvvvsuTp48Cb1ej2XLluE///mPNXsjIiLqsR4dYxszZgzeeOMN7N27Fx9++CFCQ0Mxbdo0nDhxwlr9ERER9UiPgu3AgQOYO3cuHnzwQTzxxBOorKxEcnIyHnjgAWv1R0RE1CMOli541113wdPTEytWrMCDDz4Ie3t7AMC8efPw1ltvWa1BIiKinrA42DIzMxEZGdlpbc+ePX3WEBER0a2w+KvIoqIiXLp0SZ6uqanBG2+8YZWmiIiIesviYHv99dcxZMgQeVqtVuP111+3SlNERES9ZXGwCSF+NM9sNnc7pqWlBbGxsdDr9QgLC8O0adNQVlYGAKiqqsLMmTMxcuRIhISEID8/Xx7X2xoREZHFwebn54ft27fL09nZ2fDz87vpuKSkJJw5cwbHjh3D3LlzkZiYCABYvXo1oqOjUVpaioyMDCxYsACtra23VCMiIrL45JFXXnkFc+fOxVNPPQUAcHZ2xj//+c9uxzg5OWH27NnydHR0NNLT0wEA27dvl/feoqKiMHToUHz66ae49957e10jIiKyONh+9rOf4T//+Q/OnDkDAAgODpZP+bfU5s2bMXfuXNTU1KC1tRW+vr5yLTAwEEajsdc1IiIioAfBBgCSJMHd3R1tbW04d+4cAECr1Vo0Ni0tDWVlZTh48CCam5t73mkPGQwGGAwGebqhocHq6yQiItuz+Bjb22+/DXd3d4wePRqRkZGIjIzE2LFjLRqbnp6OnTt3Ys+ePXB2doZarYaDgwMqKyvlZcrLy6HVantdu1FKSgoqKirkh4uLi6WbSkREtzGLg+3555/H4cOHUVNTg+rqalRXV6Oqquqm4wwGA7KysrB//364u7vL8+fPn48tW7YAAA4fPoxz585h0qRJt1QjIiKy+KtIT09PBAcH9+jFKyoqsGrVKgQFBWHKlCkAgMGDB+PLL7/Exo0b8eijj2LkyJEYNGgQMjMz4ejoCAC9rhEREVkcbLGxsXjllVewYMECODk5yfNVKlWXYzQaTaf//w0AfHx8sG/fvj6tERERWRxsa9asAXDt2JUkSRBCQJKkm/4nbSIiov5kcbC1t7dbsw8iIqI+0aP7sRUVFeGdd94BANTW1uLChQtWaYqIiKi3enQR5Mceewzr1q0DcO3q/gsWLLBWX0RERL1icbD99a9/xRdffCGfLDJixAhUV1dbrTEiIqLesDjYBg8ejDvuuKPDPAeHHl24hIiIyOosDjYvLy+UlJRAkiQA165EYunltIiIiPpLj67u/8gjj+D06dPw9/eHSqXChx9+aM3eiIiIesziYNPpdPjyyy9x5swZCCF6dXV/IiIia7M42K7fGubOO+8EgB5f3Z+IiKg/WBxskZGR8hVHWlpa0NTUBLVabdGFkImIiPqLxcF246n9O3fuxLFjx/q8ISIiolvRoyuP/NCDDz6I3NzcvuyFiIjollm8x3b58mX5udlsxpdfftlhHhER0UBgcbC5u7vLx9js7e0xcuRIvPrqq9bsjYiIqMd4dX8iIlKUXh9jIyIiGogs3mOzs7OTL6f1Q7zhKBERDSQWB9v69evR3NyMxx9/HACwZcsW3HHHHVi5cqW1eiMiIuoxi4Pt/fffR1FRkTy9YcMGREZGYs2aNVZpjIiIqDcsPsZWX1/f4SojVVVVqK+vt0pTREREvWXxHtuqVasQFhaG2bNnAwD27t0r302biIhooLA42JKTk/F///d/yMvLAwCkpKRg1KhRVmuMiIioN3p0C2y1Wo3Ro0dj8uTJaGtrw9WrVzFo0CBr9UZERNRjFh9j27FjB6Kjo7F48WIAwKlTpxAbG2utvoiIiHrF4mB74YUXcOTIEbi7uwMAwsLC8N1339103IoVKxAYGAhJklBcXCzPDwwMRHBwMMLDwxEeHo7s7Gy5VlpaipiYGOj1ekRFReHUqVMW1YiIiCwONnt7e6jV6g7zLPkact68eTh06BACAgJ+VMvOzkZxcTGKi4vx0EMPyfOTk5ORlJSEkpISpKamIiEhwaIaERGRxcHm6uqKixcvylcfOXjwIIYMGXLTcRMnToRGo7G4oaqqKhQWFmLhwoUAgLi4OJhMJpSVlXVbIyIiAnpw8sjGjRsxa9YsnD17FuPHj8e33357y/djW7RoEYQQuOeee/Diiy/Cy8sLJpMJfn5+cHC41pokSdBqtTAajXBzc+uyptPpOry2wWCAwWCQpxsaGm6pVyIiuj1YFGzt7e0wm83Iy8vD559/DiEEYmJi5ONtvZGfnw+tVovW1lY888wziI+Px+7du3v9ejdKSUlBSkqKPN2TvUYiIrp9WRRsdnZ2SEpKwrFjxzBr1qw+WbFWqwUAODo6YuXKldDr9QAAf39/XLhwAW1tbXBwcIAQAkajEVqtFiqVqssaERER0INjbCNHjuyzY1mNjY2ora2Vp7OysjBmzBgAgLe3NyIiIpCZmQkAyMnJgUajgU6n67ZGREQE9OAY26VLlxAeHo6YmBi4uLjI83fu3NntuOTkZOTm5qKyshIzZsyAq6sr9u3bh7i4OJjNZgghEBQUhG3btsljtm7dioSEBKSlpUGlUiEjI8OiGhER0U2DLSkpCX/9618RHx+POXPmwMPDo0cr2Lp1a6fzjx492uWY4OBgFBQU9LhGRER002ArLCwEAMTHxyMiIgJHjhyxelNERES9ZfExNuDa3bKJiIgGspvusTU3N+PEiRMQQqClpUV+fl1oaKhVGyQiIuoJi4Jtzpw58vQPn0uShLNnz1qnMyIiol64abCVl5f3QxtERER9o0fH2IiIiAY6BhsRESkKg42IiBSFwUZERIrCYCMiIkVhsBERkaIw2IiISFEYbEREpCgMNiIiUhQGGxERKQqDjYiIFIXBRkREisJgIyIiRWGwERGRojDYiIhIURhsRESkKAw2IiJSFAYbEREpCoONiIgUxerBtmLFCgQGBkKSJBQXF8vzS0tLERMTA71ej6ioKJw6deqWa0RERFYPtnnz5uHQoUMICAjoMD85ORlJSUkoKSlBamoqEhISbrlGRERk9WCbOHEiNBpNh3lVVVUoLCzEwoULAQBxcXEwmUwoKyvrdY2IiAiw0TE2k8kEPz8/ODg4AAAkSYJWq4XRaOx1jYiICFDwySMGgwEajUZ+NDQ02LolIiLqBzYJNn9/f1y4cAFtbW0AACEEjEYjtFptr2s3SklJQUVFhfxwcXHpvw0kIiKbsUmweXt7IyIiApmZmQCAnJwcaDQa6HS6XteIiIgAwMHaK0hOTkZubi4qKysxY8YMuLq6oqysDFu3bkVCQgLS0tKgUqmQkZEhj+ltjYiIyOrBtnXr1k7nBwcHo6CgoE9rREREij15hIiIfpoYbEREpCgMNiIiUhQGGxERKQqDjYiIFIXBRkREisJgIyIiRWGwERGRojDYiIhIURhsRESkKAw2IiJSFAYbEREpCoONiIgUhcFGRESKwmAjIiJFYbAREZGiMNiIiEhRGGxERKQoDDYiIlIUBhsRESkKg42IiBSFwUZERIrCYCMiIkVhsBERkaIw2IiISFFsGmyBgYEIDg5GeHg4wsPDkZ2dDQAoLS1FTEwM9Ho9oqKicOrUKXlMdzUiIiKb77FlZ2ejuLgYxcXFeOihhwAAycnJSEpKQklJCVJTU5GQkCAv312NiIjI5sF2o6qqKhQWFmLhwoUAgLi4OJhMJpSVlXVbIyIiAgZAsC1atAijR4/GkiVLUF1dDZPJBD8/Pzg4OAAAJEmCVquF0WjstnYjg8EAjUYjPxoaGvp1u4iIyDZsGmz5+fk4fvw4jhw5Ak9PT8THx/fZa6ekpKCiokJ+uLi49NlrExHRwOVgy5VrtVoAgKOjI1auXAm9Xg9/f39cuHABbW1tcHBwgBACRqMRWq0WKpWqyxoRERFgwz22xsZG1NbWytNZWVkYM2YMvL29ERERgczMTABATk4ONBoNdDpdtzUiIiLAhntsFy9eRFxcHMxmM4QQCAoKwrZt2wAAW7duRUJCAtLS0qBSqZCRkSGP665GRERks2ALCgrC0aNHO60FBwejoKCgxzUiIiKbnxVJRETUlxhsRESkKAw2IiJSFAYbEREpCoONiIgUhcFGRESKwmAjIiJFYbAREZGiMNiIiEhRGGxERKQoDDYiIlIUBhsRESkKg42IiBSFwUZERIrCYCMiIkVhsBERkaIw2IiISFEYbEREpCgMNiIiUhQGGxERKQqDjYiIFIXBRkREisJgIyIiRWGwERGRotyWwVZaWoqYmBjo9XpERUXh1KlTtm6JiIgGiNsy2JKTk5GUlISSkhKkpqYiISHB1i0REdEAcdsFW1VVFQoLC7Fw4UIAQFxcHEwmE8rKymzcGRERDQS3XbCZTCb4+fnBwcEBACBJErRaLYxGo407IyKigcDB1g1Yi8FggMFgkKcrKyuh0Whs2FHfaWhogIuLi63bgCbT1h3QjfjeoO4MhPdHX7w3qquru61LQghx66vpP1VVVdDpdLh06RIcHBwghICfnx8OHToEnU5n6/b6hUajQUVFha3boAGI7w3qzk/l/XHbfRXp7e2NiIgIZGZei/2cnBxoNJqfTKgREVH3bsuvIrdu3YqEhASkpaVBpVIhIyPD1i0REdEAcVsGW3BwMAoKCmzdhs2kpKTYugUaoPjeoO78VN4ft90xNiIiou7cdsfYiIiIusNgIyIiRWGw3UZWrFiBwMBASJKE4uJiW7dDA0hLSwtiY2Oh1+sRFhaGadOm8Wo8JJs+fTpCQ0MRHh6OCRMm4OjRo7ZuyaoYbLeRefPm4dChQwgICLB1KzQAJSUl4cyZMzh27Bjmzp2LxMREW7dEA8T27dtx/PhxFBcXIyUlRfHX12Ww3UYmTpyomKunUN9ycnLC7NmzIUkSACA6Ohrl5eW2bYoGDHd3d/l5XV2d/D5RqtvydH8i6t7mzZsxd+5cW7dBA8iiRYuQl5cHANi9e7eNu7EuBhuRwqSlpaGsrAwHDx60dSs0gGzbtg0A8Pe//x2pqamKDjd+FUmkIOnp6di5cyf27NkDZ2dnW7dDA1B8fDzy8vJQU1Nj61ashsFGpBAGgwFZWVnYv39/h2Mq9NNWW1uL8+fPy9O7du2CWq3GkCFDbNiVdfHKI7eR5ORk5ObmorKyEmq1Gq6urjylmwAAFRUV8Pf3R1BQEFxdXQEAgwcPxpdffmnjzsjWvvvuO8yfPx/Nzc2ws7ODl5cX0tPTER4ebuvWrIbBRkREisKvIomISFEYbEREpCgMNiIiUhQGGxERKQqDjYiIFIXBRjRAtLW14bnnnsPPfvYzhISEIDw8HElJSdi1a1evTs3+4IMP8Nvf/rbvGyUa4HhJLaIBYsmSJbh06RIKCgrg4eEBIQR27NiBS5cu9er15syZgzlz5vRxl0QDH/fYiAaAsrIyvPfee8jIyICHhwcAQJIkzJ8/H0FBQWhra8OyZcsQFhaGUaNGobCwUB77zjvvIDQ0FKGhobjvvvtw7tw5AMDbb7+N2NhYebmMjAyEh4cjLCwMY8eOla/+/9FHH2H8+PGIjIzEPffcI18ol+i2JYjI5rKzs0VoaGintby8PGFvby+++OILIYQQf/nLX8T06dOFEEKcOHFC+Pj4iIqKCiGEEBs2bBAzZ84UQgiRkZEh5s6dK79GYGCgOH/+vBBCiMbGRtHY2Ci++eYbER0dLerq6oQQQpSWlgpfX1/R0tJitW0lsjbusRHdBnQ6HcaNGwcA+PnPf45vvvkGAJCXl4eZM2di2LBhAIBly5bh448/htls7jA+NzcXjz76KPz8/AAAzs7OcHZ2xt69e1FWVoaJEyciPDwc8+bNg52dHYxGYz9uHVHf4jE2ogEgIiICpaWlqKmpgVqt/lHdyclJfm5vb4+2trZOX6enN5AUQmDatGn4xz/+0bOGiQYw7rERDQA6nQ5xcXFYsmQJamtrAVwLnZycHJw9e7bLcVOmTMHevXvlq7dv2bIFU6dOhb29fYfl7r//fmRmZuLChQsAgKamJjQ1NWHGjBk4cOAAjh8/Li/71Vdf9fHWEfUv7rERDRB/+9vfsGHDBowbNw4ODg5ob2/HxIkTMWvWrC7HhISEYNOmTZg5cyYAwN/fH2+88caPlps4cSLWrl2LGTNmQJIkDBo0CDt27IBOp8M//vEPJCcno6mpCVevXsWYMWO4B0e3NV7dn4iIFIVfRRIRkaIw2IiISFEYbEREpCgMNiIiUhQGGxERKQqDjYiIFIXBRkREisJgIyIiRWGwERGRovw/QSHHFv1g034AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show how often each alternative is chosen\n",
    "print(f\"Total number of choices: {len(df.CHOICE)}\")\n",
    "print('--------------------------------')\n",
    "for choice in range(1, 4):\n",
    "    print(f\"\\t Number of choices equal to {choice}: {len(df.CHOICE[df.CHOICE == choice])} --> {round(len(df.CHOICE[df.CHOICE == choice])/len(df.CHOICE)*100, 2)}% of total\")\n",
    "\n",
    "fig=plt.figure(figsize=(6,4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.hist(df.CHOICE, bins = [0.75, 1.25, 1.75, 2.25, 2.75, 3.25])\n",
    "plt.xticks((1, 2, 3))\n",
    "plt.title('Number of choices per alternative')\n",
    "plt.xlabel('Choice')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of each feature to CHOICE, sorted by absolute value:\n",
      "CHOICE        1.000000\n",
      "GREEN1        0.269186\n",
      "NOISE1        0.236012\n",
      "GREEN3        0.221183\n",
      "NOISE3        0.217670\n",
      "TRANSPORT1    0.197005\n",
      "TRANSPORT3    0.187422\n",
      "NOISE2        0.168685\n",
      "CITY3         0.165109\n",
      "CITY1         0.153796\n",
      "FOREIGN1      0.095885\n",
      "TRANSPORT2    0.095360\n",
      "STORES3       0.079537\n",
      "CITY2         0.067889\n",
      "FOREIGN3      0.064269\n",
      "STORES1       0.060248\n",
      "FOREIGN2      0.048984\n",
      "GREEN2        0.025195\n",
      "SSTADT        0.009905\n",
      "RESPCITY      0.009905\n",
      "AGE           0.007536\n",
      "ENVCONC       0.006206\n",
      "WOMAN         0.002445\n",
      "STORES2       0.000457\n",
      "Name: CHOICE, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAH9CAYAAAA041e5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACSKUlEQVR4nO29eZwcVbn///7MZAJhgixhk2GJAoKCkElGUC/IMsqiREC8BhQhooko6BUFEUHNdeMiKHxFFKNs8QcKLihREXFBULjiBMIqCshy2dRERAlhm3l+f5zTmUqne6a7q6b7TM/znle9puvUqaeeU8+pU0+dVWaG4ziO4zhOinS0WgHHcRzHcZxquKPiOI7jOE6yuKPiOI7jOE6yuKPiOI7jOE6yuKPiOI7jOE6yuKPiOI7jOE6yTGq1AuMVSbOB2euss868LbbYIpesoaEhOjry+YxFyEhJF09P2rq0W3pS0sXTk7YuKaXnz3/+8zIz2xhgo402sunTp+fWqxaWLFmy6rrNQD6PSj56e3vtN7/5TS4ZAwMD9PX1tVxGSrp4etLWpd3Sk5Iunp60dUkpPeutt94SM+sD6Ovrs4GBgdx61YKkVddtBt704ziO4zhOsnjTT0HMOedSVj7/Qs3xp3RN4rIPvH0MNXIcx3Gc8Y/XqBREPU5KI/Edx3EcZyKSXI2KpM2As4FXAf8E/gp8CPiBme2UibcAeMrMzpQk4BTgKMCAR4DjzOzOGPcBoM/Mlo0g/zngj8CfMup8ycwWjUU6ncZYcfetMDS05oGODrp32KX5CjmO4zhjSlKOSnQ4rgAuNrPDYtguwKajnHos8FpgFzN7WtK+wJWSdjSzZ2qU/3/AfWY2o+BktZS/LPsnlfpLS/DSjdavWc4jT/ybcjECejZYt2YZdz++jKEKunQIdthso9qEVHJSRgp3aubZRx9kjcwisdbmW7dGoQR45uG/rHlPACTW3uKlNct57rGHKt7byS/eqmYZK+//E1iFfK4Oprxk+5pk3PPX5VWfwe02nVazLo7TTJJyVIC9gefN7LxSgJndKmn6KOedBOxpZk/Hc34u6QbgHcD5o8kHqOEaLWHFc6s3EXVPrs9k1QZ11TvYq1L0eseLVSogRwofS55Y+ewaYRtMWav5igCDT/5jjbDO9TasW87Qin+vtt/RXbsTCVTOFC0cFWjPrFxtX2tPqVvG0FNPrhHWMXW9OpQo6gEq4N5WclJGCq9Akc/g0NNPrbbfsc7U+oU4Tg2k5qjsBCypcmwbSUsz+5sBZ0p6EdBtZn8piz8A7FiH/ErX+ICZXT+q1o7jrMbzmRdfl1qnhzM+EPV/+GQxCNXEZuTKbjY0rIsa7MJZhIwoh7wy2oTUHJWRWK1ZJvZRGdNrVEPSfGA+wJZbbjkGajiO4zjNRpn/jTpORchwVic1V+1OYFY9J5jZv4AVksobjGdFebnkV7nmQjPrM7O+adO8XddxHCcPeV/oApS3NiWjR+7anZwygFCT4rUpQHqOyq+AtWKNBQCSdgZGq7Y4A/iypCnxnNcDuwOX1iJf0h5FKD8WdE+etNpWL6ry5FYLryqnxjCndXR0r7vaVjeVMkW9GSXSpeGtUbT2lNW2llDYA1TcvU2FjnWmrra1BerA8joIRchwViOpph8zM0mHAGdLOgl4BniAMHx4JM4BNgBulzQIPA4cZGar9carQX55H5ULzOzLedLUauoZ2TMS9YzuqUaHKnfa66invO7oqDo8uR5a1XG2Eo10nB0L2nF0T10dZytQz8iekahndE9V1FF11E+tFPIMOk6TScpRATCzR4G3VTi0U1m8BZnfBvx33CrJnF6DfIAWfbZNDGoegjwCPleKM1GpdQjySPgQZGc84nVTjuM4juMkizsqBTGlq77KqXrjO47jOM5ExN+WBeELDDqO4zhO8XiNiuM4juM4hSHpAkl/k3RHIfKshVNkj2ckzQZm9/T0zFu0KN+6hStWrKC7u7vlMlLSxdOTti7tlp6UdPH0pK1LSunp7+9fYmZ9AH19fTYwMJBbr1qQtOq6VY6/DngKWJRdTLhRvOmnQcxsMbC4t7d3Xl9fVXvVxMDAACnISEkXT0/aurRbelLSxdOTti4ppSfLnx79G3st+Eph8vJgZtcVuX6eOyqO4ziO49TDRpKy1TcLzWzhWF3MHZWEmHPOpax8/oXRI2aY0jXJO/I6juM4qHmzHS8bqemnaNxRSYh6nZRGz3Gcduahb5yOPf/cqPHUNZmt5p3UBI0cZ+yRRMc4X5ahGk0f9SPpFEl3SrpN0lJJv47/75X0ZPy9VNJrJU2WdHY8do+kH0naIiNrMMa9Q9JiSevH8OmSVmZkLZV0ZDx2tKTb4/XvkHRQDP/PqNeQpKZ5io7jFEstTko98RzHaS1NrVGR9BrgQGCmmT0raSNgspk9Kmkv4AQzOzAT/0xgXWB7MxuU9C7gB5J2i9PmrzSzGTHuxcCxwOfi6feVjmXkbQGcEq//pKSpwMbx8B3AW4Cvj0HSnTbkuccegvJRc1Ix67o4juPUSSoVKpK+DexF6MvyMPApMzu/UXnNbvp5MaFt61kAM1tWLaKkdYB3AS8xs8EY/0JJRwP7AL8sO+VGYOdRrr8J8G/CsCnM7KnM7z/G69aZpOqseG71ZplGVj92EqbS0H4f7u84zgTHzA4vUl6zm35+Dmwp6c+SvippzxHibgs8ZGb/KgsfAHbMBkjqBPqBKzPB25Q1/ewB3Ar8Fbhf0oVxLpQJQyLONtgQsqHKK8HWQTLpKQADTCKvm2Nxa7UuRaWHAvJJUSST3wp6flJhEBhEDLZYRhA0iAYHYTCHpBbK6Ij9VMZ6azZN/cQ3s6ckzQL2APYGLpP0MTO7qEGRUyQtBXqAPwLXZI6t0fQDIGl/4FUEx+YsSbOyKzHXgqT5wHyALbfcsiHFm40y/1v9zZ+SLslQevilfLUyJTlFyMijS0HpKeWVVueTovJsEelpv+eniBQVc1dS0aQRGaKpo36aStM705rZoJlda2afAo4DDq0S9T5gK0nrloXPAu6Mv0t9VLYm2OnYGq5vZnaTmZ0GHDbC9UeSsdDM+sysb9q08bFsupX9byVF6ZJCWgqj9DLP23RkVoyMvLoUlJ4iaoiKoMg8W1S+T+G+FEMRKSrmrqSiSfvZOB9NdVQkbS9pu0zQDODBSnHNbAVwMfCl2LRDHLmzDvCrsrhPAx8EPiKpai2RpM0lzazl+kXQPXnSalurSSbTqwNTB2icLzVV6eulwS8aATLL3bwg8jdRFKFLUekhoXziz8/Y0Al0YnS2WEYQ1Il1dkJnDkktlCGpKVuzafbbcypwThxG/AJwL7EJpQonA2cCf5Y0BNwNHGIVFigys1sk3QYcDlxP7KOSiXIB8CPgTEmbA88AfweOAZB0CHAOYRTQTyQtNbP9cqTVaXN8dI/jOMkg6GjPlp+m91FZAry2yrFrgWvLwp4FPhC3SudMLdvPdo6dUkWNfarIugK4oso5juM4juO0gNa3RziO4xSIuibXPDOt47QTSmdsWqG4o5IQU7omNbTWj+M4w/i0+M5ERLSm/0gz8LdcQvjigo7jOI6zOu6oOI7jOE4b0K6LEqrCABqnBuKstrN7enrmLVq0KJesFStW0N3d3XIZKeni6Ulbl3ZLT0q6eHrS1iWl9PT39y8xsz6A9beYbnt+8NTcetXClSfNW3XdZuA1Kg1iZouBxb29vfP6+vLZa2BggBRkpKSLpydtXdotPSnp4ulJW5eU0jNRcEfFcRzHccY5on2bftxRaUPmnHNpXaOHpnRN8o68juM44xm171o/7qi0IfUOca43vuO0Ow994/Sa52Lx4dCOM7aMuFiEpGmSlsbtcUmPZPYt/r9D0uI4LX723KWSvlMWdlGUsVbc30jSA/F3h6QvR3m3S/qDpJfEYw/EsNsk/VzSZjF8PUmLJN0r6b74e714bLqklVGPu+KxTUdIz2RJF0j6m6Q7irrBjuOMP2pxUuqJ5zjNYEKu9WNmywkL9yFpAfCUmZ0Z95+KKxcj6WLCysWfi/svJ6wTtYek7rjAYIlB4Gjga2WXmwNsDuxsZkOStgCy5+1tZsskfR74OGERwvOBO8zsyHjd/wa+CfxnPOc+M5sRFzW8Bnh9RufV0hPDLgK+AuQaxvOXZf+suGisBC/daP08op0249lHH6y8wrDEWptv3XyFHMdxEqOo5TdvBHoy+4cD3wJ+DhxUFvds4Hitucrxi4HHzGwIwMweNrMnKlzrOmBbSdsCs4DPZI59GuiTtE32BDMbBG4q03ENzOw64B8jxamFaiO+fSS4swaeWRzHKYDQmbY5W7PJ7ajE2op+4MpM8BzgO8C3CU5LloeA3wLvLAu/HJgdm2G+KKm3yiUPBG4HXgEsjU4IsMohWQrsWKbj2sBuwM9qT5lTERsKW6tlQDGrWhSUHhWUprxY3FKgCPsMxi0PBpiUxn0pIJ8UkZ7C7kmbPT+F6FJQeup/lpvT7NOKpp88jsoUSUuBx4FNCU0rSOoDlpnZQ8AvgV5JG5adexpwYvb6ZvYwsD1wMjAE/FJSf+acX8frvSieXwvbxHP+Sqitua2eBFZD0nxJA5IGli9fXoTIka9HQS/lAihCl6JkZP+3gy6FIIUtjwhSuicFaFO6HwmMiCjkWS4iPQXdk5TySiq6FJb3C3iW24U8jsrK2N9ja4JNjo3hhwM7xE6y9xEci0OzJ5rZPYSaj7eVhT9rZleZ2YnA54GDM4f3NrMZZnakmf0TuAuYIWlVGuLvGfEYxD4qwDbALElvzpHerJ4LzazPzPqmTZtWhMiRr0c6X8lF6FKUjOz/dtClEMxyNxuldU8K0KZ0PxJoTivkWS4iPQXdk5TySiq6FJb3G3iWO6SmbM0md9OPmT1N6Nj6EUmTCc7HK81suplNJ/RRKW/+gdDx9oTSjqSZkjaPvzuAnYEHR7juvcAtQHbO4FOBm+OxbNxlwMcItTVOHtQRtlbLoCDHoKD0WEFpyktKtW9F2KczbnkQILM07ksB+aSI9BR2T9rs+SlEl4LS08izrCb9NZtCcoaZ3QLcRnAEHjGzRzOHrwNeIenFZefcCdycCdoEWByHBt8GvEAYgTMS7wZeFocm3we8LIZV4ofAOpL2qCZM0rcJHYO3l/SwpGqyRqSaw+m1eM4aeGZxHMcZkZonfDOzBWX7U8v2Z8ef/10WPghsFnfnlh17S+b3z6jS2TXWzFQKfwI4osqxB4CdMvsG7JLZX1DhnEo1P3XjQ5CdWvEhyI7jFEE7d2nxmWkdx3HKUNfkmmemdZxU8LV+nHHDlK5Jda/14zjOMD4tvuOkg7+h2hBfYNBxHGei0Zo5TpqBOyqO4ziO0wa0q6MiS2BugfGIpNnA7J6ennmLFuVaGogVK1bQ3d3dchkp6eLpSVuXdktPSrp4etLWJaX09Pf3LzGzPoBpW73U3vTRz4x2SiF86wNHrLpuM/AalQYxs8XA4t7e3nl9ffnsNTAwQAoyUtLF05O2Lu2WnpR08fSkrUtK6clSWuunHXFHxXEcx3HGO2rfph93VJyKzDnn0rpHDnknXsdxHKdo3FFxKlKPk9JIfMdpd+49/SPYc8/WFFeT12Lbk744xho57U67zqOSwOIKjuM47UetTkq9cR1nojFuHRVJm0n6TlznZ4mkn0p6maQ7JO0naWncnpL0p/j7p5IekLRZRs65kk6WNE3Sr2P80dYYchzHcZxkEKGPSjO2ZjMum34U7tQVwMVmdlgM2wXYFMDMrgaujuHXAieY2UDcPwY4EzhC0kxgD2AWMBn4BGF9oJ3IySNP/HuN1WMF9Gywbl7RjrMGg/9cvkZY5/rTWqCJ4zitoj0bfsZvjcrewPNmdl4pwMxuBf6vhnMXAttI2hs4FzjOzJ43sxVm9lvgmSIUrDQ7TUtnrLEhZENgQ63UIjA4iAYHYXCwcRkppacIEkqPASblzq/JFJpF5LeEGAQGEXlSU5SNKSLPppb3i5CRyr1tE8ZljQqhxmNJIyea2ZCk9wG/Aq40s+vqlSFpPjAfYMstt2xEjfquF//nyfjK/G/1FH9F6FJUeoq8t+1in1VLsErQ4ISQKdonBV2KoYAUFWDjrCZtY5/SfckzEWrL7q28M207YWZLgTuArzZ4/kIz6zOzvmnTxr56vSgvP/u/lRShS1HpKewLqgAZ2f8tpVS45ihkU7NPKroUQwEpKsDGJQ3ayj5mue9JK++t91FJizuBt+aUMRS3iYE6Eilkgc7O/LqklJ4iSCg9gvyFNam81CkmvyVEJ5D37hZlY1TAt25qeb8IGanc2zZhvDoqvwI+L2m+mS0EkLQzsF5r1RqmUjVme1bKOSngHWcdZ2Ijn5k2LczMJB0CnC3pJEIH2AeAD+WRK+kB4EXAZEkHA/ua2V2NyPLRPY7jOE4z8bV+EsPMHgXeVuHQTmXx9qpy/hrhZja9ANUcx3EcxymIceuoOGPLlK5Jda/14zjOMJq8Vl1T6DtOXrzpx5lQ+AKDjpMPX7vHaSbC1/pxHMdxHMdpOrIihlFNQCTNBmb39PTMW7RoUS5ZK1asoLu7u+UyUtLF05O2Lu2WnpR08fSkrUtK6env719iZn0Am07f1g771Bdy61ULXz760FXXbQbe9NMgZrYYWNzb2zuvry+fvQYGBkhBRkq6eHrS1qXd0pOSLp6etHVJKT2roeFJcdsNb/pxHMdxHCdZvEbFGVPmnHNp3aOHvCOv4zhO/bRrZ1p3VJwxpR4npZH4jtPuPHLJudgLz48aT5O66HnHsU3QyHGaizsqjuM4CVOLk1JPPKc9EaA2XaglSUdFkgFfMrOPxP0TgKlmtiDuzwc+HKP/C/iwmf02HrsWOMHMBiQdDRxPWHanAzjFzH4k6SJgT+DJKONpM3utpB2AC4GZMe6Zjeh/9+PLGKowmKpDsMNmGzUi0nHGnGceuq/yYmoSa2+1TfMVchynLrzpp7k8C7xF0mlmtix7QNKBwHuB3c1smaSZwA8l7Wpmj2fibQGcAsw0syclTQU2zog60cy+V3bdfwAfBA7Oo3wlJ2WkcMdJgmpTFfgUBo7jtJBUR/28ACwk1IaUcxLByVgGYGY3AxcD5Y2zmwD/Bp6K8Z4ys/tHuqiZ/c3M/gCkVYdqQ2HLKUN55QwOosFBGBzMp0sBGGBSMsvD56Wo9BhrrtrdEorIbylRUHoG49YupJLfnrfhLReplLUN6iI1Z2s2qToqAOcC75C0Xln4jsCSsrCBGJ7lVuCvwP2SLowTtGU5Q9LSuF1Sj2KS5ksakDSwfPnyek5tCMUtr4zs/1bJKIzS05LzqSnq3ua+JwWlp2UlSbkaZf/zyGl9aorM+6mkqMB8W0B+S+OOpFPWNqSLwlo/zdiaTbKOipn9C1hEaIpp5PxBYH/grcCfgbMkLchEOdHMZsTtHXXKXmhmfWbWN23atEbUq4sivlqs7H+rZBRGqTkiZ7NEUfc29z0pKD2YJdFUU1ReSeWLvbi8n0qKCsy3CeS3okilrC1Kl3Yh1T4qJc4GbiZ0cC1xFzAL+FUmbBZwZ/nJFtYHuAm4SdI1Uc6CMdJ17FAB/qQ68mf6zs5kHhxBWxWQRaUnlS/TQvJbShSUns4CZKREUfkt773tKkqRVMraKKeu6KhtO9MmW6MCYGb/AC4H3p0J/gJwuqRpAJJmAHOBr2bPlbR57GhbYgbw4Biqu4qOKnmlWrjjJEG1Qq5NCz/HaTfatekn9RoVgC8Cx5V2zOxKST3ADXEY87+BI8zssbLzuoAzJW0OPAP8HTgmc/wMSadm9ncFNiT0d3kRMCTpQ8ArYjNUzfgQZGc84kOQHcdJkSQdFTObmvn9V2CdsuNfA75W5dy9Mrv7VIkzt8qlHwe2qENVx3GcMUWTumqemdaZ2LRr5WeSjorTPkzpmlT3Wj+O4wzj0+I7tSB8wjfHaQhfYNBxHMfJgzsqjuM4jjPeifOotCOyNhri2UziBHKze3p65i1atCiXrBUrVtDd3d1yGSnp4ulJW5d2S09Kunh60tYlpfT09/cvMbM+gM232c7mf/7LufWqhf8+7I2rrtsMvEalQcxsMbC4t7d3Xl9fPnsNDAyQgoyUdPH0pK1Lu6UnJV08PWnrklJ6JgruqDiO4zhOG9CmLT/uqDjpM+ecS+seOeSdeB3HcdoDd1Sc5KnHSWkkvuM4znhHtGbW2GbgjorjOE6b88gl59Y8aZzP2zJ+8XlUxhBJmwJnAa8GngCeI6zp8wTwI+B+YG3gx2Z2QjxnLnAG8EhG1NuBp4E/An/KhH/JzBZJegBYYmaHRhlvBQ40s7mSdiAsWjgTOMXMzmw0PSvuvhWGhtY80NFB9w67NCrWcRynIWpxUuqJ5zjNpOWOikJd1Q+Bi83s7TFsa+DNBEflejM7UNIU4BZJV5jZ7+Lpl5nZcWXypgP3mdmMKpecJekVZnZXWfg/gA8CB+dOVCUnZaRwx2kTnnnovsqrQEu+lpDjjDFtWqGSxOrJ+wDPmdl5pQAze9DMzslGMrOVwFKgJ+f1vgicUh5oZn8zsz8A/kkxkbChsDnFUG1epkbna3L7JM0gMIgYbLUibYjFrWbUvqsnp+Co7AjcPFokSRsA2wHXZYLnSFqa2abE8G3KwvfInHM5MFPSto0qLGm+pAFJA8uXL29UTNMpJHsV8OKo+wEcQ0T++1JEegwwqRg5OWWkRBH2KclpJ9JJj8r+55OSi0TKpqKeZaT2rSKpk5Y3/ZQj6Vxgd0I/lROBPSTdSnBSzjazxzPRKzX9wMhNP4OEvi0nA1c1oqOZLQQWAvT29rbTe2HC4cZLG7dP6hjBzXBLFU6dtZDtvChhCjUqdxI6sAJgZscC/cDGMeh6M9uFUPPybkkzCrjmt4DXAVsWIGvcUEhRoo6w5RFBQl+EiaRHgMyKkZNTRlIUYB9ov9doKunpBDoxOnPKaaeyqZXPsjf9jB2/AtaW9L5M2DrlkczsfuB/gJPyXtDMnieMMjo+ryzHcTJUK8Ta9EvPcZyxp+VNP2Zmkg4GzpL0UeDvwAoqOyTnASfEkT0Q+qjsnjn+fuBRYh+VTPgFZla+WtP5wKmlHUmbAQPAi4AhSR8CXmFm/6o7UR0dVYcnO0474yN7HKd1dLTp90DLHRUAM3sMOKzK4Wsz8VYyPOrnorhVYkqlQDObnvn9LLB5Zv9xYIvaNB4ZnyvFcZyU0KSumid8c8YnPjOt47SQKV2T6l7rx3GcYXy2WWc84yW6kzy+wKDjOM7oqL260q/CHRXHcRzHGe+ofYcnyxqdMXKCI2k2MLunp2feokWLcslasWIF3d3dLZeRki6enrR1abf0pKSLpydtXVJKT39//xIz6wPYcrvt7cNfOm+0Uwrhw2/eZ9V1m4HXqDSImS0GFvf29s7r68tnr4GBAVKQkZIunp60dWm39KSki6cnbV1SSk85bVqhksQ8Ko7jOI7jOBXxGhVnQjDnnEvrHjnknXgdxxkvtPMU+u6oOBOCepyURuI7juO0Gp9HxXEcx5nQPHLJuaNOHKdJXT5vi1MoY9ZHRdKgpKWZbXoM313STZLujtv8zDkLJD0S498l6fDMsYsk3Z+Rd0MMnyvpK5l4R0i6TdKdkm6V9E1J68dj10oayMTtk3Rt/D1N0q8lPZWV5ziO4wRqmd22ljjOWNCcBQlbUWszljUqK81sRjYgrqdzKXCwmd0saSPgakmPmNlPYrSzzOxMSdsBSyR9Ly4iCHCimX2v2gUl7U9YaPAAM3tEUidwFLAp8M8YbRNJB5jZVWWnPwN8Atgpbrl4YuWza4RtMGWtvGIdZ0LwzMN/WXOZe4m1t3hpaxRynMSR2netn2aP+jkWuMjMbgYws2XAR4GPlUc0s3uAp4EN6pB/CnCCmT0SZQya2QVm9qdMnDNivPLrrTCz3xIcFsdxcjAIDCIGGxVQaX4nn/PJmSi88Pzw5oypozIl00xzRQzbEVhSFm8ghq+GpJnAPWb2t0zwGRmZl1S45o7AzaPodSPwnKS9a0vGmkiaL2lA0sDy5csbFdNcbAjZEFiFVZ3HIymlpyA9kvkYKuTequz/+MYAk0jFVcp9V1N6figml1jc8gkp4J608N5600/9rNH0UyPHS3oX8DJgdtmxEZt+skh6JfAtYF3g42Z2WebwZ4FTgZMa0A8zWwgsBOjt7U2l7HKchDDC68cfD8dpFu06PLnZTT93AbPKwmYBd2b2zzKzHYFDgfMlrV2H/DuBmQBmdnt0lK4CpmQjmdmvYtir69J+PKMOTB2gNpnjL6X0FKRHMq/0Au5tJ9CJ0VmcVi1FgMySqR/KnVdSen4oJu+LAmpmirgnRdzbSV3Dm9N0R+VcYK6kGRBG2gCnA18oj2hmVxKahY6qQ/5pwJmStsiETakS97OE/jFjwgZT1lpjcxynRip9Gbbp16LjFEFpwrdmbM2mqfOomNljko4AviFpXcK9PTuum1OJTwOXSvpG3D9D0qmZ47uWyf+ppI2Bq+KIn38CdwBXV9Dlp5L+ng2T9ADwImCypIOBfc3srjqT6ThOTnx0j+PUj0/4VidmNrVK+HXAq6ocW1C2vwTYPu7OrXKpi+JWOudi4OIq8vcq259Vtj+9yjUcx3EmPJrUVdOEb45TJD4zreM4jlMTPuNswrRoRE4zcEfFmRBM6ZpU96KEjuM444l2nfDNS2NnQuArITuO44xPZD7bY0NImg3M7unpmbdo0aJcslasWEF3d3fLZaSki6cnbV3aLT0p6eLpSVuXlNLT39+/xMz6AF6y/cvtU+ddmFuvWnjXPq9Zdd1m4DUqDRJHKi3u7e2d19eXz14DAwOkICMlXTw9aevSbulJSRdPT9q6pJSecpTMTD/FksZsP47jOI7jOBXwGhXHqYM551xad6dc7x/jOE4z8Cn0Hcepy0lpJL7jOI6zOl6j4jiO4zjjHNG+q0w03VGRdArwdmAQGAKeADYApgIbA/fHqO8nrPXzBeBAwrpVdwHHmtnDUdYgcDshHfcD7zSzf0qaDvwR+FPm0l8ys0WSjgaOj/I6gFPM7EeSziCs1vwccB/wLjP751jcA8dxHMcpFLVv009THRVJryE4HTPN7FlJGwGTzexRSXsBJ5jZgZn4ZwLrAtub2aCkdwE/kLSbhXHVK+MKyUi6GDgW+Fw8/b7SsYy8LYBT4vWflFRyjgCuAU42sxcknQ6cDJxU/F2oneceewjKh49LTH7xVq1RyHHGEc89/nDl52ezLSqf4DhOkjS7j8qLgWVm9iyAmS0zs0crRZS0DvAu4HgzG4zxLwSeBfapcMqNQM8o198E+DfwVJT3lJndH3//3MxKHQr+F2h9aVZpjhuf98ZxasOfH2dCEabQb8bWbJrtqPwc2FLSnyV9VdKeI8TdFnjIzP5VFj4A7JgNiCsl9wNXZoK3kbQ0s+0B3Ar8Fbhf0oVx0rZKHA1cVUe60seGkA2BDbVak0IwwCRyv3YSuifJVNoWkVcGB9HgIAwO5lMlbimQjH0oSJc2y/vtlFcGgUFEvU+POyoFYGZPAbOA+cDfgcskzc0hcoqkpcDjwKaE5psS95nZjMx2fayZ2R94K/Bn4CxJC7ICYx+aF4BLql1U0nxJA5IGli9fnkN9x2lPVPbfcRynUZo+PNnMBs3sWjP7FHAccGiVqPcBW0latyx8FnBn/F3qo7I1oUwcdWlPC9xkZqcBh2WvH52mA4F32AhrC5jZQjPrM7O+adOmjXbJNFAHpg5Qe4xIFyCz/C/ChO5JKl+DReQVK/vfsCqk4+wkYx8K0qXN8n475ZVOoBOjs45zRFiUsBlbs2lqLpW0vaTtMkEzgAcrxTWzFcDFwJdi0w6SjgTWAX5VFvdp4IPARyRV7SAsaXNJMytdX9L+wEeBN0d5radSFVub9up22ozOTqyzEzrrKWoLxp8fZ4LRrk0/zR6ePBU4R9L6hOaVewnNQNU4GTgT+LOkIeBu4JBKtR1mdouk24DDgeuJfVQyUS4AfgScKWlz4BlC89Mx8fhXgLWAa6Ih/tfMjqGF+Ogex2kcH93jOO1BUx0VM1sCvLbKsWuBa8vCngU+ELdK50wt2892jp1SRY1KI4Yws22rxHccx3GctBEtqe1oBj4zreM4juOMcwR0JNNLp1jS6EnlOOOEKV31+fb1xnccx3FWx0tRx6kDXwnZcZxUadOWH3dUHMdxHGf8o7Zd60cjTBfijECc1XZ2T0/PvEWLFuWStWLFCrq7u1suIyVdPD1p69Ju6UlJF09P2rqklJ7+/v4lZtYHsO3Ld7QvXnRpbr1q4eBXz1h13WbgNSoNYmaLgcW9vb3z+vry2WtgYIAUZKSki6cnbV3aLT0p6eLpSVuXlNJTTruO+vHOtI7jOI7jJIvXqDhOk5lzzqWsfP6F0SNGpnRN8k68juOMiGjfGhV3VBynydTjpDQS33GcCUiL1uFpBiM2/UiaJmlp3B6X9Ehm3+L/OyQtjtPiZ89dKuk7ZWEXRRlrxf2NJD0Qf3dI+nKUd7ukP0h6STz2QAy7TdLPJW0Ww9eTtEjSvZLui7/Xi8emS1oZ9bgrHtt0hPRsLenXMe6dkv6rqJvsOI7jOE5jjFijYmbLCQv3IWkB8JSZnRn3n4orFyPpYsLKxZ+L+y8nLAC5h6TuuMBgiUHgaOBrZZebA2wO7GxmQ5K2ALLn7W1myyR9Hvg4YRHC84E7zOzIeN3/Br4J/Gc85z4zmxEXNbwGeH1G5/L0vBj4iJndHFdsXiLpGjO7a6R7lDrPPvogVBrZJbHW5ls3XyHHGWc897dH1nyGJCZv0tMahRynCt70MzI3Ajtn9g8HvgW8HDgIyI6ZOhs4XtI3ymS8GHjMzIYAzOzhKte6DvigpG2BWQQHp8SngXslbUNwiIiyBiXdBFQtWczsMeCx+Pvfkv4Y4zfkqAw++Y81wjrX27ARUfmoNvzch6U7Tm1Uelb8+XESQ9C286jkHvUTayv6gSszwXOA7wDfJjgtWR4Cfgu8syz8cmB2bIb5oqTeKpc8ELgdeAWw1MxWc0iApcCOZTquDewG/KzGNE0HeoHf1xJ/rLG4JYENhS2PCMCkXGkqQkbbMTiIBgdhcHD0uE0gmSLThlAB+TYZikhPQveksGe5gPQMAoOIPE9QKjLaiTyOyhRJS4HHgU0JTStI6gOWmdlDwC+BXknlVQmnASdmrx9rULYHTgaGgF9K6s+c8+t4vRfF82thm3jOXwm1NbeNdoKkqcD3gQ+Z2b+qxJkvaUDSwPLly2tUxXHGFpX9dwLtdl/aLT1pUcTdbZUMITVnazZ5HJWVsb/H1oS7eWwMPxzYIXaSvY/gWByaPdHM7iHUfLytLPxZM7vKzE4EPg8cnDm8t5nNMLMjzeyfhCaZGZJWpSH+nsFwc819UcdtgFmS3jxSgiR1EZyUS8zsB9XimdlCM+szs75p06aNJLIQREKFkjrClkcEILPcj3FeGe2Glf1vNanpkYo+eSkkPerACniWi6CwZ7mQ9BRxd1snQ2rO1mxy51Ize5rQsfUjkiYTnI9Xmtl0M5tO6KNS3vwDoePtCaUdSTMlbR5/dxD6vDw4wnXvBW4BTs0EnwrcHI9l4y4DPkaoramIgpt4PvBHM/tS1QSPN6rlqjZty5zQdHZinZ3Q2dlqTdIi70u50rPSyucnISej3egEOjHyPEGpyGgnCulMa2a3SLqN4Ag8YmaPZg5fB7wijqrJnnOnpJuBmTFoE+AbpaHLwE3AV0a59LuBcyTdF/dvjGGV+CGwQNIeZnZ9heP/Qeg3c3tsLgL4uJn9dBQdKtKSjrMV8JE9jpMPH93jjBc62rSOuWZHxcwWlO1PLdufHX/+d1n4ILBZ3J1bduwtmd8/o0pn11gzUyn8CeCIKsceAHbK7BuwS2Z/QVn835JQC4vjOI7j1EpolmnPV5jXHTqO4ziOkyw+hb7jNJkpXZPqXuvHcRxnNNq1RsVLQMdpMr7AoOM4Y8GEXOvHcRzHcRynlch8KuiGkDQbmN3T0zNv0aJFuWStWLGC7u7ulstISRdPT9q6tFt6UtLF05O2Limlp7+/f4mZ9QFsv+NOtvCyqtN/Fcper9x+1XWbgTf9NIiZLQYW9/b2zuvry2evgYEBUpCRki6enrR1abf0pKSLpydtXVJKz0TBHRXHcRzHGecIte2ihO6oOM44ZM45l9Y1cgjC6CHvyOs4bYrPo+I4TkrU66Q0eo7jOE6rGbeOiqTNJH1H0n2Slkj6qaSXSbpD0n6SlsbtKUl/ir9/KukBSZtl5Jwr6WRJb4hybo//92ll+hzHcRynHtp1UcJx2fQTFxC8ArjYzA6LYbsAmwKY2dXA1TH8WuAEMxuI+8cAZwJHSJoJ7AHMIky3P9vMHpW0UzzfF/lwHMdxkkfgfVQSY2/geTM7rxRgZrdKml7DuQuBoyTtDXweOM7MniesxFziTmCKpLXM7NlGlRxa8e/V9ju6121UVMsZ/OfyNcI615/WAk0cZ3wy+OQ/1ghLZfFSx0mZ8eqo7AQsaeREMxuS9D7gV8CVZnZdhWiHAjfncVKKpDTTTR5f2SDU2Zm1fOXFdktPIQwOImK6Osf/4u5J2ceGhu+tGmztLkJGUSSmC3n1aDf7wLAuDTKYkVJPadCunWnHq6OSCzNbKukO4KvlxyTtCJwO7FvtfEnzgfkAW2655VipWSylDBxfHknokkePlNJTAMr8H/+pISn7tN29TYjSvc1zX4uwT/vZuLEUqfWfBWNC613PxriT0K8kD0NxW4WkLQh9X440s/uqnWhmC82sz8z6pk0b++YPka/2ARh+WaTwUjfLr0dK6SkAK/s/7knIPoXcW3Vg6kjiaz0lXYz8ebYI+6T2/OTXI7UUtZbW5/TG+BWwVqzZAEDSzkDD1RuS1gd+AnzMzH6XW0NCn5Ts1koEKIVqeIpxvFJKTyF0dmKdnW3R7AOJ2SehF3vbUcR9LcI+bWbjTqCzzmYfCIsSNmNrNuOy6cfMTNIhwNmSTgKeAR4APpRD7HHAtsAnJX0yhu1rZn/Lo2u74B1nHScf3nHWGUskeR+V1DCzR4G3VTi0U1m8vaqcv1fZ/meBzxaknuM4juM4BTBuHRXHcRzHcYbxeVQcx0mGKV2TGlrrx3Gc9sWbfhzHSQZfXNBxnImCOyqO4ziO0wa0aYUKsgTmORiPSJoNzO7p6Zm3aNGiXLJWrFhBd3d3y2WkpIunJ21d2i09Keni6Ulbl5TS09/fv8TM+gBe8cqd7dIf/Ti3XrXQu83Wq67bDLxGpUHMbDGwuLe3d15fXz57DQwMkIKMlHTx9KStS7ulJyVdPD1p65JSerL4ooSO4ziO46SLvDOt4zhtyJxzLq1r9NCUrknekddxnKbijorjTGDqHeJcb3zHcZqF2rbpJ8mFESSZpC9m9k+QtCCzP1/S3XG7SdLumWPXSuqLv4+WdLuk2yTdIemgGH6RpPslLY3bDTH8HTHu7ZJukLRL0xLtOI7jOA2iJm7NJtUalWeBt0g6zcyWZQ9IOhB4L7C7mS2TNBP4oaRdzezxTLwtgFOAmWb2pKSpwMYZUSea2ffKrns/sKeZPSHpAGAhsFtDCXj0wTVXjpVYa/OtGxHXFjzz0H0V78naW23TGoUcZxzxzIP3VF6NWmLtrbdrvkKO0ySSrFEBXiA4CcdXOHYSwclYBmBmNwMXA8eWxdsE+DfwVIz3lJndP9JFzewGM3si7v4vsEXDKahUoEz0oeB+Txyncao9K/4MOZHSwoRjvTWbVB0VgHOBd0haryx8R2BJWdhADM9yK/BX4H5JF8Z5T7KckWn6uaTC9d8NXNWg7oVicctLEdmrKF2KoJDHxYbCllOGCpDTbq3LyaSnIPs4Y4MBJiVTrhRBq8raDqkpW7NJtekHM/uXpEXAB4GVDZw/KGl/4FVAP3CWpFlmtiBGqdT0A4CkvQmOyu5Vjs8H5gNsueWW9apWP6WMkePLSZn/uQqEAnQpgqLSU5JThIw8uqSUniJIKT2F5f0CSMU+UOy9LaRMkQop41qdnnYra1Mg5RoVgLMJDkN2+r67gFll8WYBd5afbIGbzOw04DDg0NEuKGln4JvAQWa2vFIcM1toZn1m1jdt2rSaEpILs9yZ1cr+t1KXIigqPUXUEBWhS0rpKYKU0lNY3i+AVOwDxd3bQsqU7P8W6pJUfmugrPWmnxZgZv8ALic4KyW+AJwuaRqApBnAXOCr2XMlbR472paYATw40vUkbQX8AHinmf05l/KVjNmggYvqaV1U81EqVfqFFPjqCFtOGVaAnFReYEWRTHoKso8zNgiQWTLlShG0oqyVmrc1m2SbfjJ8ETiutGNmV0rqAW6QZIQOs0eY2WNl53UBZ0raHHgG+DtwTOb4GZJOzezvCnwSmAZ8NXqNLzS6nsFEHt1TlUpVu2067t9xCqda04g/Q06bk6SjYmZTM7//CqxTdvxrwNeqnLtXZnefKnHmVrn0e+LmjAE+DNlxGseHIDuj0a4TviXpqDiO4ziOUw+t6T/SDLzR1nEmMFO66vtWqTe+4zhOXrzUcZwJjC8w6DjtgWjfph+vUXEcx3EcJ1lkCcyJMR6JM93O7unpmbdo0aJcslasWEF3d/foEcdYRkq6eHrS1qXd0pOSLp6etHVJKT39/f1LSiNTd95lhi3++TW59aqF6ZttsqTREbGN4E0/DWJmi4HFvb298/r68tlrYGCAFGSkpIunJ21d2i09Keni6Ulbl5TSsxrCO9M6juM4juM0G69RcRwnF3POuZSVz79Qc/wpXZO8E6/jjAEdbTW/7zDuqDiOk4t6nJRG4juOMzrCm34cx3Ecx3GaThI1KpI2Bc4CXg08ATxHWHzwCeBHwP3A2sCPzeyEeM5c4AzgkYyotwNPA38E/pQJ/5KZLZL0ALDEzA6NMt4KHGhmcyW9AziJ4Jj+G3ifmd06Jgl2GuaZh+6rut6JT9HvOCPzzIP3VH9+fIr+cU9He1aotN5RUair+iFwsZm9PYZtDbyZ4Khcb2YHSpoC3CLpCjP7XTz9MjM7rkzedOA+M5tR5ZKzJL3CzO4qC78f2NPMnpB0ALAQ2C1/Cp1CqTac3ofZO87o+PPTxvgU+mPJPsBzZnZeKcDMHjSzc7KRzGwlsBToyXm9LwKnlAea2Q1m9kTc/V9gi5zX4Xkb3vJgFLdseBLYUNhazCAwiBjMLWgQDQ7CYD5JRdinqLzipIsBJqVh5yKe5SKeHxtCiZQr4M9y0bS8RgXYEbh5tEiSNgC2A67LBM+RtHtm/zXx/zaSlmbCP2Bm18fflwPvl7TtCJd7N3DVCLrMB+YDbLnllqOpnp+Sl5zjq0eZ/3kyf0lOq2UUQzF3pQgpRdmnyLzSevukld+S0aVkY6nlNSFF3pMUnp9U0hME1P8st2uNSgqOympIOhfYndBP5URgD0m3EpyUs83s8Uz0Sk0/MHLTzyChb8vJVHBGJO1NcFR2Lz9WwswWEpqG6O3tHfuSooDCyCjgwSng/KJkFEMxd6UIKUXZp6i8kgop5bdkdDFLwkmB4u5JKs9PKukJguqTIPlaP2PJncDM0o6ZHQv0AxvHoOvNbBdCzcu7Jc0o4JrfAl4HrFYdImln4JvAQWa2PO9FujS85UEUV5WYBOoIW4vpBDoxOnML6sQ6O6Ezn6Simvfas6hySgiQWRp2LuJZLuL5UQeWSLkC/iwXTQpW/RWwtqT3ZcLWKY9kZvcD/0MYmZMLM3ueMMro+FKYpK2AHwDvNLM/572GM0ZU+2Jo0y8JxykUf37aGqk5W7NpedOPmZmkg4GzJH0U+DuwgsoOyXnACXFkD6zZR+X9wKOs2UflAjP7cpms84FTM/ufBKYBX43NRy80c9ElpzZ8CLLjNI4PQW5vvI/KGGJmjwGHVTl8bSbeSoZH/VwUt0pMqXKd6ZnfzwKbZ/bfA7ynNo0dx3Ecx2kGKTT9OI4zjpnSVd/3Tr3xHccZHSE61JytJn2k/SX9SdK9kj6WJ21eYjiOkwtfYNBxnCySOoFzgTcADwN/kHRlhYlWa8IdFcdxHMcZ7yipKfR3Be41s78ASPoOcBDQkKMiS2As/nhE0mxgdk9Pz7xFixblkrVixQq6u7tbLiMlXTw9aevSbulJSRdPT9q6pJSe/v7+JaVBHzN7e+03v/lNbr1q4UXrrfcgsCwTtDDOLwasWkdv/9j3E0nvBHYrn/esVrxGpUHMbDGwuLe3d15fX77BQQMDA6QgIyVdPD1p69Ju6UlJF09P2rqklJ4WsqyZo2LdUXEcx3GcdiCRtY6AR1h9QtUtYlhDuKPiOE7LmXPOpax8/oW6zpnSNck78jpOlqFkunL8AdhO0ksIDsphQMMPqzsqjuO0nHqdlEbPcRxn7DGzFyQdB1xNWK3kAjO7s1F57qg4juM4zjjHzLB0mn4ws58CPy1C1pg5KpIGgdszQQeb2QNxyvsvAS+K4V8q9RaWtACYR5hGfzLwGTP7djx2EbAn8GQ872kze62kuUBfqTexpCOAjxK8uBcIVVAnmNk/JV0LTC11ApLUB5xpZntJegNhLaHJxJWbzexXxd4VJxWeefgva65OKrH2Fi9tjUKOM4545sF7Kj8/PkV/a2nTUbxjWaOy0sxmZAMkbQZcSnBabpa0EXC1pEfM7Ccx2llmdqak7YAlkr4XFxGE4Dx8r9oFJe1PWGjwADN7JE46cxSwKfDPGG0TSQeY2VVlpy8DZpvZo5J2IlRZ9eC0J5Ue6DZ9yB2ncPz5cZpIs5t+jgUuMrObAcxsWVyIcAHwk2xEM7tH0tPABsDfapR/CqH25JEoYxC4oCzOGTHeao6Kmd2S2b0TmCJprbgmUEPYMytX29faFZcgqkFQrM7LsYT5YBAAGDkWU08HG4qpoeVLuwcdBGa5lmVflZ42IZX0FGKfhPIb5L+3ReXZQiji3g4ODsvobLyEK6KcLEJGw/ZJqOmnSMbyiZsiaWncrohhOwJLyuINxPDVkDQTuMfMsk7KGRmZl1S45o7AzaPodSPwnKS9R4hzKHBzNSdF0nxJA5IGli9fPsrl8qO45ZeS/d86XYqSkf3fUkprX+RYubSo9Lh9KtCG9smtSwH3pCiKSE9x+S0RbRqyj2FDzdmazVg6KivNbEbcDqnjvOMl3Qn8Hvhc2bETMzLfMZIQSa+MDs19kuaUHf4scGqV83YETgfeW022mS00sz4z65s2bdqoCcqLUcSXqZX9b50uRcnI/m8ppSrvHFXfRaXH7VOBNrRPbl0KuCdFUUR6istviWiTkH1SoNl1mHcBs8rCZhGaWkqcZWY7Emo1zpe0dh3y7wRmApjZ7bGPzFXAam0usZPsFODV2XBJWwBXAEea2X11XHdsUUfu6uZOoLNdmn0A1IEVcF8KUQVQAVXo7VYkpZKeQuyTUH6D/Pe2qDxbCEXc285OrLMzV7MPFFNOFiGjIfsYwbFpxtZkmv3UnQvMlTQDQNI0Qu3FF8ojmtmVhGaho+qQfxpwZnQ4SlTrGPJZwuggoi7rE/rJfMzMflfHNauitaestjkJUalKNYFqcMcZF/jzkyRmQ03Zmk1TO9Oa2WNx+PA3JK1LcBzPjuvmVOLTwKWSvhH3z5CUbbLZtUz+TyVtDFwVR/z8E7iDMIKnXJefSvp7Jug4YFvgk5I+GcP2Lesj47QJPgzZcRrHhyE7zWTMHBUzm1ol/DrgVVWOLSjbXwJsH3fnVrnURXErnXMxcHEV+XuV7c/K/P4soZbFcRzHccYfbdqnJY0GV8dxJjRTuur/ZmrkHMdxxh/+pDuO03J8cUHHyYu17Twq7qg4juM4znjHaMkcJ81A1qZtWmONpNnA7J6ennmLFi3KJWvFihV0d3e3XEZKunh60tal3dKTki6enrR1SSk9/f39S0pr1/XuvLP96qc/zq1XLWy45darrtsMvEalQeJIpcW9vb3z+vry2WtgYIAUZKSki6cnbV3aLT0p6eLpSVuXlNKzBt704ziO4zhOmrRmMrZm4I6K4zhtw5xzLmXl8y/UHH9K1yTvyOs4ieOOSoI89I3TseefGzWeuiaz1byTmqCR44wP6nFSGonvOKkSZtD3GhWnSdTipNQTz3Ecx2lzDBhqzz4qLZnwTdIpku6UdFtc4fjX8f+9kp6Mv5dKeq2kyZLOjsfukfSj7Fo+kgZj3DskLY5r9iBpuqSVGVlLJR0Zjx0t6fZ4/TskHRTDP5PR6eeSNm/F/XEcx3EcJ9D0GhVJrwEOBGaa2bOSNgImm9mjkvYCTjCzAzPxzwTWBbY3s0FJ7wJ+IGk3C/VcK+MqyUi6GDgW+Fw8/b7SsYy8LYBT4vWflDQV2DgePsPMPhHjfRD4JHBMI+kceurJNcI6pq7XiCgnUZ57/OE1O69JTN5si8onOI7jjCHe9FMcLwaWmdmzAGa2rFpESesA7wJeYmaDMf6Fko4G9gF+WXbKjcDOo1x/E+DfwFNR3lOZ3//KxOsmnZXqc2MQVjfNs7T74CAqycq5nHpbUKlQaLSgsKHhe5tnufvS8MScMgrRpQBKd7PV6/IW8vwAg/F/nqenKF2SoYj8VlDZVER+K8I+g6u0sDrySvvOTNuKUujnwJaS/izpq5L2HCHutsBDZQ4EwACwYzYgrpbcD1yZCd6mrOlnD+BW4K/A/ZIujBO3ZeV8TtL/Ae8g1KisgaT5kgYkDSxfvryGJCdAaQn2HEuxq+x/q0lFjyIo6t6qIBlF6ZIbKVeeLYwCnp8ogNx3pjBd0qCI/FZY2VREfivEPqmVtq2l6Y5KrMGYBcwH/g5cJmluDpFTJC0FHgc2Ba7JHLvPzGZktutjzcz+wFuBPwNnSVqQ0e8UM9sSuAQ4rkoaFppZn5n1TZs2LYfqTaT0pZ+jatDK/jvFUdS9tYJkFKFLIVgic0MU8PxEAeS+s4XpkgZF5LfC8mwR+a0Q+zSYopL+Y701mZbU65rZoJlda2afIjgDh1aJeh+wlaR1y8JnAXfG36U+KlsT3M9ja7i+mdlNZnYacFiV618ygl7jDgHKW1Xc2Yl1dibT7NMexXREHZg68je1FCSjCF2KsE8RNURFUMjzQ2jyyfv0FKVLMhSR3woqm4qqkcxrn5BP6mn2CZgNNWVrNk13VCRtL2m7TNAM4MFKcc1sBXAx8KXYtEMcubMO8KuyuE8DHwQ+Iqlq3xtJm0uaWen6ZXodBNxdW6rWpGPqemtsTptRqWq3TarjHcdxUqEVnWmnAufEYcQvAPcSmoGqcTJwJvBnSUME5+EQq9C92cxukXQbcDhwPbGPSibKBcCPgDPj0ONnCM1PpZE9/yNpe2CI4Lw0NOLHmRj46B7HcZLBDNp09eSmOypmtgR4bZVj1wLXloU9C3wgbpXOmVq2n+0cO6WKGvtUkZVEU4+6Jtc8M63jOI7jAG076sdnpk0QnxbfcRpjStekutf6cRwnbfwpdRynbfAFBp2JTLtO+Nba2Zwcx3Ecx3FGQO3qgY01caK42T09PfMWLVqUS9aKFSvo7u5uuYyUdPH0pK1Lu6UnJV08PWnrklJ6+vv7l5hZH8CMnXa0ay6/NLdetbDJjjNWXbcZeNNPg5jZYmBxb2/vvL6+fPYaGBggBRkp6eLpSVuXdktPSrp4etLWJaX0rIZZS+Y4aQbe9OM4juM4TrJ4jYrjOE6GOedcWvfIIe/E6ySBz6PijCce+sbpNc/F4sOhHWeYepyURuI7zpjhTT/OeKIWJ6WeeI7jOI7TCkasUZE0Dfhl3N0MGCRMOQ+wC3BrlHE/8E4z+2fm3KXA3WZ2WCbsIuANwEvN7FlJGwEDZjZdUgdwNmHWWCNMb/82M7tf0gPAv2P448CRZva4pPWAcwgz3Qr4HfABM3tS0nTgj8CfgMnAAHAicHWV9LwO+AWwVkzT9+KiiY7jOI6TNIa17TwqIzoqZracsGgfkhYAT5nZmXH/qbhqMZIuJqxa/Lm4/3LCApB7SOqOiwuWGASOBr5Wdrk5wObAzmY2JGkLIHve3ma2TNLngY8TFiA8H7jDzI6M1/1v4JvAf8Zz7jOzGXFBw2uA12d0Lk+PgH3M7ClJXcBvJV1lZv870j2qxjMP/2XN5bAl1t7ipY2Ic9qY5/72SMW8MnmTntYo5DjO+MPwpp9RuBHIlqqHA98Cfk5YhTjL2cDxFVY4fjHwmMXxVWb2sJk9UeFa1wHbStoWmAV8JnPs00CfpG2yJ5jZIHBTmY6UxTEzeyrudsWtcfe0kmfbpt6ukxPPK46Ti0FgEDGYW9AgGhyEwRySUpHRRuR2VGJtRT9wZSZ4DvAd4NsEpyXLQ8BvgXeWhV8OzJa0VNIXJfVWueSBwO3AK4Cl0QkBVjkkS4Edy3RcG9gN+NloaYlNVn8DrjGz31eJN1/SgKSB5cuXjyTSqYQNFeL5qwhVyOONJkhB97YIirBPEekxwKQk7FxUfst9b20IFXVv86pCEfZR2f/WSWmpjCFrztZk8jgqU+JL/XFgU0LTCpL6gGVm9hChf0uvpA3Lzj2N0F9k1fXN7GFge+BkYAj4paT+zDm/jtd7UTy/FraJ5/yVUFtz20iRzWwwNg1tAewqaacq8RaaWZ+Z9U2bNq1GVRzHcZyxwcr+t05KK2WYWVO2ZpPHUVkZX+pbExy/Y2P44cAOsQPsfQTH4tDsiWZ2D6Hm421l4c+a2VVmdiLweeDgzOG9zWyGmR0ZO+3eBcyInXABiL9nxGMQ+6gA2wCzJL25loRF+b8G9q8lvlMn6ghbTor6Mi3kyz8VCrq3RVBIcVZAegTILAk7F5Xfct9bdWBF3du8qpDfPp1AJ0ZnTl3o7MQ6O6Ezh6RUZLQRuUs0M3ua0LH1I5ImE5yPV5rZdDObTuijUt78A6Hj7QmlHUkzJW0ef3cAOwMPjnDde4FbgFMzwacCN8dj2bjLgI8RamsqImljSevH31MIo5PurhZ/VFThsasU5jieVxzHyY0NN5WO9dZkCpnwzcxukXQbwRF4xMwezRy+DniFpBeXnXOnpJuBmTFoE+AbktaK+zcBXxnl0u8GzpF0X9y/MYZV4ofAAkl7mNn1FY6/GLg49rnpAC43sx+Pcv2q+Ogep1Z8dI/jOLkxJubw5CxmtqBsf2rZ/uz487/LwgcJc5YAzC079pbM759RpbNrrJmpFP4EcESVYw8AO2X2jTD3S2l/QVn824BqHXjHHeqaXPPMtI7jOI6TKj6Ffpvi0+I7TmNM6ZpU91o/jpMEiYz4Kxp/whzHcTL4AoOOkxbuqDiO4zjOuKc1c5w0A7Vr55uxRtJsYHZPT8+8RYsW5ZK1YsUKuru7Wy4jJV08PWnr0m7pSUkXT0/auqSUnv7+/iVm1gewy8u3t6suOC+3XrXQ89p9Vl23GXiNSoOY2WJgcW9v77y+vnz2GhgYIAUZKeni6Ulbl3ZLT0q6eHrS1iWl9EwU3FFxHMdxnPGO0bZrhLmj4jiOUzBzzrm0rpFDEEYPeUdep3HMR/04E497T/8I9tyzNcXV5LXY9qQvjrFGjjM+qNdJafQcx5kIuKPiVKVWJ6XeuI7jOE7xWJuO+klj9bIGkLSZpO9Iuk/SEkk/lfQySXdI2k/S0rg9JelP8fdPJT0gabOMnHMlnSxp18w5t0o6pJXpcxzHcZy6MGvO1mTGZY2KJAFXABeb2WExbBdgUwAzuxq4OoZfC5xgZgNx/xjgTOAISTOBPYBZQBfQZ2YvxHWJbpW02Mwaqo997rGH1jSoxOQXb9WIOMcZkcEn/7FGWOd6G7ZAE8dxnGIZl44KsDfwvJmtGjRuZrdKml7DuQuBoyTtDXweOM7Mngeez8RZm7wrqVfyOtu0R7bjOI7TWkJlR3t2ph2vTT87AUsaOdGCJd8HfB/4k5ldVzomaTdJdwK3A8dUq02RNF/SgKSB5cuXN6JG87Eh1KIlussZBAYRgznlqAhlEsLTMzYUkd8MMCnn10tBDA6iwUEYzPsEpUFS97YgWpP3m9Ts04IP7vHqqOTCzJYCdwBfLQv/vZntCLwKOFnS2lXOX2hmfWbWN23atDHX13Ecx3EmKuO16edO4K05ZQzFbQ3M7I+SniLU3AzkvE4aqCOZL5ZOIG/LWjES0sLTMzYUkd8E6TTddnYmc2+LIKl7WxAtS00CNeZjwXh1VH4FfF7SfDNbCCBpZ2C9RgVKegnwf7Ez7dbADsADDWsoVexM6zhjgXecdRynXYcnj0tHxcwsDh8+W9JJwDMEp+JDOcTuDnxM0vOEmpb3m9myRoX56B7HcRzHyc+4dFQAzOxR4G0VDu1UFm+vKufvVbb/LeBbBannOI7jOM3D2ncK/QnZmdapDU1ea0ziOo7jOE6tjNsaFWfs8bV7HKcxpnRNamhRQsfJRZt1Si7hT4bjOE7B+CrITiuwNnVUvOnHcRzHcZxkUbt6YGONpNnA7J6ennmLFi3KJWvFihV0d3e3XEZKunh60tal3dKTki6enrR1SSk9/f39S8ysD2Dnl21rP/7yF3LrVQtbH3Doqus2A2/6aRAzWwws7u3tndfXl89eAwMDpCAjJV08PWnr0m7pSUkXT0/auqSUntUwa9umH3dUHMdxEmXOOZfW1Sl3Stck7x/jtB3uqDiO4yRKvSOH6o3vtBltOo+KOyrOmPPIJediLzw/YhxN6qLnHcc2SSPHcZw2pE2bfpIc9SPJJH0xs3+CpAWZ/fmS7o7bTZJ2zxy7VlJf/H20pNsl3SbpDkkHxfCLJN0vaWncbojhB8W4SyUNZOU6jTOak1JrHMdxHGfikWqNyrPAWySdVr7ejqQDgfcCu5vZMkkzgR9K2tXMHs/E2wI4BZhpZk9KmgpsnBF1opl9r+y6vwSujGsJ7QxcTlicsC5W3v+nylVw6mDKS7avV5zjNIVnHryn8heZxNpbb9d8hRzHqQPD2rTpJ8kaFeAFYCFwfIVjJxGcjGUAZnYzcDFQ3m6wCfBv4KkY7ykzu3+ki8Y4pZK6m0ZX666WWdo0EzltQrVq4zatTnactsKAIWvO1mRSdVQAzgXeIWm9svAdgSVlYQMxPMutwF+B+yVdGOc9yXJGpunnklKgpEMk3Q38BDg6dyqKwIZyOzkGmNSg5xUYBAYRg7k0KQ61WoEisSFUgJ2LyCtFUER+K4qidCkkvw0OosFBGEzlKcpJQfkt970t6vkpiELySkLpaTXJOipm9i9gEfDBBs8fBPYH3gr8GTgr28+FUCszI27vyJx3hZntABwMfKaS7NhHZkDSwPLlyxtRb5yisv+O49SDP0HOmGLWnK3JJOuoRM4G3k1ohilxFzCrLN4s4M7yky1wk5mdBhwGHFrrhc3sOuClkjaqcGyhmfWZWd+0adNqFdk46ghbHhGAzHIWkFb2v7WkoUVBqAMrwM5F5JUiKCa/FUNRuhSR39J6ggqgoPyW+34U9fwURCH2rTM9BpgNNWVrNmlYtQpm9g9Ch9Z3Z4K/AJwuaRqApBnAXOCr2XMlbR472paYATw40vUkbStJ8fdMYC1gIlWZjEgn0InR2WpFnLFBVV7l1cKd+unsxDo7odOfIseplVRH/WT5InBcacfMrpTUA9wgyQgdZo8ws8fKzusCzpS0OfAM8HfgmMzxMySdmtnflVDjcqSk54GVwJxM59raUUfVUT+Okyo+ssdxxjOtaZZpBkk6KmY2NfP7r8A6Zce/Bnytyrl7ZXb3qRJnbpVLnx63XPgQ5NXRpK6aJnxzHMdxnHKSdFSc9sJnnHUcxxl72nUeFXdUHMdxEmVK16S6FyV0JiileVTaEM/VjuM4ieIrITuOOyqO4ziO0wZY204Qp0YGtTgQZ7qd3dPTM2/RokW5ZK1YsYLu7u7RI46xjJR08fSkrUu7pSclXTw9aeuSUnr6+/uXmFkfwCu3mW4/PO0TufWqhW3nvGfVdZuB16g0iJktBhb39vbO6+vLZ6+BgQFSkJGSLp6etHVpt/SkpIunJ21dUkrPRMEdFcdxHMdpB9q06ccdFcdxnDZmzjmX1j1yyDvxjkOsNSsbNwN3VJxxwSOXnDvqpHEQJo7zeVscZ5h6nJRG4jvOWJPEnO6SNpV0qaS/SFoi6UZJh0jaS9KTkpZKulvSmZlz5kr6ezxW2l4habqklWXhR8ZzHpD0/YyMt0q6KP4+SNJtMf6ApN2bfiOcqtTipNQTz3Ecp90ws6ZszablNSpxEcAfAheb2dtj2NbAm4EngOvN7EBJU4BbJF1hZr+Lp19mZseVyZsO3GdmM6pccpakV5jZXWXhvwSuNDOTtDNhMcQdGknTPX9dXrEGrkOw3aZNWG3ZcVrEMw/eU3m9EcnXEnKcsaZN+6ikUKOyD/CcmZ1XCjCzB83snGwkM1sJLAV6cl7vi8Ap5YFm9lRmAcJucqzUXa2ZsE2bDx1nmGpfWz4NguM4DdLyGhVgR+Dm0SJJ2gDYDrguEzynrInmNfH/NpKWZsI/YGbXx9+XA++XtG2FaxwCnAZsAryp5hSMAwxAAjOUVw7kkpEUpS+QPCtbFyRDlOyUwvdDGiST3xKzzypd2oHE7m0RtMQ+ZtiQ16g0BUnnSrpV0h9i0B6SbgUeAa42s8cz0S8zsxmZbWUMv68s/PrMOYPAGcDJ5dc2syvMbAfgYOAzI+g4P/ZjGVi+fHmO1DYRafX/DhAKlBTuiMr+O2nh9nHGBWbN2ZpMCo7KncDM0o6ZHQv0AxvHoOvNbBdCzcu7Jc0o4JrfAl4HbFnpoJldB7xU0kZVji80sz4z65s2bZz0OSllrpyZLJUXe1EYBXz5qCP3l6CV/XcCqeS31OyTih6FoA6sgGcoJdrKPgmQQs74FbC2pPdlwtYpj2Rm9wP/A5yU94Jm9jxwFnB8KUzStrFjL5JmAmsB46S6ZHQEKGezT1uSSgHZhoV1W+H2ccYDNtScrcm0/KmLHVgPBvaUdL+km4CLqeyQnAe8Lo7sgdBHJTsM+bUxfJuy8A9WkHU+q/fRORS4I/ZtOReYk+lcWxcdVbyBauGO0zZUa1r0JkfHcRokhc60mNljwGFVDl+bibeS4VE/F8WtElOqXGd65vezwOaZ/dOB02vTeGR8CHLxaFJXzRO+Oa3DhyA7TmswaMkcJ80gCUfFcUbDZ5t1HMcZATPwUT+O4zjOeGNKV33fo/XGd5yxxnOk4zhOG+MLDE4cvOnHcRzHcZx0adMp9NWuHthYI2k2MLunp2feokWLcslasWIF3d3dLZeRki6enrR1abf0pKSLpydtXVJKT39//xIz6wPYafqW9v1T/yu3XrWww7wTV123GXiNSoOY2WJgcW9v77y+vnz2GhgYIAUZKeni6Ulbl3ZLT0q6eHrS1iWl9KxOa2aNbQbuqDiO4zjOeMfA2nTlW3dUHMdxnBGZc86lrHz+hbrOmdI1yTvyOoXgjoozoXjkknNHnThOk7p83hbHyVCvk9LoOU5O2rQz7ZjOoyJpsGwq++kxfHdJN0m6O27zM+cskPRIjH+XpMMzxy6K0+yX5N0Qw+dK+kom3hGSbpN0Z1yJ+ZuS1o/HrpU0kInbJ+na+HvXjOxbJR0ylvfHaT61zG5bSxzHcZzkaNPVk8e6RmWlmc3IBkjaDLgUONjMbo4rFF8t6REz+0mMdpaZnSlpO2CJpO/FhQQBTjSz71W7oKT9CYsNHmBmj0jqBI4CNgX+GaNtIukAM7uq7PQ7gD4ze0HSi4FbJS02M/80cJwm8syD96xZIEo+Rb/jTEBa0fRzLHCRmd0MYGbLJH0UWAD8JBvRzO6R9DSwAfC3GuWfApxgZo9EGYPABWVxzojxVnNUzOzpzO7a5Fyte+jpp1bb71hnah5xjjNxqPTV1qYjGhynGAzzpp+GmJJpSrkihu0ILCmLNxDDV0PSTOAeM8s6KWdkZF5S4Zo7AjePoteNwHOS9q5wzd0k3QncDhzTNrUpNoSKWKK7ABlGTg8QGAQGEYM55aREIesLt2gZ9kp6FJLfEsEAk3Ln20Jos3vbbmVTIXllcBANDsJgHSVcWJWwLZt+xtpRWWlmM+JWT3+P46Oz8Hvgc2XHTszIfMdIQiS9Mjo090maU3b4s8Cp5eeY2e/NbEfgVcDJktauIHe+pAFJA8uXL68jWa1DZf/zyMn9QpXClluT7P/xTUr2KUpG9v+4p5Rfc+Zbv7drklLeL6RsKiCvtJuN89KKRQnvAmaVhc0C7szsnxWdhUOB8ys5CyNwJzATwMxuj31krgKmZCOZ2a9i2KsrCTGzPwJPATtVOLbQzPrMrG/atGl1qNY6rOx/Hjm5/elCvPKiUpQGKdmnKBnZ/+OeUn7NmW/93q5JSnm/kLKpgLzS6D2xoaGmbM2mFY7KucBcSTMAJE0DTge+UB7RzK4kNAsdVYf804AzJW2RCZtSJe5ngY+WdiS9RNKk+HtrYAfggTqunS7qwNQBymnyAmQU8eXTCXRidOaUkxKFvHiKsHFBehSS3xJBgMzS+MJts3vbbmVTIXmlsxPr7ITOdirhGqfpnWnN7DFJRwDfkLQuwa5nxynpK/Fp4FJJ34j7Z0jKNtnsWib/p5I2Bq6KI37+SRjNc3UFXX4q6e+ZoN2Bj0l6HhgC3m9my+pPZcA7zzpOg0gVR/04jlMNn0K/Icys4pvazK4j9AGpdGxB2f4SYPu4O7fKpS6KW+mci4GLq8jfq2x/Vub3t4BvVbmG4zhNwochO04DtEsH6zLapO7QcWpDk7oKieM4juM0B59C35lQ+NT4jlM/U7omNbTWj9M8Qj9gb/pxHMdxJiC+uOA4oU1XT/amH8dxHMdxkkXtWlU01kiaDczu6emZt2jRolyyVqxYQXd3d8tlpKSLpydtXdotPSnp4ulJW5eU0tPf37/EzPoAdtzyxXb5h47OrVct7HTC51ddtxl400+DxOHUi3t7e+f19eWz18DAACnISEkXT0/aurRbelLSxdOTti4ppaecdq148KYfx3Ecx3GSxWtUHMdxnKYw55xL6xo9NKVrknfkrRWjbedRcUfFcRzHaQr1DnEeKf6i397C84Mjv5i7Ojs4cvfeuq45fjFv+nEcx3GcVBjNSak1jpM+LXdUJJ0l6UOZ/aslfTOz/0VJH5a0o6RfSfqTpHskfUIKi39ImivJJL0+c97BMeytmbCNJD0v6ZgyHR6Q9P3M/lslXTQ2KXYcx3GcMWBoqDlbk2m5owL8DngtgKQOYCNgx8zx1wI3AlcC/2Nm2wO7xPD3Z+LdDhyW2T8cuLXsWv8J/G88Vs4sSa9oPBmO4ziOk58Vz72w2lYzZs3ZmkwKjsoNwGvi7x0JKx3/W9IGktYCXg7sDPzOzH4OYGZPA8cBH8vIuR7YVVKXpKnAtsDSsmsdDnwE6JG0RdmxLwKnFJaqAhkEBhGDeYTYELKh/J2tipBREO20lq4BJpG7CCjAPoXoMjiIBgdhMFeuLSa/FZD3i7KPxS0vufN+G5YHuXnumdW3IuQ4hdByR8XMHgVekLQVw7Unvyc4L32EmpLtgSVl590HTJX0olIQ8AtgP+AgQg3MKiRtCbzYzG4CLgfmlKlyOTBT0raj6SxpvqQBSQPLly8fOS5FvFBV9r8VEobPT0VG9n+rdcltY2n1/+Ncl9Tsk1uXguyDVIiNs/9bJaN0fjt9MIxr4lo/zdiaTcsdlcgNBCel5KjcmNn/XR1yvkNo/jkM+HbZsTkEZ6QUr7z5ZxA4Azh5tIuY2UIz6zOzvmnTpo0clyK+oKzsfyskDJ+fiozs/1brkr8mxFb/P851Sc0+uXUpyD5FVJ0XkZ6U7OM4o5HK8ORSP5VXEpp+/o/QRPMv4EJgE+B12RMkvRR4ysz+FfvUYmY3SXol8LSZ/Vmrf7kcDmwm6R1xf3NJ25nZPZk43yI4KncUnL5cdAK5iwN1FFOgKBXftr0KSEExbb8F2KcQXTo708lvBeT9ouxTVO1Dbk3asDzIzeS105JTN9Y+zXBlpJLLbgAOBP5hZoNm9g9gfULzzw3AJcDupVE9kqYAXwa+UEHWx4CPZwMkvQyYamY9ZjbdzKYDp1FWq2JmzwNnAccXlzTHcRzHqZ3uyZNW22pmyJqzNZlUHJXbCaN9/rcs7EkzW2ZmKwn9Tk6V9Kd47A/AV8oFmdlVZvbrsuDDgSvKwr5P5dE/55NOTZPjOI7jTGiSeCGb2SDworKwuWX7twN7VTn/IuCiCuElGd+rcOw2wogiYg1LKfxZYPNadXccx3GaT1dnR00z004krE2bfpJwVBzHcZz2Z0rXpLrX+qnGxJkav0ZaNMdJM3BHxXEcx2kKvsCg0wjuqDiO4zjOOMdo36Yftetqi2ONpNnA7J6ennmLFi3KJWvFihV0d3e3XEZKunh60tal3dKTki6enrR1SSk9/f39S8ysD+AVm29il85762inFELvp7+26rrNwGtUGsTMFgOLe3t75/X15bPXwMAAKchISRdPT9q6tFt6UtLF05O2LimlZ6LgjorjOI7jtAMtmOOkGbij4jiO44wb5pxzad0jhyZEJ16ztu2j4o6K4ziO0zQW/faWUec/gTAHSqUhyPU4KY3Ed9LDHRXHcRynadTipNQTz8nQpoNj2nbaPkkHSzJJO2TCdpV0raR7JN0s6SdxEUMkLZD0iKSlmW39liXAcRzHcerBhpqzNZl2rlE5HPht/P8pSZsClwNvN7MbACTtDmxDWDsI4CwzO7MVyjqO4zgOwIrnVm+uqmthwjakLVMvaSqwO7A3sBj4FHAccHHJSQEws9+OpR4WlAGzXMu7DwJhgXijM4cclXRqMc9nlOhq9MbY0HB6ciw1X1Ilj32KkFFUelZ97eSRUQRFpGdwcNU9NYDOBnN/lJNHRlHPYCEUlVcK0oUU9CiC559bfb9rcn45jcpoCKNd50VrS0eFsNLyz8zsz5KWS5oF7AhcPMp5x0s6Iv5+wsz2rhRJ0nxgPsCWW25ZXZo0/D9XBlLmf2Ny8ktYXU6rH4ei0rPKRnnsU4CMlOxTpIw86VHZ77xy8t3bYqW0+t4WrUurywOHYISh9uzX0wZucEUOB74Tf38n7q+GpN9L+qOk/5cJPsvMZsStopMCYGYLzazPzPqmTZtWXYvSiyu3l2tl/1shYfj8FAqlotJTyEJeBchIyT5Fycj+zyOjKDkpWCiVe1ukLimUB05703Y1KpI2BPYBXinJgE7Cs3QxMBP4EYCZ7SbprcCBY6ZLuFBuOaGqOb+cVAqUhpt7sqijkPQUokoBMopKTzJV8EWkp7OzmHtSgJyinsFCKCqvFEEq+a0IimqmaWpzz+q0a9NPG+WyVbwV+JaZbW1m081sS+B+4BpgrqTXZuKu0xINHcdxHKcK3ZMnrbZNdNrxDhwOnF4W9v0YPgc4XVIP8DdgGfDpTLxsHxWAg83sgTHU1XEcx3EKwFoydLgZtJ2jUqlviZl9ObO7Z5XzFgALxkYrx3EcB8KMs7XOTOvUSZs2/bSdo+I4juOkS6Vp8ethStekutf6ccY3bkHHcRxn3DAhFhhsBAPz1ZMdx3Ecx0mWNu2jonYdzjTWSJoNzO7p6Zm3aNGiXLJWrFhBd3d3y2WkpIunJ21d2i09Keni6Ulbl5TS09/fv8TM+gBesek0W/T2/XLrVQuvOvvbq67bDLxGpUHMbDGwuLe3d15fXz57DQwMkIKMlHTx9KStS7ulJyVdPD1p65JSelangMkrE8UdFcdxHMcZ5xhgbdr0446K4ziOM+GYc86ldY8eKu/IW4QMZ3TcUXEcx3EmHPU4GNXiFyGjULzpx3Ecx3GcJDHDfPXk5iDpFEl3SrpN0lJJu0k6UNItkm6VdJek98Z4S+M2mPn9wSjnbEmPSMOrZkmaK+nvUdY9kq4urf0j6dx4/l2SVmbkvbVV98JxHMdxJjpJ1ahIeg1hNeOZZvaspI2AbuAKYFcze1jSWsB0M/sT8Ll43lNmNiMjpwM4BPg/wpT5v85c5jIzOy7G2xv4gaS9zezYGDYd+HFWnuM4juMkT5s2/aRWo/JiYJmZPQtgZsuAfxMcquUx7NnopIzEXsCdwNcIixFWxMx+DSwE5ufWvOIFhpAN5Z+EZ3AQDQ7C4GDLdTEKWOy+KD2kJHQpgkFgEJHDwm3JYNzyUEheKeIZbEMKKQ+ee2Z4a5Tnn1t9m6iYNWdrMqk5Kj8HtpT0Z0lflbSnmf0DuBJ4UNK3Jb0j25xThcOBbxNqYt4kqWuEuDcDO9SjpKT5kgYkDSxfvrx6vLL/jVKEnKJ0QQpbTl0K0SP7v5W6FEJhFkqGYlJSgIUKyCupWScVPYooDxxnNJJyVMzsKWAWoYbj78Blkuaa2XuAfuAm4ATggmoyJE0G3gj80Mz+BfweGGm6vrqfMjNbaGZ9ZtY3bdq06vHK/jdKEXKK0qUIj7qYWhlb/X8rdSmEwizUZhRgoQLyilunCi36wnYqYZgNNWVrNkn1UQEws0HgWuBaSbcDRwEXmdntwO2SvgXcD8ytImI/YP0YF2AdYCXw4yrxe4E/FqT+6qijmIKtszO/nIJ0KeTbadQKsRpEQDEFZAG6FEEn0G6vwSJS01mAjELyShHPYIGkoksydSldk1utgTOGJOWoSNoeGDKze2LQDOCvkvYys2szYQ+OIOZw4D1m9u0osxu4X9I6Fa63J6H2Zu9CEuA4juPUx+S1W61Be2CAr57cFKYC50haH3gBuBf4L+Drkr5OqBlZQZXalOiM7A8cUwozsxWSfgvMjkFzJO1OqGm5HzjUzMamRsVxHMdxmkUCAwPGgqQcFTNbAry2wqE3jnLe1Pj/aWDDCsffktm9aBRZDwA7jaKq4ziO4zhNIClHxXEcx3GawZSuSXWv0zMWMorE2rRjszsqjuM4zoSjiMUB01pg0Nq26SeNIQ+O4ziO4zgVULtWFY01kmYDs3t6euYtWrQol6wVK1bQ3d3dchkp6eLpSVuXdktPSrp4etLWJaX09Pf3LzGzPoCXb7SeXXBQpS6exfPaC3626rrNwJt+GsTMFgOLe3t75/X15bPXwMAAKchISRdPT9q6tFt6UtLF05O2LimlZw3adHiyN/04juM4jpMsXqPiOI7jTDjmnHNp3SN2yjvPFiGjONq3M607Ko7jOM6Eox4Ho1r8ImQUhdG+w5O96cdxHMdxnGRpmqMiaVDSUkl3SFocp8lH0nRJK+Ox0nZkPHa0pNsl3RbPOyiGXyTp/hj3ZkmvyVznBEl3x2N/yMi6VlKfpN/HYw9J+nvmmpdIel9Gzm7xul3NukeO4ziO0xBGaPppxtZkmtn0s9LMZgBIuhg4FvhcPHZf6VgJSVsApwAzzexJSVOBjTNRTjSz70naF/g6sLOkY4A3ALua2b8kvQg4JCvXzHaL8ucCfWZ2XNzfFLhR0veA5cBXgPeb2fNF3QDHcRzHGTPadNRPq/qo3AjsPEqcTYB/A08BmNlTpd9lXAdsG39/HNjLzP4Vz/kXcHEtCpnZXyWdCXwB+ANwm5n9tpZzqwsdQsQl2ZWj8mpwcFhOZ4ML3xelizMmDAJECzVo4bZkMP7Pc09CnheYoYYVKeAZdCrz3DPDvxtdSfn551bf75rcuD5OcjTdUZHUCfQD52eCt5G0NLP/AeAG4K/A/ZJ+Cfwgzl1Szmzg9lh7sq6Z/SWHeucBRwF7AVUHuEuaD8wH2HLLLasKU+Z/Hj+3CDlF6VI6t+ECH4arDnM4TIW8fArSpRiKslA6FJOS0n3JIUka/t9gZ8PUrJOKHoWUB05BGOajfnIzJTojPcAfgWsyx9Zo+gGQtD/wKoJjc5akWWa2IB4+Q9KpwN+BdxehoJkNSfo6oUlo+QjxFgILAXp7e6uWF0YxBUoRcorSxRkr3EKVKeB+mOVyUkpauHUcpzU08zOy1Edla8Izf+xoJ1jgJjM7DTgMODRz+EQzm2FmbzCzO2Izz1OSXppTz6G45UcdmDryf613dmKdnfmqnAvSRRTw9VSUHnlrUwrSpQg6gc42a/Yp4qXeSb5mHygorxTxDBZIKg5TIeWBUxxmzdmaTNNLaDN7Gvgg8BFJVWt0JG0uaWYmaAbw4CjiTwPOjc1ASJpaGvXjOI7jJMjktYe3RumavPo2ETEwG2rK1mxa8ilpZrcAtwGHx6BtyoYnfxDoAs4sDTUG5gD/NYrorwG/Bv4g6Q7geoqqHXEcx3EcJxeS/lPSnZKGJNW02FHT+qiY2dSy/dmZ3SlVTtuniqy5VcKNMGrnCxWO7VW2fxFwUYV4FcMdx3EcJ11a0yzTAHcAbyFMK1ITPoW+4ziOM+GY0jWp7nV6xkJGoYyDeVTM7I8AUu29m9xRcRzHcSYcRSwOOHYLDCbPRpIGMvsL42jYMcEdFcdxHMcZ50x96Q7sfvnvmnMxaZmZjTTX2C+AzSocOsXMflT35dp1tcWxRtJsYHZPT8+8RYsW5ZK1YsUKuru7Wy4jJV08PWnr0m7pSUkXT0/auqSUnv7+/iUlh6Gvr88GBgZGO6UQJC0ZyVGpUca1wAlmNqrSXqPSIHGW3MW9vb3z+vpy2YuBgQFSkJGSLp6etHVpt/SkpIunJ21dUkrPRKH1M105juM4jjMhkHSIpIeB1wA/kXT1aOd4jYrjOI7jtIg551xa98ih8dyJ18yuAK6o5xyvUXEcx3GcFlGPk9JI/HbAHRXHcRzHcZJlzB0VSYNl0+N/LIZfmx2HLakvhq0jaXlpvZ7M8R9KmhN/HyBpQNJdkm6R9MVMvPlx2v27Jd0kaffMsYrXzOzvKuk6SX+Kcr8paZ0xuTGO4ziO44xKM/qolFZNrsQmkg4ws6tKAWb2dOxccwhwMYCk9YDdgbdL2gn4CvAmM7tbUicwP8Y7EHgvsLuZLYuLGv5Q0q5m9ni1a8ZzNwW+CxxmZjfGsLcC6wJPF3AfHMdxHMepk1Y3/ZwBnFIh/NvAYZn9Q4Cr48rLHwU+Z2Z3A5jZoJl9LcY7CTjRzJbFYzcTnJ1ja7jmscDFJSclnv89M/trQykrksFBNDgIg4Ot1qS9eOH54a3FDAKDCLewM5FY8dwLa2xFyHHai2Y4KlPKmn7mZI7dCDwnae+yc64GZkqaFvcPIzgvADsBS6pca8cKxwZi+GjXHEnuasTmpQFJA8uXL68e0YaQDUHOZbFV9r8RDDCJ3NP7FZCeImQUlp4CKMbJKMLKJV3yUcS9Lco+Frc8FGKflD4WCipXCiGl+5IQ+Z5ip5xmOCorzWxGZrus7PhngVOzAWb2HHAl8FZJGwG9BOelKNa4Zj2Y2UIz6zOzvmnTpo1+Qk6s7L/TjriVHcdxKtHqph/M7FfAFODVZYdKzT9vBX5kZqX6+TuBWVXE3VXh2Kx4zmjXHEluY6gDUwco523u7MQ6O6Gzs3FVAJnl9/SLSE8BMgpLTwF0Ap0YjVunGBnDcvJRxL0tyj4i/9dpIfe2gGewMIoqV4ogpfuSEP65USwJ5HQg1HB8tCzsWmA7Qt+Rb2fCzwA+LullAJI6JB0Tj30BOL3UZCRpBjAX+GoN1/wKcJSk3UoBkt4SO9k67cikruHNcZym0z150hpbEXKc9qIZFp0iaWlm/2dm9rFsBDP7qaS/l4UNSfoe8DbgN5nw2yR9CPh2HDpswI/jsSsl9QA3SDLg38ARZvZYuVLl1zSzv0o6DDhT0ibAEHAd8LMcaXccx3EcJwdj7qiYWcU6QTPbq2x/jWYXM/sQ8KEK4T8mOicVjn0N+FqVYyNeM4742aPSuY7jOI7jNJ9Umn4cx3Ecx3HWwB0Vx3Ecx2kRU7rqa9ioN347MPFS7DiO4ziJMJ5XQm4WXqPiOI7jOE6yyMxHfOchjhx6cIQoGwHLRhGzHvDkKHFGk1OEjFrkeHoak+PpaUxOs9KTki6ensbkTMT0bGdm60FN76Ii2drMNm7StcDMfBvDDRioIc7CvHKKkFGLHE+Pp6cd05OSLp4eT0+R6WmHzZt+0mBxIjKKkpOKjKLkpCKjKDmpyChKTrvp4ukZOzmpyChKTlG6JI07KglgZrkzWxEyUtLF05O2Lu2WnpR08fSkrUu7pWc84I7K2LMwITmpyChKTioyipKTioyi5KQioyg57aaLp2fs5KQioy3wzrSO4ziO4ySL16g4juM4jpMs7qg4TpOQpFbr4IyM22jsSOXeSvKJTscZ7qjkQNJGrdYhi6SKC0C2glQKpaJpJF2S1pc0xdqwnbUoO0sqpCxqVB9Jm0qaWoQORVHEPSnQPo3e150kvR/AzKzB5+dNkgqZvlXS64BD8pSVknaX9OkCdNkgr4yJgjsqDSLpAODTeTJbERlV0r6SPgpgZoMFFW4NyygV9o0WSlFGV6PXr6RLThmvivd4D6g/XZJmA98CrpJ0WB6dJK0taZ34u9F7u42krXPm22mSXgS57by1pG2jnKFG8p2k/5D0lnifacQZlPQm4FLgO8CRkjobfKGuK6k0+Vaj92SH+HLfKMc92VTSppDbPttKmiFJDeR7RWdgO2BPSfMb0UfSG4AzgL/Vq38FWfsBXwMeNrPBHKK6CJO15bHzG4DzJPVLmpxDl4lBqydyGY8b8AbgNuD1cX9SAzLeAtwL7A10NqjHXoQH+E/A6ZnwjgZk7QG8r6RLgzIOBC4E9siEqU4ZrwdOArbMaaM3El4+e+SQcSBwS0zTd4Dj6zx/P+AOoA84DPgJ0NegLm8CfgRcCxzVoIz9oz4XxjxT9z0GDgBuBC4H/r8c9/YA4HbgSuBWoKve/BJtvBT4fLw3b6s33wGzo41fBbwZ+CWwfoP2uTrem/kN3pP9gD8C5wGPA5s0cE8OAAaAK4Af5rDP/sCdwA+A+0vlQR33tRR//XhfLwbeV499og5/BHaN+1sBb8hxb1cAh8b9rhz3ZreYZzZv8Pw3xedwf2B6o3pMpK3lCoy3LWauh4FXxP3pwCnAenXI2CoWiFcC3wdeR52OAWFByQOB+YSpln8NfCFzvGZ5QD/wDPA94AQacFaAnQjTPV8B/DewewP39jXAYCwcP0yDzgqwC/APwgv5Kw3qsjPhBbpL3H8z8NU6zp8S0/CuTNipJRvV+fIpORj9BCf5r8B+DdzbPwOvi/ufAb5Zp433Ae4G9o157lfAhxu4t/9BcJR2j/uXAovqlDEDuAl4Tdz/FHB49uUxWtoIX8YfBmbH/c0IL/nzoqxX1qjLGwkfLq8Fdo+/168zPa+N9tk77p8HvBJYq9b8QnDy/0j4+OkCriI6O3XqskfUZY+4fwXQW8f5ewHnADsy7GwdDHwdOC4Tr2qagGkE5/Prmf2bgPc3kJ794rN8GfALYrlCHR+IwLaEj8v1gKnA50p5rc5neSPgBqC/LLyuD7qJtnnTT/1sAUwGHo1VdpcDK81stTUbqlUJxvAngf82szcD1wMfB3Yvb/IYQcZBwCVm9mPg+2a2DHgP8CpJZ8CqqvT1RkuMpLUJhdongHMJjteHJXVafVXP/wDeQagNEXCgpN0z16lFziTgKIJzsRUwR9KWNV4/y9+AYwhf2g8A7yzTpZbq2meBr5nZrXH/D0CfpO2y51eSFe3zLULe+GGsBhfwCLAxrKoCX2s0JSRNIzhenzCzX5rZNQQn46U1pCHLhsCpZnZd3P8ZMNXMhmo5Oeq/C3Cymf085rlvAuvWqQfABoT0/Dbuf57goNbDU4SX3o2SNgTmEfLf5yVdDOEZqHZyxkbnmNni2KT2I+CnhJqvXYA3SeoYKb/EJrRtCQ7bDcD/Ac8Dp0p6p6Ra708Xoabs15K2Bo4APgD8UtKMmF+qPkNRx5cAx5jZr4GtYxo+Kumrih1I62iqONrMrpe0FcFB/aCkH0uaWYOc/wKOJTiP35R0MjAE/BzYUdIRMHIznZktBy4AnpD0KeAagtPy1bI0j0jU/7+AY81sDvB74DJJm1toKh+1r0psMvoCcBDBabsYOB54bykdo+mSOd4FPA1cF8M7SjLi/qhlwoSk1Z7SeNmA3ritB8wlfLncC7y9LN7WI8h4HXAIwdFZKxP+X4Rq4z3j/qwRZOwH3Az8R4Vj2xFqVk4GDgVOZIQqTsIXz0fj7ykER2E24WvoJIZrVqo2bRGqMd9VkhH/b0OoVTmd4a+ydUfR42Xx99qZdJ4FfBTYqkYbvQo4MP7uyujyYcLkSSVdNhjNRvH31FL6o82uBDaLYS8fwT63AK+ucOy1wDfi78MJL9aqX3XAK2L6dyB8UZbmPfog8J0a78mb4nUmAz2Z8I2A32Rkrj2KfaYTnJLNM+e8HrimjmfoVcC+8fdmmfAtCTUZa9egS+kZWlXTALwbOCLub0hwwqrWOGVs9Nqy8K0yv98Q7T25BvusE/e7CU7OmYRahZ8DH6rBPkdk9tciPHsfifvHA4+Okmd3BF6a2e8m1Mh8luAYXwlcWaN99i/T5WTg43H/k4RajbVGkdNJqL34Ycy7ZxKev1sJNRoPAQdXOXdPwvO6W9x/C6HW+Xtl8Y4C5tWY7zbI5JWueF9uYLhGZKRncLXyluAMvjLK+BLw3kzckWqItsj8vjqbP4nlK/ByYncC38ruX6sVGA8boep9ADgS2DaGzYsFyMsy8Y4kfAW8qIKMAwiOzQHElzYZBwD4UHwgzwLuIlOQZ+LsC/wdODcT1lEWZwrwGPAEsNMo6ToS+FVZ2FqEZo6vAEcTaibeXeX8fWPhs8bDBbwM+DTwMeCrwO8qFXCEQvVTwCWle1t2z84ivIg+DZw9Qlo6CV+hfyBT2MZj2wEfIXTK+yqhAK2kyxo2iuGlF/MVhIL/HYQv72k12EeZ37sRqr+PIji6249in6OAn1cI349hh+edwJtHsc8bysI7gB7g3rj/npi2NQrsaJ8F0T4vLTv2auB3GRmn1GifN2TCu6Iud8T9owk1NZV0qWafrrJ436iUJ0ewUckhz9rqPwk1LFNHeX5+kdlfm7CabWl/D0JNwJR6nh9g47L9S6jyAcTqz892MWwy8JJMnCkEZ2Wkj4WKzw9lDlK8J9tUOH9dMmURwbm/nuCklO7vWwiO123leSkefyOhnD0amJEJ3x/4f8RmI0Iz0q2MUL4RaoEWRH3fTWwizOj2WYKjXrV5mfCc/Z3hDzEx3PdmXeBthPLkv6rJiHE3JDT1Hx/3Pw38T/k9IDTjX1Atv0zkreUKpL4R2nvvIXboKjs2Pz4w28VCZwmwY4V4OxFeTHuUha9dtv9TgpOxRts4odrxFkK1/2cI1cIbxWPZAvathOaONfSoILMT+C7DNQelh3AtYFfCV8cTxH4aZefuR+hs99q4vwXwxvL0xQf0AUZo4yZ8oZxKeEFtX3ZsF+C3hH5BM0dJzxSCE3Et8KayY2vFQuvhSrqMZqNYuH07bgPl93c0+8StF/g3wWnboUb7fI9hx1aZe/J5QkF5Z5U8N6J9CM7KdwjV178Ddh7FPp8otw+wCWEUxaGEF1xVGTXY52Lg/cD/Vslv1exTqs0o3Zu3RPu8pIKMqjYqi/d+wrM8Yh8Vyp6fCsffQehvtUatTBX7HFhFxs2M0NeE1Z+fNfIVwaH6TTU9q9jnwEx46d4eHnXZqOy8PQl9qD6fPUZwQq8DvlUWv9L92J1Qzr66LLzUkXZfQg3GdwmOTsUazRh3f0IfmyMYrtm9KpvnYv7/EqH2rZOy2hCCM3wX8P/FdL0y+yzH3+vGe/slRuiTRCgH9yfUpBwOvIhQ43Q6oXZwHYJzdhex76NvZfew1QqkvhGqPo+Nv0tVdFnH4ChCe/m91R4eQnX1JfH3+rEwuIBQOJdGDu1AqFbdpYqMDzLccfAwwhfGscSv+szDc9QoD/E+hGrt3WNB8ntik1OZnA8QOm2u8eAQmiGuBU6L+5sSnJp3lcX7D0JP+zW+fAjVzAdn9l9M+DI8n0xhS/iyfaraA0woJD9J+CovOVxvJ3T0zBa2b4y6VHTgRrFRqbniMkJh+rIK549onxi+LqFpoOoLsBb7EJqQhggvjUovplrt8wBV8m0t9iE0Aw0RXrjV8n4l+xyetQ/hpbGMMLqkogM3in1Kz9AHCI5IxS/t0WxEeGFtGcMr2mg0+2TizSU4O5Xy/qj2IbzM3hXvbaVnsBb7TI163Er1fD/q8xN1mUt4kVZyirclOCq/IDisHyTWmhEc/KvIjECiQhMJoWawVM6WPpjOIoyi+mTMIwcSao6qvswJDs19WfvFe/N+4MdkmtUJz9LGFWRMj+l5DaGD9acINcw7lqch3uOKNVWEWuWOMt1+CcyJ9/TjhBq3n8T8MGIN+ETeWq5A6huhrbfURlvude9EePm8s0phMpPw9bsxYSjmVwjOyMVRbqlg3ZLQwXBaBRn7xAf2nWSGshFe4KWCdsMa07JnvN4FhGrZswjDID9cIW2Hkal+zYSX2nvfHtNwHOEL9pgKcdemwvA7QkG9jPCSO5PwJbgd4QXw3rg/PXMPK91bxULiV1HOtwk1LwcTvlbfGB/+0siStShrWqrTRhsSvsjLa1Jqtg+hsB2p/0VN9iG8VBZT2Umpxz6fp7LTNZp9zif0/ZlEqPGpJKNW++wV4y+oIqdW+2xEcIwr2bgeG4kq/brqsM8rgS9T2UmpyT6E5pujG7TPNwmd0dcDTiPf81PqmzGXKk2V8TrnEhzo3Qhlx8OE0ZDT47UuYYThvARn4Ltldv9FtN25xL6AQPcIMqYQail+SlnTOeGZ+X/AnFHKyFcRajmyTXi7EGoUVzkrZGpWqsjZmVAb/VtCM9M+8T69luCYHJaJu/5I6fLNHZXKNyV8LZWqHN9M8HpLGXRVNSGhkKz2pV+aJ2LnuD+TUE3+MTLtosBFZDo5lsnYjzBPxOcII0gWkOn/Qqj6/xJhSHHVznYZWbdk0jEJ2D7q82NCITfifDCEjn+XlgosQtXqNcAFZfHeTfw6qiDjJfH/bEKnug8ROg9eSqgaPZ9QeF5KpgNaBTmT4/+XE6pvP0oopD9DeImcT3gB3EOV4cl12GhRJRvVaZ8Rncl67UOFquY67DMvHqv0ZVurfS4hOOnV+l/UY59XUmEocR32ubiSfYq0UQP2WeO+1GGf9wBzcz4/lxA+fio+03Xap1JTaR+r11ocDvw5/u4lOFKXE5yGL1XRYdPM71cQ+m/NKM+X0XYVy5N4vNxJPInQd2SX7HHgi8CFozyHuxNqhd5NpqmM4Hh8guDsjNjEGeNvTOj3dVPU539j3l1IcIxvBo4cTY5v8X62WoEUN8IonEcJ3nU34cvzNFav+jssZug1OmMRvkZ+y3D15/pUmGclyriJyh1ndyZ86ZRGqrw6FkRblcV7J+ErYqRRAfsRhuyWJjuaVHb8PbGwehNVesATql2XAgeUhR9KeJHPyezfXOlhjvJ/WUpDqXAjfLF0xkLqDEJ7+kPAi6vosldMc8mZ7CMUzkdGe61H+GL9MqEKt1J/hVw2aqF9Ko5CaYF9Hi6/Jw3a586xsE+RNqrTPtVqY5ptn/8bK/sQmkOeITSFvpphR+CThJfx/cQOuYTmwa0r6LBDtM1ZhJojEWqCPk0c8RPjzSHU7KzRgTcT50Vl+7sQanPOZfVOuR+hyigsQtPisTGfvZowevJoMjUdBCfoNMJQ5WrPYQfDox83JPRROj7mxW0ItWjfiGm/iRE6OPuWua+tViDVjdCm+aeY6XciePXXEqrxPk2Y+KpS1e7WMRO+N+6/lPBlslcmzqaEL7E12o4zD/16hM6fizLHribO8Mjqw9tGGpkwm1BA3hQLkuyEWJ2Z3x8gfAGsU0HGulGXUse/dQgdKXckfFnuR5hcrTQEsVKfh32jDvuVZMT/RxH6SZReSKX26YqdBwlf2bcSXg67ZsJnEQrxD7N6u3ClEVgN28jtk7Z9iraR26eifdYjdMT+NWEKhFK6DieMktmn/P5UkLEFwRE9idDEczZhhOF3CWXtNYTar3vK7VsmZyZhfqK3k+mIG+/tJwg1K5tFO95JheareE9uIzQF9sWwvansrOxIhQ7Y8dgbCXPzXBfTtXu0/RUEB2ftTNx+Kox88q2KnVutQCob4SvjvYTqwVLV7FEEh2QXQpvx/oTalf+irO2Y1asfTyF8oexLmEvh+LK4L4nXqdQxLVtITGF44rDTCaMzTiK0ld5DmO9kpHlSNiW0p5e+nL4fr7tZleutX0XOWrEwOYjQ7+TMuD9AcN42IHwJ/ojK7eG7EV48s+L+NoS+DS+N+0fG+3xA5pxKzRKzYrpfVxb+OkKBvxPhRXQS8eu7zC65beT2Sds+RdrI7bOGTbJpfSuhKWwRYahtqXnuu4TJLGspc79EqJWZRGgGu5DQ1Lc/oWZoLyr0OSqT0U+YLPA8Qo3M+fF+itBP5xRCR+W7q+SVVxI+SF9T4VjJWXkXo4+Ymk0YlfbGaOeTCLUphxH6Al1BcMA2reXe+FZ2f1utQApbzFh3E76yvkUYkvY/hGrQo2JG3m0UGRuW7Z8IPEfZlOnxwdqTCm3HhHbubxKqTz9H6Bm+AaEfy1Os3ga+ISPPAfAywhfSxmXnfI9QUFYsbMtkvIrYVk7oZPcHQpX/hfEB3JhQvXpMjLPGw0yoCn1JPPd4wtfYb4gTzWXivSsWfJW+SLNDT79QduzrhNEIH44FwixCgb9GNX5eG7l90rZPkTZy+6wxf8oB8R6+JRP2XsIL+kxiR1NCWfoFRu70WtJnMqFmZjOCU/IAweH4TrRf1flECB2nD46/zyU0U21GqEH5EcEp3ZTQ9+VjVB+Vtj9wcdaOrO6cldb1eSdVOs8SasguY/UavxcRmvu+T2ha25RQ03IKDa7tNpG3livQ6o1QzbyE1YetvY7gqHw+7r+f0Dms4oyxMbP/Nj702bVyPkwYvljqgHdUzPTTK8h4Y3xQ5zLcgfd8QvXhBgTn6f+rJZMTOrO9jODRf6fswduAUNieziiLasXC6Q+EoaDdhAKzfI2KM4ATq5z/RuCD8fd0whfySoYnUCoVDKUvxWrV76VZSN8MfLt0brTd/yNOgAa8Ix5bY2RNXhu5fdK2T5E2cvusMb/TWgSnbxmh2eiieE+/QmjymkRo2vgy4eU8aq0BocZjMqHz7iWED8WD47GXMXLH5v0JTTWlEUl7AV+Ov/eMel5I6KfzHkZ2mv4DuCxzT7LzpOxJcDh2ZeQZx7uIfZRKaYv/X0SYx+W/4v5m5FxsdaJuLVeg1RthWN81MbNlp7XfOxZSW8f9eVSekfFNhOrkgwhfGOex+iyIJxIK4E8RPOo12tMJHbiuJs7XEcM7Cc7SRQSPfQphSOrFo6Rnf0JB/p+EgvEi4IqyOBsQqtM/Q/XOs6WHbR9C9fS7KsR5G6EgrtTu+wZCm3B2FtLp8R58JhP2LkIBXLFwi4XWFwmd8nYgvLS2ice6MvE+x/B8C+WjBhq2kdsnbfsUbSO3z5r2icc3J4wwOp3g7B1OaL76J6H5ZAOCs1Kx/8YI93t7whDvT9QYf1/gX8CrMmEbx3twAaF26OAYvh8VnEmCc3IIwRFci9jHJR7LNm8dV8lumeMvZ3jOmjOAwzP5ruREziHU8DS8WrNvE9hRIUwCNInQqe1nDPfUzj6836v2ABEKxw0JbccLYthahHbXuaU48f/HGWFK+1g4fJvhoYdZh+la4JPx94sqPXiZuHsS2qCzD/FUQjvyFWVx16fC8N/4cJeGcr6ZUGU5i1DdfCShjX0DwpfunZXSxPDMkDPj/nTgrZnfvyC8dN5MmNBppKmwdyJ89X2e4EyeDDxIcDBLQyyPJLRDb1N2biE2cvukbZ+ibOT2WcM+uxCadnYn1AasS+ifdy6hFuNl0S6lZUXqWgE+c525hI6zazRblcV7I6H2+y7K1i4izE/yNzJr71SRsT+hL8n/xPjzo33+xupzm7yd0F9muxF0uYEwuGItQp+dx1lz5uRjCLWEvjpyjq3lCrQk0WGCtS8zXNV5OZk1VRiudl5AZsGwzPFsVfAcQlXjG+P+pYQ+Ld8nfI3NJBTG61eQkx2n/zPgY5n9Uq/+twP/U2O6PsxwNWPW4eomjHS4bKQHJhZ8fyR8TS4gtD3/gPDlUCps305oJ++l8rDSdQmjF34c99eLhctHMnG2Jny1Pkn1eWhmE1a2LRVCZxC+2EToqHY9YY6Gr8f7XXHkRx4buX3Stk/RNnL7rHH+vYQ+e98hTNewB2GyuY8S+gFVtWk9G6Gm50pGcFQIs99+l+FROb8Afpk5vjHBISvNUlxpXp5XA3/JxHkFwSHcjFCr91DMc5cRnKFqTvF+8XhfWfj8eJ/eTagtm0uYHsFnnM25tVyBliQ6VAF/JBYkbyTUrPyY0AS0EaGa+D8JHnWlmSE3jQVId9x/E6E68iexYHoZwXNfGB/ySjPO7hcftq/EjD2LsFjenLJ4H2e4/bVaZ67SV+c5wGcrxSV8Qf2Q2EZdQcaGhB7u2SF+WxLaoL8Xj/cTCsjRZnfcjbjEO6EteW7Z8UlR9vQq5+/Hmouj7RztdRqhbXsrwuq9+1JhdeW8NnL7pG2fIm3k9lljXpkZhD4j2flMjiIsqbE7ofw8geBQjjjIoNaNkZ2U1xBe+tuVhV/D6s7KqfF+rbF2Tzw+J+avvRheLuAyhldu34rgQO5OlQkEY7z/IXYqjrYQw8urHETol/JdQj+ZUSeH862G/NFqBVqa+JCxr46F5CTC18OPY9iNVF4crdSefnksdI6KD8brgOeJk0Jl4leah2A/wpwIhxN6/3+fMNnQUYSC95RYsMwjfAFUXbunTO4+8fxS57oOhttK30OoNq7Wlr1xTNc2rP61uxWh9qk/7r+eyhM4vYLwxVVqQptB6Gvw62whFNP4Maq37fcTqt9Lk3RNZ3jV0dcSRhScxsiz1uaykdsnbfuMlY3cPgbBeexjeB2iyZl7MJfQWXkjQg3HsVSZVK6ojeCs3hftvV4MyzbrXQNck9mvNPFfH8PNaO8hOBClRQ5/SI39Rxhe/uDbZGruYtiqDrSlfapMCudbA/mg1Qo0LaGh09aPS5kyFiy/J3y9ncXwAlzrEiYjWqPXeSzIHoiFwRRCb/4LCdW8kwgF8HLgPzPnrDZPBKFvzD8ZnsxqbcIEcu+Ox19NqMI+n9AJq+ZqQ0IV9YJYGGVHMR1GeCFUalPfiuHVeRdlHujsMM4zgPNGuO4bCVWcA4Qe/DNi+KsIHQ6/GNNZmjyrWpXqOlGH8+P+5oTC/9hMnNcQvqA/He95+ZdvwzZy+6Rtn7G20US3D8HJOpPQr+IOhlf/znYO/UFGvzF9ETM8x8leZeFrle3/gdhnpUJ+25/QhLU/wyuhvy/mjz8wvCDlaMuH7MBwU9pRhI/crMNUKkPOYIRZdH1rMC+0WoGmJDJU521HmHTnIkK16a8zBd37Ce2bR46UYQlVfh8oC9uTUBNT6vH9dkJbZ3eFh6Y0TPAjhGF+pUmSvkHs7Bf3S31kqs4jMIKOPYTe+7+JBdxnqT6L7qYx3R+JhdGphAK5uyzeh4CTq1xvX0LnvOmEL9CvAmdkju/K8PohdzLKly2h+v6bhM5/twHvi+GlgrKD0OZfbebNhm3k9knbPs2w0US2D6G57eeEWqiTCCOw1iu7n98F9q433zfwnEyJ+eLcuL8RoXz+OsH5LO8fU6l58dUER2cNfQn9iS4h1HCt0axYJV/8H6FLwEsJtXnvyeYvQr+UG/BJ3YrPD61WYMwTuOZww4sJMxl+IBOnOxY2p1G5mnmrWBB9Anh/DMt600cTOryVPPZKEze9MRYgpa+UjxA6ZC2KD16pB352Wu5GO6dNIbSzLoiFzRr9bGK8DsKMkGcD82PY12Na9iRUR5d6v1eaMXMtwpLutzA8TG/DWJi9geHOjK+I16i21PwrY4GxSdzfmeBQfpdMzRbDK8NWan/OZSO3T9r2aaaNJpp9COXievH36wkdmy8hODvvJ754CTVLf2KEZr0iNkKt2hmEYcQrCM7tzdHOZxP6gDxGqBWvOtIo3vvPxd/TYv45PebBdQhDlH9ImPtlpL5LJSftIOCi+LufsNDgpwmjvD4Q7fzKou6DbxlbtFqBMU1c9eGG3wIuLYu7NpVny3wTYQ6HDTOZsfRVl1186v9juFmpvCB4I+Hr762sXoi+l7A2RmmK7qaMtSfULpWWCRChSvk8YF4MOzEWaNcAV1F5gbTdCW3W+xHmcriSMBTyfwhVrfcQqol/QWh2q7aI1/6ZuE+UHvQo60JCe/z6hI5wI/UbathGbp+07ZOajdrJPoRalFuIM8TGsLcTHJ1PE2qV7iUMSb6NMX4RE5yGWxleAHJnwiy1JxKc3ZLzcDHV+9nsQBjJ8xpCbdV7GV5R+vuE2rfSqKq5VB+uvkXZ/s4Ex6aU12YSZvs9l9AnquIILN8KyBetVmBMEzf6cMPLywvEsvNLw9BmZMLOj+dl5R1NaEpaYyVMQpXhbzKZe3K8/qaZc28jM1pgjO/JNMK8FX8jdIY7huEvwwWE9tvSF8SLqDCrYywclxKmlX5djPfBWGDeFOOsTehwdxpV1uuI5/4fcXIvwkiH3zD8ZdxLKPCvIFR7V/oqzWUjt0/a9knNRm1on0kEB/H/CGXiGwk1J6cAB8U4/YRamzGdVZXgXPya+GHJsBO7dVm8dxJqWCo1X72RUNOxXdw/jLAUwmkEB6aDMHfWxVTpkBzPW5cwyul0Vp9f5eR47fXGOq/5lrFHqxUYk0QVM9xwf8K6HEsZXvxLBK/+gvjgf4zQhv0Xqndw6yZUwb4qFkifJowqWkLouDaJMC/B7ynrJDaG92cfQmH7AcLwz9JQuq/H38dSYZrzeO6ehC+s3crCX0foGPljRvnqivexi9AOfjmrz0K6KN77LeP+FoQvlh3GwkZun7Ttk6KN2sE+0QalYbkbEZpTPkOofTiT0AfjMhroh5XjvpZm/H0lwVFbQHAyro/3dyZhvaNbqe4U38jwCtOloe/lnW/nRplr1KDH468irM1Umo33yqjXLvG+/Tdx6DejdML1raC80WoFxjRxDQ43JIyzHyBU6R4RC49Xl8WZHzPxJ6g8BfbriCMXCJ3zLiV46BcSeo3vS6iKLC2JPmqHroLvzRsIk1NNJnQuPopQTb2c0ON/vSrnfYhYS5UJ+wLhC/PT8Z5dR9lkSFVkbUKo0v0SoT36i4TZHX8cdfgJcTrsom3k9knbPqnbaDzbh+D4fYNQq3BwDDuK0Dy0AWFxwZ8QnLGvN/GeitDv6GqCg3sRoZzeLdr8fYQmtmqrIA9l8sK2hLJ/50ycjeL9v4XKjo4I74h9CU7v2zLHvkJogvo5YbTQV5p1X3xrf0elkeGG+xJ6bpdmydyU8OW0mDomNyL0Kl9G6JzWQei9fxirV3dfBLwn/m76FMuEvgN/Jna4i4XUJlRe8G2NWqq4fwDhK+41hK/i9xK+WKqtSvsqwtwXswlVsSJ8Df+C8GIrOZK9MU6lF1huG7l90rbPeLDReLVPPL4ZoS/KwwQH4A2E/hulj7pNCQ5kxWanMbynU+O9eBurd7a+ADhkhPu6btT/PMIH6C/JLPYY71MvoS/PiMPVCTV0+xL6tbw/E/6SmP/uBe4nOD4+NX4z8kWrFRjzBNY33PBAQjX1gWXh0whrXCxmuP1U2f9Vrn1IzNBvqXDsMDJV4i28PwfEwramr1FCe/U1DM8X0cVwm/jHCV9l1SajemO8H2cSqpVvKhUmhC+pc4groo5w/cJs5PZJ2z7jwUbjzT4VZM6M+nyUMHLqWoYXLWxo7Z4xuMf/SWjmW8NpYnVnZm1Cf5tVozoZdtxeTRiWXa1Jbm+Ck7MTsXMtwXn7CZl5aGL4dGDjVt+XibS1XIGmJLKG4YYMd+TKdtibSnB0JhOGVn6QUC07q8p1+gmTx/US1yWJBdl9DPdin05YlfNOqgw3bMH9OYhQwzRqwcTqtVS7ZsIPJ3xFr7F+STy+PcFB3DPudxC+CB+OhWQHoRp7IXEtjqJt5PZJ2z7j1UbjxT4j6LQFYbK8cwnNJ8dTZRXlJt/XFxOaaqot3rgvoaPwAoantO+mbFQnYVTV76gyLT7DC1oOEfr8LCG8J95GmC34F2SagXxrQV5otQKpbFTuyPWLWKheQJhaej1Cu/oa1bIEZ+hbMbNfHQuudxP6yexNmI2zNK31QTS5SrWG9K8xb8UIcUu1VNfGl8rnCV+VVYfnEYb2LYq/xfDIiJcThq5OJ7zojqf6ZGEN28jtk7Z9xruNxoN9RtGpi+EFESs2F7Xgnk4hNK9VqknZn9CP5FhC59ZvMDzSZ92YjxYR+kf9luodtfsIQ7SnEYZon0YYcnwyofbvBwQHchlxFJRvzd9KVa8THkkiDGfel9CZ7BeEDH47YdKj75rZjyV1mtlgFRnbEXri30ooqJ8gPEg/IbQHb05Y8+N3Y5ycMUfSFEK18RuAR4BrzeyeCvE2M7PHJW1DqK4+wszujscmEdqDvw98ycx+Ocr9zWUjt0/a9okyJoSNWmGfdkHShgw7DoslbUGYdO08M7sxxplMuF/7Epoa76og5wBCV4B5ZnazpM0JjtpvCMsQ/CPG2Rk4lDBz8n1NSKJTxqRWK5AKZmaSvk7wnrcEfmRmzwJImk/4WqS8EJA0zcyWx2P3SDqXUL19K6H3/WWEQnuQ8GX4t+akaGwxs5WE6tSqLwxJbwI+JenNhEm5BoDdJf3VzJ4wsxeAFyQ9QpgpEsLXdLVr1m0jt0/a9onHJpyNWmGfdiE6ELOBL0j6jZk9LGkj4AxJA4TlFy4k1MatZWaPlcuQtD9hyYOTo5OyMfBvQm3fQmBDSZ8zs6uAqyR9OdrMaQWtrtJJfSN05BqgwkJThNVIBwhtxBsyPP33LMKDciqZyYqoMPlTu26EqtnrgQMyYXsTXjzziTNkEtbvuJcqS9bnsZHbJ237uI3SsM943Qh9l+4hdCK+itDxej6hk/H5VFgOJZ63IcGhOzjubxPvdWlocw9hjq2ziJ1m8dE9rbV1qxVIdWOUjlwxzusJ8ybcS+iJfy7DPca3J8wK+VmGJ1aaEJm9QkGwHcNrZLyFsOz9nYR5MW6vdn/z2sjtk7Z93EattU87bDH/DJGZD4vQOXajUc57E2GG2Z0Jo54+Ujo3/n8xYQSRj+5JYGu5AqluVOnIVV5QEuaHmE+YlOhkQi/8EwlV1VvHgrepk4WlsJUVBL8sFQTxWBdhpMFLyLHSaCUbuX3Sto/bKB37tMtGqFm5izo7ERNqrYaAj8X9UgflA+N9b3uneLxsLVdgvG2UzXFAGMZ2Rfy9FfAUYejhw7HwrbiY2ETYKhQEkwgjFsasAHD7pG0ft1H69hmPG2EU2M3UOfcLoTPz3QwPhZ9LaDpq6fxJvq2++aifOpD0esKY/FuBW83s6hj+HcL4/ZcDHzazKyVtDwxZhZ78EwlJbyC0Ie9mZk9KmmShE+BYXMvtUyfNtE+8ntuoDpptn/GMpKlm9lQD5x1AcIy/ShhZdoyZ3Vm0fk7juKNSI5L2I8x3cBlh6uT1gNPN7C+SXkdoS/8vM7tK0loWRzs4qwqCswmLp/1jjK7h9mmQZtgnXsdt1ADNss9ERtKBhDlTet1JSQ8fnlwDsYD9EWFVzt/EuR4+RWiDhzAx1d8IkwYBPNd8LdMlvngmA7+Q1BeCivOQ3T75GGv7gNsoD82wz0THwvw+65vZ063WxVkTr1EZhVjAfoY4P4GZvTqG/zxGWUKYYXI9wkqfBwMrvSBZk0arZkeR6fYpiLGwT5TrNiqAsbKP46SO16iMQCxgv0JYY+Q2Sd+V9AdCoSrC8MBpwP8jzML5LvfIqzNGTorbpyDG0ElxGxWAOynORMVrVKogaV/CehHXA58qtVtKuhA4ijAx1XMxbCqwjpmN+xkzxwtun/RxGzmOUwTuqFRAUj/wNcJiV5sCmwA/M7Nr4/HLCFOE72lmz7dKz4mK2yd93EaO4xSFOyoVkPQqoMvMbohDJI8gNJNdnSloryJ8Ae7ZOk0nJm6f9HEbOY5TFO6ojICkDjMbiiMU3kmYEfIqM7suHu8xs0daquQExu2TPm4jx3Hy4o5KjcSC9u2Ejn+XmdnvJMlHJqSB2yd93EaO4zRCR6sVGC/E2TEvAx4D/hzDvIBNBLdP+riNHMdpBK9RqRNJXd75L13cPunjNnIcpx7cUXEcx3EcJ1m86cdxHMdxnGRxR8VxHMdxnGRxR8VxHMdxnGRxR8VxHMdxnGRxR8VxHMdxnGRxR8VxHMdxnGRxR8VxHMdxnGRxR8VxHMdxnGT5/wE+zaLunsR9JQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_features = [features_choices[i]+str(j) for j in range(1, 4) for i in range(len(features_choices))]\n",
    "\n",
    "corr = df[['CHOICE'] + all_features + features_other].corr()\n",
    "\n",
    "corr_choice = corr['CHOICE']\n",
    "abs_corr_sorted = corr_choice.abs().sort_values(ascending=False)     # sorted by largest correlation to income\n",
    "\n",
    "print('Correlation of each feature to CHOICE, sorted by absolute value:')\n",
    "print(abs_corr_sorted)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "corrplot(corr, size_scale=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>GREEN2</th>\n",
       "      <th>FOREIGN2</th>\n",
       "      <th>STORES3</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  TRANSPORT2  CITY2  \\\n",
       "0       10           5      1       2       2       0.4          10      2   \n",
       "1       15           5      4       4       1       0.1          10      5   \n",
       "2       10          15      1       3       1       0.4           2      2   \n",
       "3       15          15      5       4       4       0.4           2      1   \n",
       "4       15           5      5       1       3       0.4          10      1   \n",
       "\n",
       "   NOISE2  GREEN2  FOREIGN2  STORES3  TRANSPORT3  CITY3  NOISE3  GREEN3  \\\n",
       "0       3       3       0.1        2          15      4       4       4   \n",
       "1       1       2       0.2        5          15      1       2       3   \n",
       "2       4       2       0.1        2           5      4       1       3   \n",
       "3       1       1       0.1        5           5      2       2       2   \n",
       "4       2       4       0.1        5          15      2       3       1   \n",
       "\n",
       "   FOREIGN3  CHOICE  \n",
       "0       0.2       1  \n",
       "1       0.3       2  \n",
       "2       0.2       3  \n",
       "3       0.2       2  \n",
       "4       0.2       2  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop features that are leased relatted to choice\n",
    "df_reduced = df.drop(['STORES2'] + features_other + ['COMPLETE', 'ID', 'ID2'], axis=1)\n",
    "# df_reduced = df.drop(['STORES2', 'GREEN2', 'FOREIGN2'] + features_other + ['COMPLETE', 'ID', 'ID2'], axis=1)\n",
    "# df_reduced = df.drop(['STORES2', 'GREEN2', 'FOREIGN2', 'STORES1', 'FOREIGN3', 'CITY2'] + features_other + ['COMPLETE', 'ID', 'ID2'], axis=1)\n",
    "\n",
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q1** <br>\n",
    "The dataset is seen to consist out of two main set of features. The first set is the various 'choice features' available for each of the three choices; and the second set consist of 'other features', which contain information regarding the applicant, e.g.: age, woman (yes or no), place of citizenship.\n",
    "\n",
    "Considering all the available data, the dataset is checked for Nan and empty values. It is found that none of these input types are present. It is also checked whether all choices are complete, which is done by evaluation the COMPLETE feature. This is also found to true for all choices.\n",
    "\n",
    "Then, the type of levels each feature can take-on are obtained. For the choice features, no irrelevant/faulty levels are seen to exist in the dataset. For the 'other features', it can be seen that the WOMAN, AGE, and ENVCONC, contain irrelevant/faulty levels, equal to 99999. The number of occurances of these irrelevant levels are obtained for the three features. As later-on it will be found that these 'other features' do not relate to the CHOICE output, they will be discarded. Therefore, there is no need to correct for these faulty levels.\n",
    "\n",
    "Furthermore, the data is seen to be nicely balanced, with a distribution of 35.4%, 33.6%, and 31%, for the three choices, respectively.\n",
    "\n",
    "Finally, the correlations for all features to the CHOICE are constructed. These correlations are plotted, from which it can be seen that the 'other features' are not related to the CHOICE, and can therefore be discarded in the model. It is also found that ['STORES2', 'GREEN2', 'FOREIGN2', 'STORES1', 'FOREIGN3', 'CITY2'] do also have a small correlation to CHOICE. By removing some or all of these features, and evaluating the model performance, it is decided to remove the following features from the model: ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Estimate a RUM-MNL discrete choice model (1.0 pt)\n",
    "\n",
    "Assume utility is linear additive-utility: \n",
    "\n",
    "$ V_{in} = \\sum_{m}\\beta_m x_{imn}$\n",
    "\n",
    "And estimate marginal utilities (i.e. betas) for: \n",
    "\n",
    "1. Distance to Transport [min] (**Note** that distances are given in minutes)\n",
    "2. Distance to City [km]\n",
    "3. Distance to Stores [min] (**Note** that distances are given in minutes)\n",
    "4. Traffic Noise\n",
    "5. Green area\n",
    "6. Share of foreigners [%]\n",
    "\n",
    "**Note:** Do not add any other variables (features) to the model.\n",
    "\n",
    "**To get the scores, address the following:**\n",
    "\n",
    "- (A) Report the parameter estimates, and interpret them. i.e. do they have the expected sign? (0.5 pts)\n",
    "- (B) Compute and report the cross-entropy (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with pandas and database variable for Biogeme estimation\n",
    "database = db.Database('residential_choicedata2021', df)\n",
    "\n",
    "# The following statement allows you to use the names of the variable stored in Biogeme as Python variables.\n",
    "globals().update(database.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_stores = Beta('B_stores', 0, None, None, 0)\n",
    "B_transport = Beta('B_transport', 0, None, None, 0)\n",
    "B_city = Beta('B_city', 0, None, None, 0)\n",
    "B_noise = Beta('B_noise', 0, None, None, 0)\n",
    "B_green = Beta('B_green', 0, None, None, 0)\n",
    "B_foreign = Beta('B_foreign', 0, None, None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "V1 = B_stores * STORES1 + B_transport * TRANSPORT1 + B_city * CITY1 + B_noise * NOISE1 + B_green * GREEN1 + B_foreign * FOREIGN1\n",
    "V2 = B_stores * STORES2 + B_transport * TRANSPORT2 + B_city * CITY2 + B_noise * NOISE2 + B_green * GREEN2 + B_foreign * FOREIGN2\n",
    "V3 = B_stores * STORES3 + B_transport * TRANSPORT3 + B_city * CITY3 + B_noise * NOISE3 + B_green * GREEN3 + B_foreign * FOREIGN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate utility functions with the numbering of alternatives in df.CHOICE\n",
    "V = {1: V1, 2: V2, 3: V3}\n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "av = {1:1, 2:1, 3:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters\n",
      "----------\n",
      "                Value   Std err     t-test  p-value\n",
      "B_city      -0.167377  0.007949 -21.055742      0.0\n",
      "B_foreign   -1.196023  0.109408 -10.931775      0.0\n",
      "B_green      0.415894  0.011616  35.802485      0.0\n",
      "B_noise     -0.437468  0.011335 -38.594267      0.0\n",
      "B_stores    -0.034433  0.002577 -13.363956      0.0\n",
      "B_transport -0.073962  0.002548 -29.026039      0.0\n"
     ]
    }
   ],
   "source": [
    "# Definition of the model. This is the contribution of each observation to the log likelihood function.\n",
    "prob = models.loglogit(V, av, CHOICE)\n",
    "\n",
    "# Create the Biogeme object\n",
    "biogeme = bio.BIOGEME(database, prob)\n",
    "biogeme.modelName = 'My first discrete choice model'\n",
    "biogeme.generatePickle = False\n",
    "biogeme.generateHtml = False\n",
    "\n",
    "# Calculate the null log likelihood for reporting.\n",
    "biogeme.calculateNullLoglikelihood(av)\n",
    "\n",
    "# Estimate the parameters\n",
    "results = biogeme.estimate()\n",
    "\n",
    "# Report the results in a pandas table\n",
    "print('Estimated parameters')\n",
    "print('----------')\n",
    "pandasResults = results.getEstimatedParameters()\n",
    "print(pandasResults[['Value','Std err','t-test','p-value']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-entropy of the DCM is         0.889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Get the estimated betas from the discrete choice model\n",
    "betas = results.getBetaValues()\n",
    "\n",
    "# Define compute objects\n",
    "prob_1 = models.logit(V, av, 1)\n",
    "prob_2 = models.logit(V, av, 2)\n",
    "prob_3 = models.logit(V, av, 3)\n",
    "\n",
    "# Define dictionary\n",
    "simulate_dict = {\n",
    "    'Prob_1': prob_1,\n",
    "    'Prob_2': prob_2,\n",
    "    'Prob_3': prob_3}\n",
    "\n",
    "# Create Biogeme object\n",
    "simulator = bio.BIOGEME(database, simulate_dict)\n",
    "\n",
    "# Compute probabilities using the estimated choice model\n",
    "probs_DCM = simulator.simulate(betas)\n",
    "\n",
    "# Compute the cross-entropy for the DCM\n",
    "cross_entropy_DCM = log_loss(df.CHOICE,probs_DCM)\n",
    "\n",
    "print('The cross-entropy of the DCM is        ',\"{:.3f}\".format(cross_entropy_DCM))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q2** <br>\n",
    "The signs make sense as people in general want to be close to things as the city, stores and transport. Also they want less foreigners in their neighbourhood and less noise from traffic. They do want more green in their neighboorhood. \n",
    "What we can see people attach most value to not having a lot of foreigners close to their home and less to the other properties. After that green and noise are most important. \n",
    "    \n",
    "<br> The cross-entropy measures the performance of a classification model. The cross-entropy increases as the predicted probability diverges from the actual label. A perfect model would have a cross-entropy of 0, so minimization of the cross-entropy leads to optimization of the model. In the situation above we have found a cross-entropy of 0.889, which is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Based on your results, compute the WtP of the average decision maker to reduce the share of foreigners in a neighbourhood by 1 percentage point in terms of the distance to the grocery stores (0.5 pts)\n",
    "\n",
    "Thus, the answer must be of the following form: .... [minutes/percentage point].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Willingness-to-Pay estimates\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  34.74 min per percentage point\n"
     ]
    }
   ],
   "source": [
    "## Wtp for less foreigners in a neighbourhood compared to distance to grocery stores. So B_foreign/B_stores\n",
    "\n",
    "# Get the results in a pandas table\n",
    "print('Willingness-to-Pay estimates')\n",
    "print('----------')\n",
    "betas = results.getBetaValues()\n",
    "WtP_foreign_stores = betas['B_foreign']/betas['B_stores']\n",
    "\n",
    "print('Willingness to Pay; reduction in foreigners at an expense of store distance = ', \"{:.2f}\".format(WtP_foreign_stores),'min per percentage point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q3** <br>\n",
    "We could see from the beta-values already that people don't attach a lot of value to a short distance towards grocery stores (beta = -0.034432), while they do think a lower percentage of foreigners is important (beta = -1.195431). We can see from the Willingness-to-pay that for every percentage of less foreigners, people are willing to add 34.7 min to the walking distance towards the nearest grocery store. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Train a hybrid RUM-MNL-ANN model (1.5 pts)\n",
    "\n",
    "Since we are interested in the WtP of Q3, make sure when building the hybrid model to place the features of the share of foreigners and of the distance to the grocery stores in the *MNL part of the model*. For the *ANN part of the model* use 2 hidden layers, with 5 nodes each. \n",
    "\n",
    "\n",
    "**To get the scores, address the following:**\n",
    "\n",
    "\n",
    "- (A) Build the model, plot the loss as a function of the epochs & report the cross entropy of your final model based on the test data. (1.0 pt)\n",
    "- (B) Compare the model performance to that of the discrete choice model. Interpret the result. (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "NALT = 3           # Number of alterantives in the data set.\n",
    "no_X_MNL = 2       # Number of attributes with behavioural interest (-->MNL model part).  In this example we are particularly interested in the WtP for extra storage space --> Cost & Storage\n",
    "no_X_ANN = 17       # Number of features without behavioural interest (-->ANN model part). In this example we are not behaviourall interested in Camera, Size, and the socio demographic variables\n",
    "num_nodes = 5      # Number of nodes in hidden layer(s). Again we use 2 hidden layers with *num_nodes* nodes each\n",
    "nEpoch = 500       # Number epochs for training (max). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FOR MNL PART\n",
    "X_MNL = Input((no_X_MNL, NALT,1), name = 'Features2MNL')\n",
    "\n",
    "# COMPUTE UTILITY FOR MNL\n",
    "V_MNL = Conv2D(filters = 1, kernel_size = [no_X_MNL,1], strides = (1,1), padding = 'valid', name = 'MNL_layer', use_bias = False, trainable = True)(X_MNL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT FOR ANN PART\n",
    "X_ANN = Input((no_X_ANN), name ='Features2ANN')\n",
    "\n",
    "# CREATE HIDDEN LAYER(S) OF ANN\n",
    "layer1_ANN = Dense(units = num_nodes, name = \"ANN_layer1\", use_bias = True)(X_ANN) \n",
    "layer2_ANN = Dense(units = num_nodes, name = \"ANN_layer2\", use_bias = True)(layer1_ANN)\n",
    "\n",
    "# COMPUTE UTILITY FOR ANN \n",
    "V_ANN = Dense(units = NALT, name = \"V_ANN\")(layer2_ANN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1', 'FOREIGN1',\n",
       "       'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2', 'FOREIGN2', 'STORES3',\n",
       "       'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3', 'FOREIGN3', 'CHOICE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE TENSORS TO [1 X NALT]\n",
    "V_MNL = Reshape([NALT], name = 'Flatten_Dim_MNL')(V_MNL)\n",
    "V_ANN = Reshape([NALT], name = 'Flatten_Dim_ANN')(V_ANN) \n",
    "\n",
    "# SUM THE UTILITIES OF BOTH MODEL PARTS\n",
    "V_MNL_ANN = Add(name = \"Combining_Vs\")([V_MNL,V_ANN])\n",
    "\n",
    "# CREATE LOGIT (AKA SOFTMAX ) OUTPUT LAYER\n",
    "logits = Activation('softmax', name = 'Probability')(V_MNL_ANN)\n",
    "\n",
    "# BUILD THE MODEL\n",
    "model = Model(inputs = [X_MNL, X_ANN], outputs = logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORES1</th>\n",
       "      <th>TRANSPORT1</th>\n",
       "      <th>CITY1</th>\n",
       "      <th>NOISE1</th>\n",
       "      <th>GREEN1</th>\n",
       "      <th>FOREIGN1</th>\n",
       "      <th>TRANSPORT2</th>\n",
       "      <th>CITY2</th>\n",
       "      <th>NOISE2</th>\n",
       "      <th>GREEN2</th>\n",
       "      <th>FOREIGN2</th>\n",
       "      <th>STORES3</th>\n",
       "      <th>TRANSPORT3</th>\n",
       "      <th>CITY3</th>\n",
       "      <th>NOISE3</th>\n",
       "      <th>GREEN3</th>\n",
       "      <th>FOREIGN3</th>\n",
       "      <th>CHOICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9718</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9720 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STORES1  TRANSPORT1  CITY1  NOISE1  GREEN1  FOREIGN1  TRANSPORT2  CITY2  \\\n",
       "0          10           5      1       2       2       0.4          10      2   \n",
       "1          15           5      4       4       1       0.1          10      5   \n",
       "2          10          15      1       3       1       0.4           2      2   \n",
       "3          15          15      5       4       4       0.4           2      1   \n",
       "4          15           5      5       1       3       0.4          10      1   \n",
       "...       ...         ...    ...     ...     ...       ...         ...    ...   \n",
       "9715        5           5      2       4       1       0.3          10      4   \n",
       "9716       15          10      1       3       3       0.3          15      2   \n",
       "9717       10           5      2       3       4       0.1          10      4   \n",
       "9718        5           2      5       2       4       0.1           5      1   \n",
       "9719        5           5      2       4       1       0.3          10      4   \n",
       "\n",
       "      NOISE2  GREEN2  FOREIGN2  STORES3  TRANSPORT3  CITY3  NOISE3  GREEN3  \\\n",
       "0          3       3       0.1        2          15      4       4       4   \n",
       "1          1       2       0.2        5          15      1       2       3   \n",
       "2          4       2       0.1        2           5      4       1       3   \n",
       "3          1       1       0.1        5           5      2       2       2   \n",
       "4          2       4       0.1        5          15      2       3       1   \n",
       "...      ...     ...       ...      ...         ...    ...     ...     ...   \n",
       "9715       1       2       0.4       15          15      5       2       3   \n",
       "9716       4       4       0.4        5           2      4       1       1   \n",
       "9717       4       1       0.2        2          15      5       1       2   \n",
       "9718       3       1       0.2       15          10      2       4       2   \n",
       "9719       1       2       0.4       15          15      5       2       3   \n",
       "\n",
       "      FOREIGN3  CHOICE  \n",
       "0          0.2       1  \n",
       "1          0.3       2  \n",
       "2          0.2       3  \n",
       "3          0.2       2  \n",
       "4          0.2       2  \n",
       "...        ...     ...  \n",
       "9715       0.1       2  \n",
       "9716       0.1       3  \n",
       "9717       0.3       1  \n",
       "9718       0.3       1  \n",
       "9719       0.1       2  \n",
       "\n",
       "[9720 rows x 18 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and the output class\n",
    "X = df[['STORES1', 'TRANSPORT1', 'CITY1', 'NOISE1', 'GREEN1',\n",
    "       'FOREIGN1', 'STORES2', 'TRANSPORT2', 'CITY2', 'NOISE2', 'GREEN2',\n",
    "       'FOREIGN2', 'STORES3', 'TRANSPORT3', 'CITY3', 'NOISE3', 'GREEN3',\n",
    "       'FOREIGN3', 'SSTADT', 'RESPCITY', 'WOMAN', 'AGE', 'ENVCONC']]\n",
    "\n",
    "# Define the output target\n",
    "Y = df['CHOICE']\n",
    "Y_cat = to_categorical(Y-1, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_mnl (9720, 2, 3, 1)\n",
      "Shape of x_ann (9720, 17)\n"
     ]
    }
   ],
   "source": [
    "# Create x input for MNL layer, and rescale\n",
    "scale = 100 # We cannot just use the sklearn scaler here, as it is import for the interpretation later how the input data are scaled. \n",
    "\n",
    "x_mnl = np.array([[np.divide(X['STORES1'], scale), np.divide(X['FOREIGN1'], scale)],\n",
    "                  [np.divide(X['STORES2'], scale), np.divide(X['FOREIGN2'], scale)],\n",
    "                  [np.divide(X['STORES3'], scale), np.divide(X['FOREIGN3'], scale)]])\n",
    "x_mnl = np.swapaxes(x_mnl, 0, 2)\n",
    "x_mnl = np.expand_dims(x_mnl, 3)\n",
    "print('Shape of x_mnl', x_mnl.shape)\n",
    "\n",
    "# Create x input for ANN layer\n",
    "x_ann = np.array([[X['TRANSPORT1'], X['CITY1'], X['NOISE1'], X['GREEN1'], X['TRANSPORT2'], X['CITY2'], X['NOISE2'], X['GREEN2'], X['TRANSPORT3'], X['CITY3'], X['NOISE3'], X['GREEN3'], X['SSTADT'], X['RESPCITY'], X['WOMAN'], X['AGE'], X['ENVCONC']]])\n",
    "x_ann = np.squeeze(np.swapaxes(x_ann, 0, 2))\n",
    "\n",
    "# Rescale input for the ANN part\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(x_ann)  \n",
    "x_ann = scaler.transform(x_ann)  \n",
    "print('Shape of x_ann',x_ann.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of obervations in the data set =  9720\n",
      "Number of obervations in the training set   =  6318\n",
      "Number of obervations in the test set       =  3402\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training and test part\n",
    "X_mnl_train, X_mnl_test, Y_train, Y_test = train_test_split(x_mnl, Y_cat, random_state = 1, test_size = 0.35)\n",
    "X_ann_train, X_ann_test, Y_train, Y_test = train_test_split(x_ann, Y_cat, random_state = 1, test_size = 0.35)\n",
    "print('Total number of obervations in the data set = ', len(x_mnl))\n",
    "print('Number of obervations in the training set   = ', len(X_mnl_train))\n",
    "print('Number of obervations in the test set       = ', len(X_mnl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features2ANN (InputLayer)       [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer1 (Dense)              (None, 5)            90          Features2ANN[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Features2MNL (InputLayer)       [(None, 2, 3, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ANN_layer2 (Dense)              (None, 5)            30          ANN_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MNL_layer (Conv2D)              (None, 1, 3, 1)      2           Features2MNL[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "V_ANN (Dense)                   (None, 3)            18          ANN_layer2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_MNL (Reshape)       (None, 3)            0           MNL_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Dim_ANN (Reshape)       (None, 3)            0           V_ANN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Combining_Vs (Add)              (None, 3)            0           Flatten_Dim_MNL[0][0]            \n",
      "                                                                 Flatten_Dim_ANN[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Probability (Activation)        (None, 3)            0           Combining_Vs[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 140\n",
      "Trainable params: 140\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = Adam(learning_rate = 1e-2), metrics = [\"accuracy\"], loss = 'categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 1.1895 - accuracy: 0.4270 - val_loss: 1.0991 - val_accuracy: 0.4624\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1351 - accuracy: 0.4410 - val_loss: 1.0587 - val_accuracy: 0.4847\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0912 - accuracy: 0.4579 - val_loss: 1.0269 - val_accuracy: 0.4879\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0565 - accuracy: 0.4631 - val_loss: 1.0019 - val_accuracy: 0.4832\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0292 - accuracy: 0.4544 - val_loss: 0.9820 - val_accuracy: 0.4941\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0076 - accuracy: 0.4663 - val_loss: 0.9659 - val_accuracy: 0.5100\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9902 - accuracy: 0.4816 - val_loss: 0.9525 - val_accuracy: 0.5467\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9757 - accuracy: 0.5269 - val_loss: 0.9412 - val_accuracy: 0.5591\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9634 - accuracy: 0.5442 - val_loss: 0.9314 - val_accuracy: 0.5620\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9526 - accuracy: 0.5451 - val_loss: 0.9228 - val_accuracy: 0.5629\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9429 - accuracy: 0.5464 - val_loss: 0.9152 - val_accuracy: 0.5670\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9341 - accuracy: 0.5502 - val_loss: 0.9084 - val_accuracy: 0.5688\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9262 - accuracy: 0.5516 - val_loss: 0.9025 - val_accuracy: 0.5717\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9190 - accuracy: 0.5530 - val_loss: 0.8974 - val_accuracy: 0.5705\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9126 - accuracy: 0.5532 - val_loss: 0.8931 - val_accuracy: 0.5682\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9070 - accuracy: 0.5510 - val_loss: 0.8895 - val_accuracy: 0.5732\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9021 - accuracy: 0.5597 - val_loss: 0.8866 - val_accuracy: 0.5838\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8980 - accuracy: 0.5714 - val_loss: 0.8843 - val_accuracy: 0.5894\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8945 - accuracy: 0.5764 - val_loss: 0.8823 - val_accuracy: 0.5944\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8915 - accuracy: 0.5810 - val_loss: 0.8805 - val_accuracy: 0.5973\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8887 - accuracy: 0.5872 - val_loss: 0.8788 - val_accuracy: 0.6017\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8862 - accuracy: 0.5861 - val_loss: 0.8771 - val_accuracy: 0.6064\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8837 - accuracy: 0.5897 - val_loss: 0.8754 - val_accuracy: 0.6061\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8813 - accuracy: 0.5896 - val_loss: 0.8737 - val_accuracy: 0.6035\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8789 - accuracy: 0.5880 - val_loss: 0.8720 - val_accuracy: 0.6035\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8766 - accuracy: 0.5869 - val_loss: 0.8705 - val_accuracy: 0.6023\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8745 - accuracy: 0.5853 - val_loss: 0.8691 - val_accuracy: 0.5991\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8726 - accuracy: 0.5905 - val_loss: 0.8679 - val_accuracy: 0.5991\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8709 - accuracy: 0.5905 - val_loss: 0.8669 - val_accuracy: 0.5994\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8693 - accuracy: 0.5912 - val_loss: 0.8660 - val_accuracy: 0.5994\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8680 - accuracy: 0.5913 - val_loss: 0.8653 - val_accuracy: 0.5961\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8667 - accuracy: 0.5855 - val_loss: 0.8646 - val_accuracy: 0.5952\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8656 - accuracy: 0.5848 - val_loss: 0.8640 - val_accuracy: 0.5944\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8645 - accuracy: 0.5853 - val_loss: 0.8633 - val_accuracy: 0.5941\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8634 - accuracy: 0.5858 - val_loss: 0.8627 - val_accuracy: 0.5941\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8624 - accuracy: 0.5853 - val_loss: 0.8621 - val_accuracy: 0.5941\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8614 - accuracy: 0.5867 - val_loss: 0.8615 - val_accuracy: 0.5947\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8604 - accuracy: 0.5869 - val_loss: 0.8610 - val_accuracy: 0.5979\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8595 - accuracy: 0.5880 - val_loss: 0.8605 - val_accuracy: 0.5988\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8587 - accuracy: 0.5913 - val_loss: 0.8600 - val_accuracy: 0.6011\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8580 - accuracy: 0.5942 - val_loss: 0.8597 - val_accuracy: 0.6020\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8574 - accuracy: 0.5935 - val_loss: 0.8593 - val_accuracy: 0.6029\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8568 - accuracy: 0.5937 - val_loss: 0.8590 - val_accuracy: 0.6029\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8563 - accuracy: 0.5937 - val_loss: 0.8588 - val_accuracy: 0.6026\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8558 - accuracy: 0.5935 - val_loss: 0.8584 - val_accuracy: 0.6026\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8554 - accuracy: 0.5935 - val_loss: 0.8581 - val_accuracy: 0.6026\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8550 - accuracy: 0.5935 - val_loss: 0.8577 - val_accuracy: 0.6029\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8546 - accuracy: 0.5935 - val_loss: 0.8573 - val_accuracy: 0.6029\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8542 - accuracy: 0.5935 - val_loss: 0.8569 - val_accuracy: 0.6029\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8538 - accuracy: 0.5937 - val_loss: 0.8564 - val_accuracy: 0.6029\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8535 - accuracy: 0.5937 - val_loss: 0.8559 - val_accuracy: 0.6029\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8532 - accuracy: 0.5937 - val_loss: 0.8555 - val_accuracy: 0.6035\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8529 - accuracy: 0.5939 - val_loss: 0.8551 - val_accuracy: 0.6035\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8527 - accuracy: 0.5937 - val_loss: 0.8548 - val_accuracy: 0.6038\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8525 - accuracy: 0.5939 - val_loss: 0.8544 - val_accuracy: 0.6038\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8523 - accuracy: 0.5939 - val_loss: 0.8542 - val_accuracy: 0.6035\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8521 - accuracy: 0.5939 - val_loss: 0.8539 - val_accuracy: 0.6035\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8519 - accuracy: 0.5939 - val_loss: 0.8537 - val_accuracy: 0.6038\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8517 - accuracy: 0.5937 - val_loss: 0.8536 - val_accuracy: 0.6035\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8515 - accuracy: 0.5937 - val_loss: 0.8534 - val_accuracy: 0.6029\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8513 - accuracy: 0.5939 - val_loss: 0.8533 - val_accuracy: 0.6023\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8511 - accuracy: 0.5939 - val_loss: 0.8532 - val_accuracy: 0.6017\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8510 - accuracy: 0.5939 - val_loss: 0.8532 - val_accuracy: 0.6017\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8508 - accuracy: 0.5939 - val_loss: 0.8532 - val_accuracy: 0.6020\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8507 - accuracy: 0.5939 - val_loss: 0.8531 - val_accuracy: 0.6020\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8506 - accuracy: 0.5939 - val_loss: 0.8531 - val_accuracy: 0.6020\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8505 - accuracy: 0.5939 - val_loss: 0.8530 - val_accuracy: 0.6017\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8503 - accuracy: 0.5934 - val_loss: 0.8530 - val_accuracy: 0.6017\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8502 - accuracy: 0.5934 - val_loss: 0.8529 - val_accuracy: 0.6017\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8501 - accuracy: 0.5932 - val_loss: 0.8528 - val_accuracy: 0.6032\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8500 - accuracy: 0.5931 - val_loss: 0.8527 - val_accuracy: 0.6032\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8499 - accuracy: 0.5931 - val_loss: 0.8526 - val_accuracy: 0.6029\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8498 - accuracy: 0.5934 - val_loss: 0.8524 - val_accuracy: 0.6029\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8497 - accuracy: 0.5934 - val_loss: 0.8523 - val_accuracy: 0.6029\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8496 - accuracy: 0.5934 - val_loss: 0.8522 - val_accuracy: 0.6026\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8495 - accuracy: 0.5934 - val_loss: 0.8521 - val_accuracy: 0.6026\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8495 - accuracy: 0.5934 - val_loss: 0.8520 - val_accuracy: 0.6017\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8494 - accuracy: 0.5912 - val_loss: 0.8519 - val_accuracy: 0.6014\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8493 - accuracy: 0.5912 - val_loss: 0.8518 - val_accuracy: 0.6014\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8492 - accuracy: 0.5912 - val_loss: 0.8517 - val_accuracy: 0.6014\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8492 - accuracy: 0.5912 - val_loss: 0.8516 - val_accuracy: 0.6014\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8491 - accuracy: 0.5912 - val_loss: 0.8515 - val_accuracy: 0.6014\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8490 - accuracy: 0.5912 - val_loss: 0.8515 - val_accuracy: 0.6014\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8490 - accuracy: 0.5912 - val_loss: 0.8514 - val_accuracy: 0.6017\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8489 - accuracy: 0.5912 - val_loss: 0.8514 - val_accuracy: 0.6017\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8488 - accuracy: 0.5912 - val_loss: 0.8513 - val_accuracy: 0.6011\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8488 - accuracy: 0.5912 - val_loss: 0.8513 - val_accuracy: 0.6014\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8487 - accuracy: 0.5913 - val_loss: 0.8512 - val_accuracy: 0.6011\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8487 - accuracy: 0.5912 - val_loss: 0.8512 - val_accuracy: 0.6014\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8486 - accuracy: 0.5916 - val_loss: 0.8511 - val_accuracy: 0.6014\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8486 - accuracy: 0.5916 - val_loss: 0.8511 - val_accuracy: 0.6014\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8485 - accuracy: 0.5916 - val_loss: 0.8510 - val_accuracy: 0.6014\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8485 - accuracy: 0.5916 - val_loss: 0.8510 - val_accuracy: 0.6014\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8484 - accuracy: 0.5916 - val_loss: 0.8509 - val_accuracy: 0.6014\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8484 - accuracy: 0.5916 - val_loss: 0.8509 - val_accuracy: 0.6014\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8483 - accuracy: 0.5916 - val_loss: 0.8508 - val_accuracy: 0.6014\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8483 - accuracy: 0.5916 - val_loss: 0.8508 - val_accuracy: 0.5979\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8482 - accuracy: 0.5891 - val_loss: 0.8508 - val_accuracy: 0.5979\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8482 - accuracy: 0.5891 - val_loss: 0.8507 - val_accuracy: 0.5979\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8481 - accuracy: 0.5891 - val_loss: 0.8507 - val_accuracy: 0.5982\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8481 - accuracy: 0.5893 - val_loss: 0.8506 - val_accuracy: 0.5982\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8481 - accuracy: 0.5893 - val_loss: 0.8506 - val_accuracy: 0.5982\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8480 - accuracy: 0.5893 - val_loss: 0.8505 - val_accuracy: 0.5982\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8480 - accuracy: 0.5893 - val_loss: 0.8505 - val_accuracy: 0.5982\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8479 - accuracy: 0.5893 - val_loss: 0.8504 - val_accuracy: 0.5982\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8479 - accuracy: 0.5893 - val_loss: 0.8504 - val_accuracy: 0.5982\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8478 - accuracy: 0.5893 - val_loss: 0.8503 - val_accuracy: 0.5982\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8478 - accuracy: 0.5893 - val_loss: 0.8503 - val_accuracy: 0.5982\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8478 - accuracy: 0.5893 - val_loss: 0.8502 - val_accuracy: 0.5982\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8477 - accuracy: 0.5893 - val_loss: 0.8502 - val_accuracy: 0.5973\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8477 - accuracy: 0.5928 - val_loss: 0.8501 - val_accuracy: 0.5973\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8476 - accuracy: 0.5928 - val_loss: 0.8501 - val_accuracy: 0.5973\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8476 - accuracy: 0.5928 - val_loss: 0.8500 - val_accuracy: 0.5973\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8476 - accuracy: 0.5928 - val_loss: 0.8500 - val_accuracy: 0.5973\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8475 - accuracy: 0.5928 - val_loss: 0.8499 - val_accuracy: 0.5973\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8475 - accuracy: 0.5928 - val_loss: 0.8499 - val_accuracy: 0.5973\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8475 - accuracy: 0.5928 - val_loss: 0.8499 - val_accuracy: 0.5973\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8474 - accuracy: 0.5928 - val_loss: 0.8498 - val_accuracy: 0.5973\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8474 - accuracy: 0.5928 - val_loss: 0.8498 - val_accuracy: 0.5973\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8473 - accuracy: 0.5928 - val_loss: 0.8498 - val_accuracy: 0.5973\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8473 - accuracy: 0.5928 - val_loss: 0.8497 - val_accuracy: 0.5973\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8473 - accuracy: 0.5928 - val_loss: 0.8497 - val_accuracy: 0.5973\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8472 - accuracy: 0.5928 - val_loss: 0.8496 - val_accuracy: 0.5973\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8472 - accuracy: 0.5928 - val_loss: 0.8496 - val_accuracy: 0.5973\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8472 - accuracy: 0.5928 - val_loss: 0.8495 - val_accuracy: 0.5973\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8471 - accuracy: 0.5928 - val_loss: 0.8495 - val_accuracy: 0.5973\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8471 - accuracy: 0.5928 - val_loss: 0.8494 - val_accuracy: 0.5973\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8471 - accuracy: 0.5928 - val_loss: 0.8494 - val_accuracy: 0.5973\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8470 - accuracy: 0.5928 - val_loss: 0.8494 - val_accuracy: 0.5973\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8470 - accuracy: 0.5928 - val_loss: 0.8493 - val_accuracy: 0.5973\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8470 - accuracy: 0.5928 - val_loss: 0.8493 - val_accuracy: 0.5985\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8469 - accuracy: 0.5937 - val_loss: 0.8492 - val_accuracy: 0.6017\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8469 - accuracy: 0.5959 - val_loss: 0.8492 - val_accuracy: 0.5982\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8469 - accuracy: 0.5943 - val_loss: 0.8492 - val_accuracy: 0.5982\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8468 - accuracy: 0.5943 - val_loss: 0.8491 - val_accuracy: 0.5982\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8468 - accuracy: 0.5943 - val_loss: 0.8491 - val_accuracy: 0.5982\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8468 - accuracy: 0.5943 - val_loss: 0.8491 - val_accuracy: 0.5982\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8468 - accuracy: 0.5943 - val_loss: 0.8490 - val_accuracy: 0.5982\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8467 - accuracy: 0.5943 - val_loss: 0.8490 - val_accuracy: 0.5982\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8467 - accuracy: 0.5943 - val_loss: 0.8490 - val_accuracy: 0.5982\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8467 - accuracy: 0.5943 - val_loss: 0.8489 - val_accuracy: 0.5982\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8466 - accuracy: 0.5943 - val_loss: 0.8489 - val_accuracy: 0.5982\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8466 - accuracy: 0.5943 - val_loss: 0.8489 - val_accuracy: 0.5982\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8466 - accuracy: 0.5943 - val_loss: 0.8488 - val_accuracy: 0.5982\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8466 - accuracy: 0.5943 - val_loss: 0.8488 - val_accuracy: 0.5982\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8465 - accuracy: 0.5943 - val_loss: 0.8488 - val_accuracy: 0.5982\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8465 - accuracy: 0.5943 - val_loss: 0.8487 - val_accuracy: 0.5982\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8465 - accuracy: 0.5943 - val_loss: 0.8487 - val_accuracy: 0.5982\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8464 - accuracy: 0.5943 - val_loss: 0.8487 - val_accuracy: 0.5982\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8464 - accuracy: 0.5943 - val_loss: 0.8487 - val_accuracy: 0.5982\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8464 - accuracy: 0.5943 - val_loss: 0.8486 - val_accuracy: 0.5982\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8464 - accuracy: 0.5943 - val_loss: 0.8486 - val_accuracy: 0.5982\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8463 - accuracy: 0.5943 - val_loss: 0.8486 - val_accuracy: 0.5982\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8463 - accuracy: 0.5943 - val_loss: 0.8486 - val_accuracy: 0.5958\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8463 - accuracy: 0.5962 - val_loss: 0.8485 - val_accuracy: 0.5958\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8463 - accuracy: 0.5962 - val_loss: 0.8485 - val_accuracy: 0.5958\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8462 - accuracy: 0.5962 - val_loss: 0.8485 - val_accuracy: 0.5958\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8462 - accuracy: 0.5962 - val_loss: 0.8484 - val_accuracy: 0.5958\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8462 - accuracy: 0.5962 - val_loss: 0.8484 - val_accuracy: 0.5958\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8462 - accuracy: 0.5962 - val_loss: 0.8484 - val_accuracy: 0.5958\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8461 - accuracy: 0.5962 - val_loss: 0.8484 - val_accuracy: 0.5958\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8461 - accuracy: 0.5962 - val_loss: 0.8483 - val_accuracy: 0.5958\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8461 - accuracy: 0.5962 - val_loss: 0.8483 - val_accuracy: 0.5958\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8483 - val_accuracy: 0.5958\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8483 - val_accuracy: 0.5958\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8482 - val_accuracy: 0.5958\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8482 - val_accuracy: 0.5958\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8460 - accuracy: 0.5962 - val_loss: 0.8482 - val_accuracy: 0.5958\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8459 - accuracy: 0.5962 - val_loss: 0.8482 - val_accuracy: 0.5958\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8459 - accuracy: 0.59 - 0s 18ms/step - loss: 0.8459 - accuracy: 0.5962 - val_loss: 0.8481 - val_accuracy: 0.5958\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8459 - accuracy: 0.5962 - val_loss: 0.8481 - val_accuracy: 0.5958\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8459 - accuracy: 0.5962 - val_loss: 0.8481 - val_accuracy: 0.5958\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8458 - accuracy: 0.5962 - val_loss: 0.8481 - val_accuracy: 0.5958\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8458 - accuracy: 0.5962 - val_loss: 0.8480 - val_accuracy: 0.5885\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8458 - accuracy: 0.5986 - val_loss: 0.8480 - val_accuracy: 0.5888\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8458 - accuracy: 0.5986 - val_loss: 0.8480 - val_accuracy: 0.5891\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8457 - accuracy: 0.5996 - val_loss: 0.8480 - val_accuracy: 0.5891\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8457 - accuracy: 0.5996 - val_loss: 0.8480 - val_accuracy: 0.5891\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8457 - accuracy: 0.5996 - val_loss: 0.8479 - val_accuracy: 0.5885\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8457 - accuracy: 0.5994 - val_loss: 0.8479 - val_accuracy: 0.5885\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8457 - accuracy: 0.5994 - val_loss: 0.8479 - val_accuracy: 0.5885\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8456 - accuracy: 0.5994 - val_loss: 0.8479 - val_accuracy: 0.5885\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8456 - accuracy: 0.5994 - val_loss: 0.8478 - val_accuracy: 0.5885\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8456 - accuracy: 0.5994 - val_loss: 0.8478 - val_accuracy: 0.5885\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8456 - accuracy: 0.5994 - val_loss: 0.8478 - val_accuracy: 0.5885\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8455 - accuracy: 0.5994 - val_loss: 0.8478 - val_accuracy: 0.5885\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8455 - accuracy: 0.5994 - val_loss: 0.8478 - val_accuracy: 0.5885\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8455 - accuracy: 0.5994 - val_loss: 0.8477 - val_accuracy: 0.5885\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8455 - accuracy: 0.5994 - val_loss: 0.8477 - val_accuracy: 0.5885\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8455 - accuracy: 0.5994 - val_loss: 0.8477 - val_accuracy: 0.5885\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8477 - val_accuracy: 0.5885\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8477 - val_accuracy: 0.5885\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8454 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8476 - val_accuracy: 0.5885\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8453 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8452 - accuracy: 0.59 - 0s 17ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5885\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8475 - val_accuracy: 0.5888\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8474 - val_accuracy: 0.5888\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8452 - accuracy: 0.5994 - val_loss: 0.8474 - val_accuracy: 0.5920\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8451 - accuracy: 0.6040 - val_loss: 0.8474 - val_accuracy: 0.5920\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8451 - accuracy: 0.6040 - val_loss: 0.8474 - val_accuracy: 0.5920\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8451 - accuracy: 0.6040 - val_loss: 0.8474 - val_accuracy: 0.5920\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8451 - accuracy: 0.6040 - val_loss: 0.8473 - val_accuracy: 0.5920\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8451 - accuracy: 0.6040 - val_loss: 0.8473 - val_accuracy: 0.5920\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8450 - accuracy: 0.6040 - val_loss: 0.8473 - val_accuracy: 0.5920\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8450 - accuracy: 0.6040 - val_loss: 0.8473 - val_accuracy: 0.5920\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8450 - accuracy: 0.6040 - val_loss: 0.8473 - val_accuracy: 0.5920\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8450 - accuracy: 0.6040 - val_loss: 0.8473 - val_accuracy: 0.5920\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8450 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5920\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5920\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5920\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5920\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5920\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8472 - val_accuracy: 0.5920\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8449 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8471 - val_accuracy: 0.5920\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8448 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5920\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5917\n",
      "Epoch 231/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8447 - accuracy: 0.6040 - val_loss: 0.8470 - val_accuracy: 0.5917\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8447 - accuracy: 0.6038 - val_loss: 0.8470 - val_accuracy: 0.5923\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8447 - accuracy: 0.6038 - val_loss: 0.8470 - val_accuracy: 0.5938\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8446 - accuracy: 0.6056 - val_loss: 0.8469 - val_accuracy: 0.5949\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8446 - accuracy: 0.6064 - val_loss: 0.8469 - val_accuracy: 0.5949\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8446 - accuracy: 0.6064 - val_loss: 0.8469 - val_accuracy: 0.5949\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8446 - accuracy: 0.6064 - val_loss: 0.8469 - val_accuracy: 0.5949\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8446 - accuracy: 0.6064 - val_loss: 0.8469 - val_accuracy: 0.5949\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8446 - accuracy: 0.6064 - val_loss: 0.8469 - val_accuracy: 0.5949\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8469 - val_accuracy: 0.5949\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5949\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5949\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5949\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5949\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5949\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8445 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5947\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8468 - val_accuracy: 0.5947\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5947\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5947\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5947\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5947\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8444 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5947\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5947\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5947\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8467 - val_accuracy: 0.5947\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5947\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8443 - accuracy: 0.6064 - val_loss: 0.8466 - val_accuracy: 0.5952\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8443 - accuracy: 0.6067 - val_loss: 0.8466 - val_accuracy: 0.5935\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8442 - accuracy: 0.6081 - val_loss: 0.8466 - val_accuracy: 0.5935\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8442 - accuracy: 0.6091 - val_loss: 0.8466 - val_accuracy: 0.5935\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8442 - accuracy: 0.6091 - val_loss: 0.8466 - val_accuracy: 0.5935\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8442 - accuracy: 0.6091 - val_loss: 0.8466 - val_accuracy: 0.5935\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8442 - accuracy: 0.6091 - val_loss: 0.8465 - val_accuracy: 0.5935\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8442 - accuracy: 0.6091 - val_loss: 0.8465 - val_accuracy: 0.5935\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8442 - accuracy: 0.6091 - val_loss: 0.8465 - val_accuracy: 0.5935\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8442 - accuracy: 0.6091 - val_loss: 0.8465 - val_accuracy: 0.5935\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8441 - accuracy: 0.6091 - val_loss: 0.8465 - val_accuracy: 0.5935\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8441 - accuracy: 0.6091 - val_loss: 0.8465 - val_accuracy: 0.5935\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8441 - accuracy: 0.6091 - val_loss: 0.8465 - val_accuracy: 0.5935\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8441 - accuracy: 0.6091 - val_loss: 0.8465 - val_accuracy: 0.5935\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8441 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8441 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8441 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8441 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8464 - val_accuracy: 0.5935\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8440 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8463 - val_accuracy: 0.5935\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8439 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8438 - accuracy: 0.60 - 0s 18ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8438 - accuracy: 0.6091 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8438 - accuracy: 0.6089 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8438 - accuracy: 0.6089 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8438 - accuracy: 0.6089 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8438 - accuracy: 0.6089 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8437 - accuracy: 0.6089 - val_loss: 0.8462 - val_accuracy: 0.5935\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8437 - accuracy: 0.6089 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8437 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8437 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8437 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8437 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8437 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8437 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8437 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8437 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8461 - val_accuracy: 0.5935\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8436 - accuracy: 0.60 - 0s 18ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8436 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8435 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8435 - accuracy: 0.6098 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8435 - accuracy: 0.6100 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8435 - accuracy: 0.6100 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8435 - accuracy: 0.6100 - val_loss: 0.8460 - val_accuracy: 0.5935\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8435 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8435 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8435 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8435 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8435 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8435 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5935\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5938\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5938\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8459 - val_accuracy: 0.5938\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8434 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 346/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8458 - val_accuracy: 0.5938\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8433 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5938\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8432 - accuracy: 0.6100 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8432 - accuracy: 0.6092 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8432 - accuracy: 0.6092 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8432 - accuracy: 0.6092 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8432 - accuracy: 0.6092 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8432 - accuracy: 0.6092 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8432 - accuracy: 0.6092 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8432 - accuracy: 0.6092 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8432 - accuracy: 0.6092 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8432 - accuracy: 0.6091 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8432 - accuracy: 0.6089 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8457 - val_accuracy: 0.5944\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8431 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8430 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8430 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8430 - accuracy: 0.6089 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8456 - val_accuracy: 0.5944\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8430 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8455 - val_accuracy: 0.5944\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8429 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8428 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5944\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6091 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.6092 - val_loss: 0.8454 - val_accuracy: 0.5941\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6091 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6091 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8427 - accuracy: 0.6091 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6091 - val_loss: 0.8453 - val_accuracy: 0.5941\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6091 - val_loss: 0.8453 - val_accuracy: 0.5944\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6092 - val_loss: 0.8453 - val_accuracy: 0.5932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8427 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8427 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8426 - accuracy: 0.60 - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8453 - val_accuracy: 0.5932\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8426 - accuracy: 0.6086 - val_loss: 0.8452 - val_accuracy: 0.5932\n",
      "The cross-entropy on the test data of the tensor flow ANN is 0.843\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(patience = 4, monitor = 'val_loss')\n",
    "history = model.fit([X_mnl_train, X_ann_train],Y_train, batch_size=len(X_mnl_train), epochs = nEpoch, verbose = 1, validation_data = ([X_mnl_test, X_ann_test], Y_test), callbacks = [early_stopping])\n",
    "\n",
    "betas_layer = model.get_layer(name = 'MNL_layer')\n",
    "betas = betas_layer.get_weights()\n",
    "print('The cross-entropy on the test data of the tensor flow ANN is',\"{:.3f}\".format(history.history['loss'][-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss as a function of epochs\n",
    "plt.subplot(211)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(history.history['loss'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.ylim(0.8,1)\n",
    "\n",
    "# plot accuracy\n",
    "plt.subplot(212)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(history.history['accuracy'],     color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label = 'test')\n",
    "plt.ylim(0, 0.8)\n",
    "plt.legend()\n",
    "\n",
    "# Tweak spacing between subplots to prevent labels from overlapping\n",
    "plt.subplots_adjust(hspace = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q4** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Compute the WtP of the average decision maker to reduce the share of foreigners in a neighbourhood by 1 percentage point using the results from the hybrid model. Compare the outcome with the results of your discrete choice model (0.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta_STORES    =  -3.508\n",
      "Beta_FOREIGN =  -3.729\n",
      "Willingness-to-Pay estimates Hybrid model\n",
      "----------\n",
      "Willingness to Pay; reduction in foreigners at an expense of store distance =  1.06 min per percentage point\n"
     ]
    }
   ],
   "source": [
    "# Show the trained taste parameters, from the MNL part\n",
    "beta_STORES = np.squeeze((betas[0][0]))\n",
    "beta_FOREIGN = np.squeeze((betas[0][1]))\n",
    "print('Beta_STORES    = ', \"{:.3f}\".format(beta_STORES )) \n",
    "print('Beta_FOREIGN = ', \"{:.3f}\".format(beta_FOREIGN ))\n",
    "\n",
    "# Compute the Willingness to Pay for a Gb extra storage space\n",
    "WtP_foreign_stores_mnl = beta_FOREIGN/beta_STORES\n",
    "print('Willingness-to-Pay estimates Hybrid model')\n",
    "print('----------')\n",
    "\n",
    "print('Willingness to Pay; reduction in foreigners at an expense of store distance = ', \"{:.2f}\".format(WtP_foreign_stores_mnl),'min per percentage point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q5** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Explore whether, or not, the preferences of the inhabitants of the four cities regarding the trade-off between share of foreigners and distance to grocery stores are equal across the four cities. (1.5 pts)\n",
    "\n",
    "Perform a series of (clever) analyses, and interpret the findings. In other words, can we conclude that the inhabintants of all cities are equally xenophobic? For these analysis, use hybrid models, and/or DCMs.\n",
    "\n",
    "**Hint:** create new features capturing for the share of foreigners *per city*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "**ANSWER Q6** <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cab132ea358786bca809bd44131ddd0564f8abae658fe95d8fa3ee53812826fd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
