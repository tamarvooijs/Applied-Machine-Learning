{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4305TU - Assignment 2 - Regression\n",
    "\n",
    "In this assignment, you will apply your newly obtained regression techniques with real-life data. **You should work in groups for this assignment.**\n",
    "\n",
    "## Data source\n",
    "\n",
    "What you will be playing with is aircraft trajectory data derived from [ADS-B](https://www.skybrary.aero/index.php/Automatic_Dependent_Surveillance_Broadcast_(ADS-B)). It is collected using the antenna from the top of the aerospace building:\n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/EoBz7vVXEAAze48?format=jpg&name=medium\" width=\"400\"/>\n",
    "\n",
    "Ensentially, ADS-B data is what you see on website like FlightRadar24:\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/cPutGcE0a9jdS/giphy.gif\" width=\"400\"/>\n",
    "\n",
    "## Background\n",
    "\n",
    "In the dataset, all flight trajectories include only the descent part of the flight. The dataset is split into two directories. One directory contains flights that are following the [Continous Descent Approach (CDA)](https://www.skybrary.aero/index.php/Continuous_Descent). The other directory contains flights that do not follow CDA. \n",
    "\n",
    "CDA is an operation, where the aircraft does not have any level flight segment during the descent. Follow the link above to know more.\n",
    "\n",
    "<img src=\"https://1.bp.blogspot.com/-UFmjVcjmqCM/UIai54Y_wYI/AAAAAAAAAUM/tW1HTFP1IGI/s1600/image02_05_large.gif\" width=\"400\">\n",
    "\n",
    "\n",
    "## Data attributes\n",
    "\n",
    "The structures of all CSV files are the same. Here are descriptions of all columns:\n",
    "\n",
    "- **time**: flight time in seconds, the first row starts at time 0.\n",
    "- **icao**: aircraft transponder address, string format, unique for each aircraft.\n",
    "- **type**: aircraft type code, string format.\n",
    "- **callsign**: string format, often related to the flight number, unique for each flight.\n",
    "- **latitude**: latitude coordinate in degrees.\n",
    "- **longitude**: latitude coordinate  in degrees.\n",
    "- **speed**: aircraft speed respective to ground, unit is in knots (1 knot = 0.51444 m/s).\n",
    "- **track_angle**: direction of aircraft in relation to the true north, in degrees.\n",
    "- **vertical_rate**: aircraft climb or descent speed in feet/minute (1 ft/min = 000508 m/s), negative value indicates aircraft is descending.\n",
    "\n",
    "The most important features we are using are **time**, **altitude**, **speed**, and **vertical_rate**. \n",
    "\n",
    "## Instructions\n",
    "\n",
    "The code in this notebook serves as the base for your assignment. The tasks are defined in each section.\n",
    "\n",
    "You should implement the solutions using code cells and write your analysis using markdown cells.\n",
    "\n",
    "Once you have complete everything, before submission, remember to restart the kernel and run all cells again. Make sure there are no errors. Then you should:\n",
    "\n",
    " - Save the notebook (**replace XX in the filename with your group number**)\n",
    " - Export a HTML version of the notebook. Hint: follow Mene -> File -> Download as -> HTML\n",
    " - Submit both the notebook (.ipynb) and the export (.html)\n",
    "\n",
    "\n",
    " ## References\n",
    "\n",
    "- Quick tutorial for **Jupyter Notebook** : https://www.youtube.com/watch?v=2eCHD6f_phE\n",
    "\n",
    "- Quick tutorial for **Jupyter Lab** (if you wish to use): https://www.youtube.com/watch?v=A5YyoCKxEOU\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all trajectory files\n",
    "\n",
    "cda_files = sorted(glob.glob(\"data/cda/*.csv\"))\n",
    "noncda_files = sorted(glob.glob(\"data/noncda/*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Following two cells are some examples for data and plotting.\n",
    "\n",
    "Remove these before submit your assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_example = pd.read_csv(cda_files[0])\n",
    "df_example.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization example\n",
    "\n",
    "flight_sample = pd.read_csv(noncda_files[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 3))\n",
    "ax[0].scatter(flight_sample.time, flight_sample.altitude, s=5)\n",
    "ax[0].set_xlabel(\"time\")\n",
    "ax[0].set_ylabel(\"altitude\")\n",
    "ax[1].scatter(flight_sample.time, flight_sample.speed, s=5)\n",
    "ax[1].set_xlabel(\"time\")\n",
    "ax[1].set_ylabel(\"speed\")\n",
    "ax[2].scatter(flight_sample.time, flight_sample.vertical_rate, s=5)\n",
    "ax[2].set_xlabel(\"time\")\n",
    "ax[2].set_ylabel(\"vertical_rate\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Simple linear regression \n",
    "\n",
    "In this task you will learn how to apply simple linear regression model using a couple of flight trajectories. To complete the task, follow the steps below:\n",
    "\n",
    "1. Use you group id as random seed, select one flight from CDA trajectories, and another one from Non-CDA trajectories\n",
    "\n",
    "1. Inspect the relationships of (time, altitude), (time, speed), and (time, vertical_rate) for these two trajectories.\n",
    "\n",
    "1. Apply linear regression to all three parameters for both trajectories, using time as input and altitude as output.\n",
    "\n",
    "1. Evaluate the performance of the estimators using different error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set group_id to your own group number\n",
    "\n",
    "group_id = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(group_id)\n",
    "\n",
    "cda_filename = np.random.choice(cda_files)\n",
    "noncda_filename = np.random.choice(noncda_files)\n",
    "\n",
    "df_cda = pd.read_csv(cda_filename)\n",
    "df_noncda = pd.read_csv(noncda_filename)\n",
    "\n",
    "type_cda = df_cda[\"type\"].iloc[0]\n",
    "type_noncda = df_noncda[\"type\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    ")\n",
    "def plot_data(ax,df,xcol,ycol):\n",
    "    x = df[xcol].values\n",
    "    y = df[ycol].values\n",
    "    type = df.index.values\n",
    "    \n",
    "    ax.scatter(x, y, color=\"k\",s=5,lw=2,label=ycol)\n",
    "    ax.set_xlabel(xcol)\n",
    "    ax.set_ylabel(ycol)\n",
    "    ax.legend()\n",
    "\n",
    "def plot_predict(ax, b0, b1, x, y, color='b'):\n",
    "\n",
    "    x_ = np.linspace(min(x), max(x), 10)\n",
    "\n",
    "    y_ = b0 + b1 * x_\n",
    "\n",
    "    ax.plot(x_, y_, label=\"$\\\\beta_0$:{} \\t $\\\\beta_1$:{}\".format(b0, b1))\n",
    "\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(this is a markdown cell)\n",
    "\n",
    "write your analysis here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Multiple linear regression\n",
    "\n",
    "In this task you will learn how to apply Polynomial regression model. To complete the task, follow the steps below:\n",
    "\n",
    "1. Using the same trajectories from the previous task, but choose both speed and altitude as predictors for the vertical rate. \n",
    "\n",
    "1. Construct a 3D multiple linear regression model\n",
    "\n",
    "1. Visualize your result and briefly analyze your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "# create more cells if needed\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(this is a markdown cell)\n",
    "\n",
    "write your analysis here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Polynomial regression\n",
    "\n",
    "In this task you will learn how to apply Polynomial regression model. To complete the task, follow the steps below:\n",
    "\n",
    "1. Based on previous trajectories, apply polynomial regression, using altitude as input and speed as output. \n",
    "\n",
    "1. Try out different orders of polynomials.\n",
    "\n",
    "1. Analyze your choice briefly. Taking into consideration of bias-variance trade-off.\n",
    "\n",
    "1. Applying regularization to a high-order polynomial model you have tried earlier. Write a brief analysis of your result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "# create more cells if needed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(this is a markdown cell)\n",
    "\n",
    "write your analysis here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Logistic regression\n",
    "\n",
    "In this task you will learn how to apply Logistic regression model. You need to generate a new dataset based on given data. To complete the task, follow the steps below:\n",
    "\n",
    "1. For all trajectories in CDA and NON-CDA group, apply linear regression, using time as input and altitude as output.\n",
    "\n",
    "1. Calculate MAE for all regression models. Construct a dataset with MAE as input, and CDA status as output (CDA as 0, and NON-CDA as 1).\n",
    "\n",
    "1. Determine the Logistic regression model describe the relationship between MAE and CDA status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "# create more cells if needed\n",
    "\n",
    "\n",
    "def calcMAE(df):\n",
    "    # complete this function for calculating MAE\n",
    "\n",
    "    # [TODO] fit linear model to time and altitude\n",
    "\n",
    "    # [TODO] calculate MAE\n",
    "\n",
    "    return MAE\n",
    "\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for f in cda_files:\n",
    "    df = pd.read_csv(f)\n",
    "    MAE = calcMAE(df)\n",
    "    new_data.append((MAE, 0))\n",
    "\n",
    "for f in noncda_files:\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "    MAE = calcMAE(df)\n",
    "    new_data.append((MAE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your logistic regression code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(this is a markdown cell)\n",
    "\n",
    "write your analysis here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Bayesian regression\n",
    "\n",
    "In this task you will learn how to apply Bayesian regression model. I recommend to use of `pymc3` library. To complete the task, follow the steps below:\n",
    "\n",
    "1. Apply Bayesian linear regression to vertical speed of CDA and Non-CDA trajectories (time as input). Provide an analysis of your result.\n",
    "\n",
    "1. **(Bonus)** Design a quadratic model to altitude using the Bayesian regression approach. Visualize and analyze your findings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "# create more cells if needed\n",
    "\n",
    "# Tip: try different prior probability density functions of parameters. If the regression fails:\n",
    "#   1. change the initial guess.\n",
    "#   2. change the variance for the priors of the random variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data preprocessing\n",
    "#   - Combine data from all cda into single array (same for non cda)\n",
    "#   - Split data into test and train set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_var = 'time'\n",
    "y_var = 'vertical_rate'\n",
    "train_size = 0.8    \n",
    "\n",
    "all_data = {'cda':      cda_files, \n",
    "            'non cda':  noncda_files}\n",
    "X_train, X_test, y_train, y_test = {}, {}, {}, {}\n",
    "\n",
    "for item in all_data.keys():    # iterate over 1. cda, 2. non cda\n",
    "    X, y = [], []\n",
    "    for f in all_data[item]:\n",
    "        df = pd.read_csv(f)\n",
    "        X.append(df.loc[:, X_var].to_numpy())\n",
    "        y.append(df.loc[:, y_var].to_numpy())\n",
    "\n",
    "    X = np.array([item for sublist in X for item in sublist])   # create a 1-dimensional array\n",
    "    y = np.array([item for sublist in y for item in sublist])   # create a 1-dimensional array\n",
    "\n",
    "    X_train[item], X_test[item], y_train[item], y_test[item] = train_test_split(X, y, train_size=train_size, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform bayesian linear regression \n",
    "import pymc3 as pm\n",
    "\n",
    "trace_dict = {}     # used to store the trace output for 1. cda, 2. non cda\n",
    "\n",
    "for item in all_data.keys():\n",
    "    print(f'Starting the {item} data points analysis ...')\n",
    "    with pm.Model() as model:\n",
    "        beta_0 = pm.Normal(\"beta_0\", mu=-1500, sd=1000)     # initial guesses\n",
    "        beta_1 = pm.Normal(\"beta_1\", mu=0, sd=200)          # initial guesses\n",
    "        sigma  = pm.HalfNormal(\"sigma\", sd=1000)            # initial guesses\n",
    "\n",
    "        y = pm.Normal(\"y\", mu=beta_0 + beta_1 * X_train[item], sd=sigma, observed=y_train[item])\n",
    "\n",
    "        # using the simplest MH sampler\n",
    "        step = pm.Metropolis()\n",
    "\n",
    "        # we are drawing 5000 samples using 4 chains\n",
    "        trace = pm.sample(draws=5000, step=step, chains=4)\n",
    "        trace_dict[item] = trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results of the final parameters\n",
    "import arviz as az\n",
    "\n",
    "for item in all_data.keys():\n",
    "    print(az.summary(trace_dict[item], round_to=2))\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 8))\n",
    "    fig.suptitle(f'{item} data points', fontsize=16)\n",
    "    pm.traceplot(trace_dict[item], axes=axes)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform reference linear regression for comparison\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg_dict = {}\n",
    "\n",
    "for item in all_data.keys():\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train[item].reshape(-1, 1), y_train[item])\n",
    "    linreg_dict[item] = linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the final results\n",
    "\n",
    "fig_scale = 1.4\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14*fig_scale, 6*fig_scale))\n",
    "\n",
    "data_labels = list(all_data.keys())\n",
    "blr_coef = {}\n",
    "\n",
    "for i in range(len(data_labels)):\n",
    "    item = data_labels[i]\n",
    "\n",
    "    axes[i].set_title(f'{item} data points', fontsize=16)\n",
    "    axes[i].scatter(X_train[item], y_train[item], s=20, lw=1.5, color='b', label=\"training set\", facecolor=\"w\", zorder=10, alpha=0.2)\n",
    "    axes[i].scatter(X_test[item], y_test[item],  s=20, lw=1.5, color=\"r\", label=\"testing set\", facecolor=\"w\", zorder=10, alpha=0.2)\n",
    "\n",
    "    x_ = np.linspace(X_train[item].min(), X_train[item].max(), 100)\n",
    "    for j in range(100):\n",
    "        b0 = np.random.choice(trace_dict[item][\"beta_0\"])\n",
    "        b1 = np.random.choice(trace_dict[item][\"beta_1\"])\n",
    "        axes[i].plot(x_, b0 + b1 * x_, lw=0.5, color=\"k\", alpha=0.4)   \n",
    "    \n",
    "    axes[i].plot(x_, linreg_dict[item].predict(x_.reshape(-1,1)), 'orange', label='linear regression')    # 'normal' linear regression\n",
    "\n",
    "    b0_mean = trace_dict[item][\"beta_0\"].mean()\n",
    "    b1_mean = trace_dict[item][\"beta_1\"].mean()\n",
    "    sigma_mean = trace_dict[item][\"sigma\"].mean()\n",
    "    blr_coef[item] = [b0_mean, b1_mean, sigma_mean]\n",
    "\n",
    "    axes[i].plot(x_, b0_mean + b1_mean * x_, lw=1, color=\"r\", label=\"mean bayesian linear regressor\")   # mean of the bayesian linear regression\n",
    "    axes[i].set_xlabel(X_var.capitalize())\n",
    "    axes[i].axhline(0, color='k', linewidth=1, linestyle='-')\n",
    "    axes[i].set_ylabel(y_var.replace('_', ' ').capitalize())\n",
    "    axes[i].legend()\n",
    "    axes[i].set_xlim(0, None)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare error metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for item in all_data.keys():\n",
    "    MSE_lr = mean_squared_error(y_test[item], linreg_dict[item].predict(X_test[item].reshape(-1, 1)))\n",
    "    print(f'Linear Regression testing results {item}:\\n\\tMSE: {MSE_lr.round(2)}\\n\\tRMSE:{np.sqrt(MSE_lr).round(2)}')\n",
    "\n",
    "    MSE_blr = mean_squared_error(y_test[item], blr_coef[item][0] + blr_coef[item][1] * X_test[item])\n",
    "    print(f'Average Bayesian Linear Regression testing results {item}:\\n\\tMSE: {MSE_blr.round(2)}\\n\\tRMSE:{np.sqrt(MSE_blr).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of above methods and results:\n",
    "\n",
    "-   To start this task, the input and output data was retrieved for all CDA and NON CDA data files, and split into a trainging and test set (80% - 20%) to allow to compute error metrics afterwards.\n",
    "-   To perform the bayesian linear regression, three random variables are to be defined: beta_0, beta_1, and sigma; which are taken to follow a Normal, Normal, and Half Normal distribution, respectively. The initial guesses for the mean and stdv are found by trial and error such that the final model converges to an optimal solution. These probability metrics were found to give the required results.\n",
    "-   For the optimisation method, the simplest Metropolis (MH) sampler is used, as this is found to get the job done. Furthermore, four chains are used to ensure a converged solution.\n",
    "-   Subsequently, the random variables as obtained from the optimisation are plotted, from which it becomes clear that each of the four chains converged to a similar probability distribution.\n",
    "-   By using the optimised random variables for the bayesian linear regression prediction, the final results are plotted together with the train and test data points. Here, both the mean of the bayesian linear regression, as well as the uncertainty range becomes visible. To check whether the obtained mean bayesian liner regression corresponds to a 'normal' linear regression analysis, the latter line is also added to the graph. It can be seen that both lines coincide, which indicates that the found bayesian linear regression solution actually is correct.\n",
    "-   Finally, both the MSE and RMSE are computed for the test data, for both the 'normal' linear regressor, and the mean of the bayesian linear regressor. These values are seen to be similar, which again indicates a correct implimentation of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================================================\n",
    "\n",
    "2. **(Bonus)** Design a quadratic model to altitude using the Bayesian regression approach. Visualize and analyze your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "# create more cells if needed\n",
    "\n",
    "# Tip: try different prior probability density functions of parameters. If the regression fails:\n",
    "#   1. change the initial guess.\n",
    "#   2. change the variance for the priors of the random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform data preprocessing\n",
    "#   - Combine data from all cda into single array (same for non cda)\n",
    "#   - Split data into test and train\n",
    "\n",
    "X_var = 'time'\n",
    "y_var = 'altitude'\n",
    "train_size = 0.8    \n",
    "\n",
    "all_data = {'cda':      cda_files, \n",
    "            'non cda':  noncda_files}\n",
    "X_train, X_test, y_train, y_test = {}, {}, {}, {}\n",
    "\n",
    "for item in all_data.keys():    # iterate over 1. cda, 2. non cda\n",
    "    X, y = [], []\n",
    "    for f in all_data[item]:\n",
    "        df = pd.read_csv(f)\n",
    "        X.append(df.loc[:, X_var].to_numpy())\n",
    "        y.append(df.loc[:, y_var].to_numpy())\n",
    "\n",
    "    X = np.array([item for sublist in X for item in sublist])   # create a 1-dimensional array\n",
    "    y = np.array([item for sublist in y for item in sublist])   # create a 1-dimensional array\n",
    "\n",
    "    X_train[item], X_test[item], y_train[item], y_test[item] = train_test_split(X, y, train_size=train_size, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "trace_dict = {}     # used to store the trace output for 1. cda, 2. non cda\n",
    "\n",
    "# perform bayesian quadratic regression \n",
    "for item in all_data.keys():\n",
    "    print(f'Starting the {item} data points analysis ...')\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        beta_0 = pm.Normal(\"beta_0\", mu=25_000, sd=1000)   # initial guesses\n",
    "        beta_1 = pm.Normal(\"beta_1\", mu=0, sd=20)       # initial guesses\n",
    "        beta_2 = pm.Normal(\"beta_2\", mu=0, sd=20)       # initial guesses\n",
    "        sigma  = pm.HalfNormal(\"sigma\", sd=1000)         # initial guesses\n",
    "\n",
    "        y = pm.Normal(\"y\", mu=beta_0 + beta_1 * X_train[item] + beta_2 * X_train[item]**2, sd=sigma, observed=y_train[item])\n",
    "\n",
    "        # using the simplest MH sampler\n",
    "        # step = pm.Metropolis()\n",
    "        step = pm.NUTS()\n",
    "\n",
    "        # we are drawing 8000 samples using 4 chains\n",
    "        trace = pm.sample(draws=8000, step=step, chains=4)\n",
    "        trace_dict[item] = trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results of the final parameters\n",
    "import arviz as az\n",
    "\n",
    "for item in all_data.keys():\n",
    "    print(az.summary(trace_dict[item], round_to=3))\n",
    "\n",
    "    fig, axes = plt.subplots(4, 2, figsize=(12, 8))\n",
    "    fig.suptitle(f'{item} data points', fontsize=16)\n",
    "    pm.traceplot(trace_dict[item], axes=axes)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform reference quadratic regression for comparison\n",
    "qr_coef = {}\n",
    "\n",
    "for item in all_data.keys():\n",
    "    k = 2\n",
    "    coef_np = np.polyfit(X_train[item], y_train[item], deg=k)\n",
    "    coef = coef_np[::-1]\n",
    "    qr_coef[item] = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "\n",
    "fig_scale = 1.4\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14*fig_scale, 6*fig_scale))\n",
    "\n",
    "data_labels = list(all_data.keys())\n",
    "bqr_coef = {}   # bayesian quadratic coefficients \n",
    "\n",
    "for i in range(len(data_labels)):\n",
    "    item = data_labels[i]\n",
    "    \n",
    "    axes[i].set_title(f'{item} data points', fontsize=16)\n",
    "    axes[i].scatter(X_train[item], y_train[item], s=20, lw=1.5, color='b', label=\"training set\", facecolor=\"w\", zorder=10, alpha=0.2)\n",
    "    axes[i].scatter(X_test[item], y_test[item],  s=20, lw=1.5, color=\"r\", label=\"testing set\", facecolor=\"w\", zorder=10, alpha=0.2)\n",
    "\n",
    "    x_ = np.linspace(X_train[item].min(), X_train[item].max(), 100)\n",
    "    for j in range(100):\n",
    "        b0 = np.random.choice(trace_dict[item][\"beta_0\"])\n",
    "        b1 = np.random.choice(trace_dict[item][\"beta_1\"])\n",
    "        b2 = np.random.choice(trace_dict[item][\"beta_2\"])\n",
    "        axes[i].plot(x_, b0 + b1 * x_ + b2 * x_**2, lw=0.5, color=\"k\", alpha=0.4)\n",
    "\n",
    "    axes[i].plot(x_, qr_coef[item][0] + qr_coef[item][1]*x_ + qr_coef[item][2]*x_**2, 'orange', label='quadratic regression')     # 'normal' quadratic regression\n",
    "    \n",
    "    b0_mean = trace_dict[item][\"beta_0\"].mean()\n",
    "    b1_mean = trace_dict[item][\"beta_1\"].mean()\n",
    "    b2_mean = trace_dict[item][\"beta_2\"].mean()\n",
    "    sigma_mean = trace_dict[item][\"sigma\"].mean()\n",
    "    bqr_coef[item] = [b0_mean, b1_mean, b2_mean, sigma_mean]\n",
    "\n",
    "    axes[i].plot(x_, b0_mean + b1_mean * x_ + b2_mean * x_**2, lw=1, color=\"r\", label=\"mean bayesian quadratic regressor\")   # average bayesian quadratic regression\n",
    "\n",
    "    axes[i].set_xlabel(X_var.capitalize())\n",
    "    axes[i].axhline(0, color='k', linewidth=1, linestyle='-')\n",
    "    axes[i].set_ylabel(y_var.replace('_', ' ').capitalize())\n",
    "    axes[i].legend()\n",
    "    axes[i].set_ylim(5000, None)\n",
    "    axes[i].set_xlim(0, None)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare error metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for item in all_data.keys():\n",
    "    MSE_qr = mean_squared_error(y_test[item], qr_coef[item][0] + qr_coef[item][1]*X_test[item] + qr_coef[item][2]*X_test[item]**2)\n",
    "    print(f'Quadratic Regression testing results {item}:\\n\\tMSE: {MSE_qr.round(2)}\\n\\tRMSE:{np.sqrt(MSE_qr).round(2)}')\n",
    "\n",
    "    MSE_bqr = mean_squared_error(y_test[item], bqr_coef[item][0] + bqr_coef[item][1] * X_test[item] + bqr_coef[item][2] * X_test[item]**2)\n",
    "    print(f'Average Bayesian Quadratic Regression testing results {item}:\\n\\tMSE: {MSE_bqr.round(2)}\\n\\tRMSE:{np.sqrt(MSE_bqr).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of above methods and results:\n",
    "\n",
    "-   Similar to part 1 of this task, first, the input and output data was retrieved for all CDA and NON CDA data files, and split into a training and test set (80% - 20%) to allow to compute error metrics afterwards.\n",
    "-   To perform the bayesian quadratic regression, an additional random variable is needed in order to describe the relation. This results in a total of four random variables to be optimised. The initial guesses for these parameters turned out to be more sensitive compared to the bayesian linear regressor. More trial and error iterations were required to find initial values that resulted in a converged solution.\n",
    "-   For the optimisation method, it was found that the simples Metropolis (MH) sampler was not able to converge to the optimal solution (while it did get close). Therefore, it was chosen to use the NUTS sampler, which resulted in a more accurate final solution. The number of draws was also increased from 4000 to 8000 to allow the optimiser more trials to reach convergence.\n",
    "-   Subsequently, the random variables as obtained from the optimisation are plotted, from which it becomes clear that each of the four chains converged to a similar probability distribution.\n",
    "-   By using the optimised random variables for the bayesian quadratic regression prediction, the final results are plotted together with the train and test data points. Here, both the mean of the bayesian quadratic regressor, as well as the uncertainty range becomes visible. To check whether the obtained mean bayesian quadratic regression corresponds to a 'normal' quadratic regression analysis, the latter line is also added to the graph. It can be seen that both lines coincide, which indicates that the found bayesian quadratic regression solution actually is correct.\n",
    "-   Finally, both the MSE and RMSE are computed for the test data, for both the 'normal' quadratic regressor, and the mean of the bayesian quadratic regressor. These values are seen to be similar, which again indicates a correct implimentation of the model."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df9436bd41cfce2279a4eb3ca812802e0d60e734b01d8c00509ce9fbce533a4a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
